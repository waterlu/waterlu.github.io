<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Java基础-泛型]]></title>
    <url>%2F2018%2F05%2F29%2Fjava-basic-generic%2F</url>
    <content type="text"><![CDATA[Java泛型泛型泛型简单理解就是类型可以是变量，原本需要声明一个固定的类，现在变成了变量，这就是泛型。 泛型的好处是在编译期就可以进行类型检查，避免出现错误。 常见的List类就声明了泛型，如果声明List&lt;String&gt; list; 那么list中就只能添加String对象，否则编译时会报错。 public interface List&lt;E&gt; extends Collection&lt;E&gt; &#123;&#125; 这里E可以使用任何字母，都没有关系，都表示一个待确定的类。一般习惯上经常使用的泛型字母有E、T、K、V。 泛型除了可以放在类上，还可以放在方法上，既可以声明参数，也可以声明返回值。 public interface Map&lt;K,V&gt; &#123; V get(Object key); V put(K key, V value);&#125; 泛型除了声明方法外，还可以直接放入代码中代替类声明 for (Map.Entry&lt;? extends K, ? extends V&gt; e : m.entrySet()) &#123; K key = e.getKey(); V value = e.getValue(); putVal(hash(key), key, value, false, evict);&#125; 限定子类以上声明的泛型可以被替换成任何类，如果需要限定类型范围，可以使用extends和super关键字 假设继承关系： Man -&gt; Human -&gt; Object // 可以使用Man或者Human，从Human类开始向下找，Human类和它的子类都可以public class Test&lt;? extends Human&gt; &#123;&#125; // 可以使用Human或者Object，从Human类开始向上找，Human类和它的父类都可以public class Test&lt;? super Human&gt; &#123;&#125; 除了在声明类和方法时使用extends和super关键字，也可以在引用时使用 List&lt;? extends Integer&gt; list1 = new ArrayList&lt;&gt;();List&lt;? super Integer&gt; list2 = new ArrayList&lt;&gt;(); 类型擦除类型擦除是Java泛型中比较绕的一点，类型擦除的意思是：泛型只在编译期有效，运行期实际上泛型是不存在的。 public class Test&lt;T&gt; &#123; T data;&#125; 在运行期间等同于 public class Test&lt;Object&gt; &#123; Object data;&#125; 也就是说，泛型的类型检查只在编译期起作用，在运行期实际上已经没有用了。这么做的原因是为了兼容，JDK1.5以后才引入泛型。 我们来看一个例子，运行结果输入[1, test] 。虽然list声明为只接收Integer元素，但是当我们通过反射获取到list的add()方法后，是可以添加字符串进去的。这个例子充分说明：泛型的类型检查只在编译期有效，运行期是没有类型检查的。 List&lt;Integer&gt; list = new ArrayList&lt;&gt;();list.add(1);Class&lt;? extends List&gt; clazz = list.getClass();Method addMethod = clazz.getMethod("add", Object.class);addMethod.invoke(list, "test");System.out.println(list); 运行期类型检查被去掉了，就叫做类型擦除。 由于类型擦除问题的存在，Java不允许创建泛型数组。 List&lt;Integer&gt; [] listArray = new List&lt;Integer&gt;[2]; // Generic Array Creation 上面这样的写法是无法编译通过的。 为什么？因为Java对于数组[]有自己执着的要求，必须知道数组[]里面数据的类型。虽然现在声明了&lt;Integer&gt; ，但是由于运行期间类型会被擦除掉，所以Java实际上不知道也不能保证里面的数据类型，所以就不让创建。当然，把泛型去掉后就可以创建了，像下面这样写是可以编译通过的。 List&lt;Integer&gt; [] listArray = new List[2]; 实战泛型Class对象例如：在JSON解析字符串时，有时需要从外部传入Class对象，一般写法如下： public &lt;T&gt; T string2Object(String jsonString, Class&lt;T&gt; clazz) &#123; return JSONObject.parseObject(jsonString, clazz);&#125;public &lt;T&gt; List&lt;T&gt; string2ObjectList(String jsonString, Class&lt;T&gt; clazz) &#123; return JSONObject.parseArray(jsonString, clazz);&#125; 读取真实类型有时需要在代码中读取泛型的真实类型，一般写法如下： public abstract class BaseController&lt;T extends BaseEntity, P extends ParamDTO&gt; &#123; protected T paramToEntity(P param) &#123; String jsonString = JSON.toJSONString(param); return (T) JSON.parseObject(jsonString, getGenericType(0)); &#125; protected Type getGenericType(int index) &#123; // 读取泛型参数 Type superType = this.getClass().getGenericSuperclass(); if (superType instanceof ParameterizedType) &#123; return ((ParameterizedType) superType).getActualTypeArguments()[index]; &#125; else &#123; throw new RuntimeException("Unknown entity class type"); &#125; &#125;&#125; 上面是一个真实的例子，BaseController类声明了两个泛型，T基础实体类基类BaseEntity，P继承实体类基类ParamDTO；paramToEntity()方法将P类实例对象通过JSON转换成T类实例对象。JSON.parseObject()方法需要传入实体类的真实类型T，这里写T或者T.class都是不行的。这个时候就需要通过反射读取真实的T类型。 public class UserController extends BaseController&lt;User, UserDTO&gt; &#123; &#125; 运行时执行getGenericType(0)返回User.class。getActualTypeArguments()方法返回泛型参数，index是泛型参数的顺序，如果只有一个泛型参数写0就行。]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>泛型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java基础-动态代理]]></title>
    <url>%2F2018%2F05%2F28%2Fjava-basic-proxy%2F</url>
    <content type="text"><![CDATA[JDK动态代理动态代理是AOP面向接口编程的基础。 静态代理解释动态代理概念前我们先来看看什么是静态代理。 非常常见的代码，我们定义UserMapper接口和它的实现类UserMapperImpl，然后我们又定义了代理类UserMapperProxy，代理类同样实现UserMapper接口，但它把真正的工作交给UserMapperImpl去做。 public interface UserMapper &#123; void save(User user);&#125; public class UserMapperImpl implements UserMapper &#123; @Override public void save(User user) &#123; System.out.println("UserMapperImpl save()"); &#125;&#125; public class UserMapperProxy implements UserMapper &#123; private UserMapperImpl userMapperImpl; public UserMapperProxy(UserMapperImpl userMapperImpl) &#123; this.userMapperImpl = userMapperImpl; &#125; @Override public void save(User user) &#123; System.out.println("UserMapperProxy before save()"); userMapperImpl.save(user); System.out.println("UserMapperProxy after save()"); &#125;&#125; 使用时的代码如下，这就是静态代理。UserMapperProxy作为UserMapperImpl的代理，接收外部请求，可以在实际处理逻辑前后或者抛出异常时增加自己的处理。UserMapperProxy实际上就起到了切入的作用，但它是静态了，需要硬编码。所谓动态代理，个人理解就是UserMapperProxy类不用硬编码了，我们可以在运行时动态生成UserMapperProxy类的代码。 UserMapper userMapper = new UserMapperProxy(new UserMapperImpl());userMapper.save(new User()); 动态代理动态代理有两种常见的实现方式：JDK实现和CGLib实现，本文只关注JDK实现方式。 下面看看基于JDK动态代理如何实现上面的效果。注意：JDK只能基于接口做动态代理。 首先，我们创建DynamicProxy类。 DynamicProxy类的作用是生成代理对象； DynamicProxy类必须继承InvocationHandler接口，并实现invoke()方法； 核心代码是Proxy.newProxyInstance() ，这个方法创建了代理对象。 public class DynamicProxy implements InvocationHandler &#123; private Object target; public Object bind(Object target) &#123; this.target = target; return Proxy.newProxyInstance(target.getClass().getClassLoader(), target.getClass().getInterfaces(), this); &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println("proxy invoke begin"); Object result = method.invoke(target, args); System.out.println("proxy invoke end"); return result; &#125;&#125; 下面看看如何使用 DynamicProxy proxy = new DynamicProxy();UserMapper userMapper = (UserMapper) proxy.bind(new UserMapperImpl());userMapper.save(new User()); 为什么用动态代理我们再来比对一下静态代理和动态代理的代码，看上去差不多啊，没看出来使用动态代理有什么好处啊，为什么要使用动态代理呢？ // 静态代理UserMapper userMapper = new UserMapperProxy(new UserMapperImpl());userMapper.save(new User());// 动态代理UserMapper userMapper = (UserMapper) new DynamicProxy().bind(new UserMapperImpl());userMapper.save(new User()); 首先，假设我们在UserMapper中增加一个update()方法，那么UserMapperImpl肯定要实现这个新增的update()方法，这个跑不了。我们再来看看静态代理和动态代理都需要做出哪些改变： 静态代理：UserMapperProxy类由于实现了UserMapper接口，所以必须要修改UserMapperProxy类实现update()方法，在update()方法中调用UserMapperImpl并输出日志。 动态代理：DynamicProxy类不用修改就可以用。 public interface UserMapper &#123; void save(User user); int update(User user);&#125; 接下来，假设我们添加一个新的接口AccountMapper和它的实现类AccountMapperImpl，那么静态代理和动态代理又要做出哪些改变呢： 静态代理：UserMapperProxy不能用了，我们还得再定义一个AccountMapperProxy类； 动态代理：DynamicProxy类不用修改就可以用。 看到动态代理的好处了吧，这就是使用动态代理的原因。 实现原理动态代理到底都做了什么？简单说，就是动态生成了XxxProxy代理类，这应该也是动态代理这个名字的由来。从上面的例子我们可以看到，静态代理麻烦之处就在于每次接口发生改变，代理类就得随之改变，怎么解决这个问题呢？那就是代理类不是在编译期生成的，而是在运行期生成的，在运行期根据接口内容动态生成代理类，自然就能满足要求。所以，动态代理可以认为是一种动态生成Java字节码的技术。 添加JVM参数-Dsun.misc.ProxyGenerator.saveGeneratedFiles=true ，重新运行前面的例子，可以在项目根目录下的com/sun/proxy目录下找到自动生成的代理类$proxy?.class。 我这里是$Proxy2.class Proxy2就是bind()时返回的代理类，所以userMapper.save()实际上调用的是Proxy2的save()方法，这个方法调用了InvocationHandler接口的invoke()方法（所以DynamicProxy一定要实现InvocationHandler接口），invoke()方法传递了三个参数，this就是$Proxy2类实例，m4是通过反射得到的UserMapper接口的save()方法，var1是透传的参数。 public final class $Proxy2 extends Proxy implements UserMapper &#123; private static Method m3; private static Method m4; static &#123; m3 = Class.forName("UserMapper").getMethod("update", new Class[]&#123;Class.forName("User")&#125;); m4 = Class.forName("UserMapper").getMethod("save", new Class[]&#123;Class.forName("User")&#125;); &#125; public $Proxy2(InvocationHandler var1) throws &#123; super(var1); &#125; public final int update(User var1) throws &#123; return ((Integer)super.h.invoke(this, m3, new Object[]&#123;var1&#125;)).intValue(); &#125; public final void save(User var1) throws &#123; super.h.invoke(this, m4, new Object[]&#123;var1&#125;); &#125;&#125; public class Proxy &#123; protected InvocationHandler h; protected Proxy(InvocationHandler h) &#123; this.h = h; &#125; &#125; 个人理解：根据实现类的实例对象通过反射机制自动生成了实现了接口的代理类实例对象，这就是动态代理。 DynamicProxy类的bind()方法是整个动态代理实现的核心，我们来详细解读一下： 首先，bind()方法的入参和返回值都是一个对象：入参是实现类实例对象，返回值是代理类实例对象； target.getClass().getInterfaces()得到了入参对象实现的接口类信息（可以是多个）； Proxy.newProxyInstance()方法传入接口类信息和回调Handler，生成代理类实例对象并返回： 自动生成$Proxy0类，继承Proxy类，实现传入的接口类； 通过反射获取接口类的所有方法，在$Proxy0类中自动生成这些方法的实现； $Proxy0类中保存了通过反射得到的接口类的方法； $Proxy0类在接口类实现方法中调用Handler的invoke()方法，传入反射Method作为参数； DynamicProxy类的invoke()方法中，通过反射调用target对象的Method方法，虽然Method方法是通过对接口的反射得到的，由于接口是从target对象的类信息中提取的，所以target一定有这个方法。 核心要点 自动生成$Proxy0类并通过反射创建它的实例对象； 根据实现类提取接口，在代理类中实现这些接口，并在代理类中通过反射得到接口的成员方法； DynamicProxy类拥有target对象，invoke()回调传递了方法，就可以通过反射来执行了。 源码分析Proxy以上我们了解了JDK动态代理的原理，知道最核心的是Proxy.newProxyInstance()方法，下面就来看看它的源码。 package java.lang.reflect;public class Proxy implements java.io.Serializable &#123; public static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) &#123; Class&lt;?&gt; cl = getProxyClass0(loader, intfs); final Constructor&lt;?&gt; cons = cl.getConstructor(constructorParams); cons.setAccessible(true); return cons.newInstance(new Object[]&#123;h&#125;); &#125; &#125; 调用getProxyClass0()获取$Proxy0类信息，反射获取构造函数，以h为参数构造$Proxy0类的实例对象并返回。 package java.lang.reflect;public class Proxy implements java.io.Serializable &#123; private static Class&lt;?&gt; getProxyClass0(ClassLoader loader, Class&lt;?&gt;... interfaces) &#123; return proxyClassCache.get(loader, interfaces); &#125;&#125; package java.lang.reflect;final class WeakCache&lt;K, P, V&gt; &#123; public V get(K key, P parameter) &#123; // 这里很复杂，做了简化 Factory factory = new Factory(key, parameter, subKey, valuesMap); V value = factory.get(); return value; &#125; private final class Factory implements Supplier&lt;V&gt; &#123; @Override public synchronized V get() &#123; V value = Objects.requireNonNull(valueFactory.apply(key, parameter)); return value; &#125; &#125;&#125; getProxyClass0()方法优先从缓存中读取，如果读取不到使用factory创建，最终调用Proxy类的内部类ProxyClassFactory的apply()方法。 package java.lang.reflect;public class Proxy implements java.io.Serializable &#123; private static final class ProxyClassFactory &#123; @Override public Class&lt;?&gt; apply(ClassLoader loader, Class&lt;?&gt;[] interfaces) &#123; // 示意 String proxyName = "com.sun.proxy.$Proxy0"; byte[] proxyClassFile = ProxyGenerator.generateProxyClass(proxyName, interfaces, accessFlags); return defineClass0(loader, proxyName, proxyClassFile, 0, proxyClassFile.length); &#125; &#125;&#125; 最后调用ProxyGenerator.generateProxyClass()方法来动态创建代理类。代理类的名字是在Proxy中确定的，具体如何生成代码在sun的package下。 ProxyGeneratorProxyGenerator类在rt.jar中，但不在java.* 包下，在sun.* 包下。generateProxyClass()静态方法创建ProxyGenerator对象并调用它的generateClassFile()方法。 JDK中默认不包括ProxyGenerator类的源码，以下内容为摘抄并整理。 package sun.misc;public class ProxyGenerator &#123; private String className; private Class&lt;?&gt;[] interfaces; private int accessFlags; private byte[] generateClassFile() &#123; // 组装ProxyMethod对象 // 为代理类生成toString, hashCode, equals等方法 addProxyMethod(hashCodeMethod, Object.class); addProxyMethod(equalsMethod, Object.class); addProxyMethod(toStringMethod, Object.class); // 遍历每一个接口的每一个方法, 并且为其生成ProxyMethod对象 for (int i = 0; i &lt; interfaces.length; i++) &#123; Method[] methods = interfaces[i].getMethods(); for (int j = 0; j &lt; methods.length; j++) &#123; addProxyMethod(methods[j], interfaces[i]); &#125; &#125; try &#123; // 添加构造函数 // 例如: public $Proxy2(InvocationHandler var1) throws &#123; super(var1); &#125; methods.add(generateConstructor()); // 遍历前面生成的代理方法 for (List&lt;ProxyMethod&gt; sigmethods : proxyMethods.values()) &#123; for (ProxyMethod pm : sigmethods) &#123; // 添加代理类的静态字段 // 例如: private static Method m2; fields.add(new FieldInfo(pm.methodFieldName, "Ljava/lang/reflect/Method;", ACC_PRIVATE | ACC_STATIC)); // 添加代理类的代理方法 // 真正实现每一个方法体 methods.add(pm.generateMethod()); &#125; &#125; // 添加代理类的静态字段初始化方法 // 例如：m2 = Class.forName("java.lang.Object").getMethod("toString", new Class[0]); methods.add(generateStaticInitializer()); &#125; catch (IOException e) &#123; throw new InternalError("unexpected I/O Exception"); &#125; // 写入文件流 ByteArrayOutputStream bout = new ByteArrayOutputStream(); DataOutputStream dout = new DataOutputStream(bout); try &#123; //1.写入魔数 dout.writeInt(0xCAFEBABE); //2.写入次版本号 dout.writeShort(CLASSFILE_MINOR_VERSION); //3.写入主版本号 dout.writeShort(CLASSFILE_MAJOR_VERSION); //4.写入常量池 cp.write(dout); //5.写入访问修饰符 dout.writeShort(ACC_PUBLIC | ACC_FINAL | ACC_SUPER); //6.写入类索引 dout.writeShort(cp.getClass(dotToSlash(className))); //7.写入父类索引, 生成的代理类都继承自Proxy dout.writeShort(cp.getClass(superclassName)); //8.写入接口计数值 dout.writeShort(interfaces.length); //9.写入接口集合 for (int i = 0; i &lt; interfaces.length; i++) &#123; dout.writeShort(cp.getClass(dotToSlash(interfaces[i].getName()))); &#125; //10.写入字段计数值 dout.writeShort(fields.size()); //11.写入字段集合 for (FieldInfo f : fields) &#123; f.write(dout); &#125; //12.写入方法计数值 dout.writeShort(methods.size()); //13.写入方法集合 for (MethodInfo m : methods) &#123; m.write(dout); &#125; //14.写入属性计数值, 代理类class文件没有属性所以为0 dout.writeShort(0); &#125; catch (IOException e) &#123; throw new InternalError("unexpected I/O Exception"); &#125; //转换成二进制数组输出 return bout.toByteArray(); &#125; &#125; 首先从方法名称generateClassFile()就可以知道这是直接生成.class文件，不是生成.java文件，所以这个方法的任务是按照.class文件格式写入数据流。 addProxyMethod()把要生成的方法加入到proxyMethods中； fields是需要写入到.class文件中的成员变量； methods是需要写入到.class文件中的方法。 CGLIB动态代理JDK动态代理必须基于接口，如果没有接口就不能使用JDK动态代理。 CGLIB是另外一种动态代理实现，不依赖于接口。]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>动态代理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java基础-注解]]></title>
    <url>%2F2018%2F05%2F28%2Fjava-basic-annotation%2F</url>
    <content type="text"><![CDATA[Java注解注解自JDK1.5开始被引入，广泛用于应用程序代码中，尤其是Spring中大量使用注解，也促进了注解的流行。 什么是注解？形式上看有点像注释，但注解在程序运行期也可以起到作用，更多时起到标识的作用。从代码角度来看，注解是和类、接口并列的概念，但它不能独立存在，需要依附于类、方法或者属性。 常见注解 注解 提供方 作用 @Override JDK 子类的方法是覆盖父类的方法 @Deprecated JDK 过时的方法，编译器在编译时会给出警告 @SuppressWarnings JDK 去除编译器的警告信息 @Autowired Spring 自动注入Bean @Component Spring 声明Bean交给Spring的Ioc容器管理 @Service/@Controller/@Repository Spring @Component的细分 @SpringBootApplication SpringBoot 多个注解的组合 注解就像class 定义类，interface 定义接口一样， @interface 用来定义注解。 我们先来看一下@Override的定义，其中@Target和@Retention是用来定义注解的注解，一般成为元注解。 @Target(ElementType.METHOD)@Retention(RetentionPolicy.SOURCE)public @interface Override &#123;&#125; 元注解四个常用的元注解是：@Target、@Retention、@Inherited和@Documented @Target 注解的作用域，就是注解可以加在哪里，可以多选，形如{ElementType.METHOD, ElementType.FIELD} 。 ElementType.TYPE - 注解加到类或者接口上 ElementType.FIELD - 注解加到类的成员变量上 ElementType.METHOD - 注解加到类的成员方法上 ElementType.CONSTRUCTOR - 注解加到类的构造函数上 ElementType.PARAMETER - 注解加到方法的参数上 @Retention 注解的生命周期，就是在什么时候起作用，或者说注解会被带到哪个阶段。 RetentionPolicy.SOURCE - 只在源代码中起作用 RetentionPolicy.CLASS - 保留到.class文件中 RetentionPolicy.RUNTIME - 在运行期仍然起作用（通常我们都用这个） @Inherited 添加@Inherited元注解说明这个注解可以被子类继承。 @Documented 添加@Documented元注解说明可以被JavaDoc文档化。 上述四个元注解中最常用的是@Target和@Retention。 属性注解可以拥有属性，虽然下面@Component注解中的value()写法看上去像是一个方法，但实际上它是一个属性，value()里面不允许有参数。注解可以拥有多个属性，可以通过default 给属性设置默认值。 @Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface Component &#123; String value() default "";&#125; 使用以@Component注解为例，@Target声明为ElementType.TYPE，说明注解的作用域在类上。属性可以在()里面根据属性名进行设置，如果不设置使用default值。 @Component(value="user")public class User &#123; &#125; 注意：value是一个特殊属性，value是注解的默认属性，如果只有一个属性并且是value，那么可以写成这样 @Component("user")public class User &#123; &#125; 这里没有指定属性名，就使用默认的属性名value。 自定义注解相信大家对于使用JDK和Spring提供的常见注解都不陌生，下面看看如何自定义注解并使用。 下面以实体类对象为例，我们定义两个注解@Table和@Column。 @Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)public @interface Table &#123; String name() default "";&#125; @Target(ElementType.FIELD)@Retention(RetentionPolicy.RUNTIME)public @interface Column &#123; String name() default "";&#125; 我们定义@Table注解作用域在类上，@Column注解作用域在类的成员变量上，都有一个name属性。我们再来定义一个User实体类，与user表对应，这里省略了get/set方法。 @Table(name = "user")public class User &#123; @Column(name = "user_id") private Long userId; @Column(name = "user_name") private String userName; @Column(name = "user_mobile") private String userMobile;&#125; 反射读取注解示例下面我们看一下自定义的注解如何起作用。我们通过自定义注解自动拼接SQL查询语句，如果字段值不为null就作为查询条件。 protected String query(Object object) throws IllegalAccessException &#123; StringBuffer buffer = new StringBuffer(); Class clazz = object.getClass(); // 判断object对象的类是否定义了@Table注解 if(!clazz.isAnnotationPresent(Table.class)) &#123; return null; &#125; // 读取@Table注解信息 Table annotationTable = (Table)clazz.getAnnotation(Table.class); buffer.append("select * from "); buffer.append(annotationTable.name()); buffer.append(" where 1=1"); // 反射读取类的全部成员变量 Field[] fieldList = clazz.getDeclaredFields(); for (int i=0; i&lt;fieldList.length; i++) &#123; Field field = fieldList[i]; // 设置可访问非公有成员变量 field.setAccessible(true); Object value = field.get(object); // 跳过未赋值的成员变量 if (null == value) &#123; continue; &#125; // 检查成员变量是否声明了@Column注解 if (!field.isAnnotationPresent(Column.class)) &#123; continue; &#125; // 读取@Column注解信息 Column annotationColumn = (Column)field.getAnnotation(Column.class); buffer.append(" and "); buffer.append(annotationColumn.name()); buffer.append("="); if (value instanceof String) &#123; buffer.append("'"); buffer.append(value); buffer.append("'"); &#125; else &#123; buffer.append(value); &#125; &#125; // 返回拼接的SQL查询语句 return buffer.toString();&#125; 我们做如下测试 User user = new User();user.setUserId(1001L);user.setUserName("test");System.out.println(query(user)); 输出结果为 select * from user where 1=1 and user_id=1001 and user_name='test' Spring读取注解示例实战中我们往往使用Spring的IoC容器来管理类对象，我们再来看看如何在Spring中如何读取到注解信息。 首先，User类需要增加@Component注解，加入到Spring的IoC容器中进行管理 @Table(name = "user")@Component("user")public class User &#123; @Column(name = "user_id") private Long userId; @Column(name = "user_name") private String userName; @Column(name = "user_mobile") private String userMobile;&#125; ApplicationContextAware第一种方法，实现ApplicationContextAware接口。 @Configurationpublic class MybatisAutoConfiguration implements ApplicationContextAware &#123; protected ApplicationContext context; @Override public void setApplicationContext(ApplicationContext context) throws BeansException &#123; this.context = context; &#125; @PostConstruct public void init() throws Exception &#123; Map&lt;String, Object&gt; beans = context.getBeansWithAnnotation(Table.class); if (beans.size() &gt; 0) &#123; for (Map.Entry&lt;String, Object&gt; entry : beans.entrySet()) &#123; String beanName = entry.getKey(); Object object = entry.getValue(); Table annotationTable = context.findAnnotationOnBean(beanName, Table.class); String tableName = annotationTable.name(); System.out.println("tableName=" + tableName); &#125; &#125; &#125; 核心是调用容器context的getBeansWithAnnotation()方法获取所有声明了@Table注解的Bean对象，然后再调用context的findAnnotationOnBean()方法读取@Table注解信息。 BeanPostProcessor第二种方法，实现BeanPostProcessor接口。 上面的方法虽然也能实现，但最正统的应该是实现BeanPostProcessor接口，它保证在每个Bean创建完成后给我们一个定制化处理的机会。 TODO：使用ApplicationContextAware需要保证执行@PostConstruct时所有对象都已经创建完毕，否则就可能出现遗漏的情况。实战过程中还没有出现过遗漏的情况，原因不清楚。 @Configurationpublic class BeanPostConfiguration implements BeanPostProcessor &#123; @Override public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123; return bean; &#125; @Override public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123; Class clazz = bean.getClass(); if(!clazz.isAnnotationPresent(Table.class)) &#123; return bean; &#125; Table annotationTable = (Table)clazz.getAnnotation(Table.class); System.out.println(annotationTable.name()); return bean; &#125;&#125; 在IoC容器实例化每一个Bean对象以后都会调用postProcessAfterInitialization()方法，所以在这里增加对注解的处理是合适的。引申开来，我们甚至可以进行定制化修改，不返回bean对象，返回其他定制化对象。]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>注解</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java基础-反射]]></title>
    <url>%2F2018%2F05%2F28%2Fjava-basic-reflect%2F</url>
    <content type="text"><![CDATA[Java反射机制什么是反射？反射是Java语言的一种特性，通过反射机制，应用程序可以在运行期动态读取类信息，并访问类实例、类成员方法和类成员变量。 所谓反射，个人理解就是反向映射，反向自然是和正向相对的。所谓正向指在编译期就知道类的内部结构；所谓反向指在编译期不知道类的内部结构，在运行期动态加载类以后才知道类的内部结构是怎么样的。编译器不知道也无需知道实现类的内部细节，也就意味着解耦合。通常我们在应用程序中声明接口，运行时利用反射机制动态加载实现类，这样就实现了应用程序和具体实现类的解耦，当具体实现类的实现细节发生改变，甚至改变了实现类时，应用程序本身都不需要进行调整。 反射非常非常重要，反射是Spring IoC和AOP的基础，也可以说反射是Spring框架的基础。IoC容器需要使用反射API来创建Bean对象，AOP中需要通过反射加载生成的代理类。 类对象我们先来澄清一些概念： public class User {} 我们称之为一个类，User类； private String name; 我们称之为类的成员变量，name是User类的私有成员变量； public String getName() {} 我们称之为类的成员方法，getName()是User类的公有成员方法； User user = new User(); 我们称之为创建了一个类实例对象，user对象是User类的一个实例对象。 package org.test;public class User &#123; private String name; public String getName() &#123; return name; &#125;&#125; User user = new User(); 我们知道user是User类的一个实例对象，那么什么是类对象呢？调用user对象的getClass()方法就返回一个类对象。注意：user是类实例对象，clazz是类对象，它们有什么区别呢？ 首先，user是User类的实例化，user对象的堆内存空间是User类的结构，里面保存name等属性；clazz是Class类的实例化，clazz对象的堆内存空间是Class类的接口，里面保存类名、类加载器、属性、方法等信息； 每个类被JVM加载到内存后，都有对应的Class类对象，类对象的数据结构是相同，但属性值不同；每个类被JVM加载到内存后，也会生成类的实例对象，类的实例对象的数据结构是互不相同的； Class clazz = user.getClass(); 我们有三种方法来获取一个类的类对象，最后一种就是通过反射获取到类对象，它是以后所有反射操作的基础。 User user = new User();Class c1 = User.class;Class c2 = user.getClass();Class c3 = Class.forName("org.test.User"); TODO：以下挪到JVM-类加载器中 我们知道在JVM规范中，User类信息存储方法区（method area）上，我们常用的Hotspot虚拟机把User类信息存储在堆的永久代上。User类对象在堆上创建，User类对象信息自然存储在堆上。user变量是对User类对象的应用，user变量存储在栈上。 user变量是一个引用，指向User类实例对象；User类实例对象的数据结构就是User类的数据结构；那么User类信息在永久代上具体是如何存储的呢？我们可以认为，永久代上存储的也是一个类对象，Class类的对象。 package java.lang;public final class Class&lt;T&gt; &#123; private transient String name; private final ClassLoader classLoader; &#125; 我们再来看一下User user = new User(); 的执行过程： 编译User.java生成User.class文件； JVM使用类加载器读取User.class文件，生成一个Class对象，放入永久代堆； JVM根据Class对象中的信息创建一个User类的实例对象，放入堆中； JVM在当前栈中添加user变量，指向堆中User类实例对象。 啰嗦这么多就是想说：这就是正向创建对象的过程，加载Class类信息的操作由JVM完成，对应用程序是透明的。那什么是反射呢？个人理解就是应用程序手动来完成原本JVM自动完成的那些操作。 下面看一个例子 User user = new User();Class c1 = User.class;Class c2 = user.getClass();Class c3 = Class.forName("org.test.User");System.out.println(c1.hashCode());System.out.println(c2.hashCode());System.out.println(c3.hashCode()); 运行后返回的hashCode是一样的，说明三个Class类对象是一个对象。也就是说：使用反射方法得到的类对象c3和JVM正常加载User类得到的c1和c2都指向同一个类对象。 动态加载还是上面的例子，c1和c2在编译时就需要加载User类，这称为静态加载。c3在编译时不需要加载User类，在运行时加载User类，这称为动态加载。从类加载的角度说，反射最重要的特性就是实现了运行时类的动态加载。 TODO：以上挪到JVM-类加载器中 反射的使用简单说，反射机制就是Java为应用程序提供了在程序运行期间获取类对象并对其进行操作的能力。 反射主要涉及到以下几个类：Class、Method、Field。 Class得到类对象信息后我们就可以动态创建类实例对象了，常见有两种方法。 Class.newInstance() newInstance()相当于执行不带参数的默认构造函数 User类可以不声明任何构造函数，也可以声明默认构造函数public User() {}，但是不能只声明带参数的构造函数；例如：如果声明public User(String name) ，那么newInstance()找不到合适的构造函数将抛出异常 import org.test;public class User &#123; private String name;&#125; Class clazz = Class.forName("org.test.User");User user = (User) clazz.newInstance(); Constructor.newInstance() 上面的方法是不能带参数的，如果需要执行带参数的构造函数，需要调用Constructor.newInstance() 先调用Class类的getConstructor()方法获取构造函数Constructor 然后再调用Constructor类的newInstance()方法并传入参数 import org.test;public class User &#123; private String name; public User(String name) &#123; this.name = name; &#125;&#125; Class clazz = Class.forName("org.test.User");Constructor constructor = clazz.getConstructor(String.class);User user = (User) constructor.newInstance("test"); 上面例子中如果User类构造函数声明为private，那么getConstructor()时将抛出NoSuchMethodException异常，怎么办？可以将getConstructor()替换为getDeclaredConstructor()，前者只能获取到public的构造函数，后者可以获取到User类声明的所有构造函数。 Class clazz = Class.forName("org.test.User");Constructor constructor = clazz.getDeclaredConstructor(String.class);User user = (User) constructor.newInstance("test"); 运行之后发现还不行，抛出IllegalAccessException异常，怎么办？通过getDeclaredConstructor()我们可以得到私有构造方法了，但是没有private方法的执行权限，需要调用setAccessible()方法设置权限。 Class clazz = Class.forName("org.test.User");Constructor constructor = clazz.getDeclaredConstructor(String.class);constructor.setAccessible(true);User user = (User) constructor.newInstance("test"); getXXX()可以获得public的方法，包括继承的方法；getDeclaredXXX()可以获得所有方法，但是只能获得自己声明的方法，不能获得继承的方法。 Method从Class中可以获取类的成员方法Method，调用Method类的invoke()方法可以执行成员方法。 import org.test;public class User &#123; private String name; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; &#125; Class clazz = Class.forName("org.test.User");Constructor constructor = clazz.getDeclaredConstructor();constructor.setAccessible(true);User user = (User) constructor.newInstance();Method method = clazz.getMethod("setName", String.class);method.invoke(user, "test");method = clazz.getMethod("getName", null);String name = (String) method.invoke(user); 同样的，如果需要访问私有方法，可以将getMethod()替换为getDeclaredMethod()并在执行invoke()方法前setAccessible(true)。 Method method = clazz.getDeclaredMethod("setName", String.class);method.setAccessible(true);method.invoke(user, "test"); Field从Class中可以获取类的成员变量Field，调用Field类的get()和set()方法可以访问成员变量。通过Field即使没有提供get()和set()方法，我们也可以直接访问User类的私有成员变量name进行赋值。 import org.test;public class User &#123; private String name;&#125; clazz = Class.forName("org.test.User");Constructor constructor = clazz.getDeclaredConstructor();constructor.setAccessible(true);User user = (User) constructor.newInstance();Field field = clazz.getDeclaredField("name");field.setAccessible(true);field.set(user, "test");String name = (String) field.get(user); PropertyDescriptor由于通常我们使用的Bean对象都会定义get()和set()方法，Java为我们提供了PropertyDescriptor类来简化操作。 new PropertyDescriptor() 时传入属性名称； getReadMethod(); 返回get()方法； getWriteMethod(); 返回set()方法。 PropertyDescriptor descriptor = new PropertyDescriptor("name", clazz);Method method = descriptor.getWriteMethod();method.setAccessible(true);method.invoke(user, "test");String name = (String)descriptor.getReadMethod().invoke(user);System.out.println(name); 反射包最后，我们罗列一下反射相关的重要类和方法。 java.lang.Class 方法 作用 forName() 动态加载类并返回类对象 getName() 获取类的名字 getSuperclass() 获取基类 getInterfaces() 获取类实例对象实现的接口类 getConstructors() 获取所有公有构造函数，包括父类的构造函数 getMethods() 获取所有公有成员方法，包括父类的成员方法 getFields() 获取所有公有成员变量，包括父类的成员变量 getDeclaredConstructors() 获取所有构造函数，不包括父类的构造函数 getDeclaredMethods() 获取所有成员方法，不包括父类的成员方法 getDeclaredFields() 获取所有成员变量，不包括父类的成员变量 getConstructor() 获取指定公有构造函数，包括父类的构造函数 getMethod() 获取指定公有成员方法，包括父类的成员方法 getField() 获取指定公有成员变量，包括父类的成员变量 getDeclaredConstructor() 获取指定构造函数，不包括父类的构造函数 getDeclaredMethod() 获取指定成员方法，不包括父类的成员方法 getDeclaredField() 获取指定成员变量，不包括父类的成员变量 isAnnotationPresent() 类上是否声明了指定注解 getAnnotations() 获取类上声明的所有注解 getAnnotation() 获取类上声明的指定注解 java.lang.reflect.Constructor 方法 作用 T newInstance(Object … initargs) 执行构造函数创建类的实例对象 java.lang.reflect.Method 方法 作用 Object invoke(Object obj, Object… args) 执行方法，传入类实例对象和参数 java.lang.reflect.Field 方法 作用 Object get(Object obj) 读取属性值，传入类实例对象 void set(Object obj, Object value) 设置属性值，传入类实例对象和新值 java.lang.reflect.InvocationHandlerpublic interface InvocationHandler &#123; // 执行代理方法的入口 public Object invoke(Object proxy, Method method, Object[] args) throws Throwable;&#125; java.lang.reflect.Proxypublic class Proxy implements java.io.Serializable &#123; // 动态生成代理类实例对象 public static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) &#123; &#125; &#125;]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>反射</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring-AOP]]></title>
    <url>%2F2018%2F05%2F27%2Fspring-aop%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Spring-IoC]]></title>
    <url>%2F2018%2F05%2F22%2Fspring-ioc%2F</url>
    <content type="text"><![CDATA[IoC概述IoC（Inversion of Control），顾名思义控制反转，什么是控制反转呢？这里的控制指对象的控制权，包括对象的创建和销毁等操作，控制反转就是对象的创建和销毁本来应该由应用程序自己控制的，现在应用程序把对象的控制权交给了Spring容器来管理，这就是控制反转。 个人理解：Spring容器成为Bean对象的代理或中介。 经常与Ioc一起出现的还有DI（Dependency Injection）依赖注入。依赖注入的意思是应用程序需要的对象是依赖于Spring容器注入的，不是自己创建的。看上去和IoC是一个意思，个人理解DI是具体实现IoC的一种方法，通过依赖Spring容器注入对象的方式实现了应用程序把对象的控制权转交给了Spring容器。 如果用租房来比喻，常规方式就是租户自己联系房东租房，IoC就是租户把找房子这件事代理给中介来完成，DI就是中介会帮租户找好房子，租户直接入住就好。（IoC还有可能是中介帮租户联系房东，租户一个一个看房，DI就是租户完全授权给中介，中介直接帮他定一个）。 面向接口编程自己管理对象不是很好吗，为什么要使用IoC，把控制权交给Spring容器呢？ 我理解，目的当然是解耦合。对象由Spring容器管理意味着应用程序不必依赖固定的Bean对象，就像租房只要找到满足条件的房子即可，不必非要指定一套房子，这就是解耦合。因此可以得出结论：面向接口编程是IoC的基础，如果应用程序声明注入是实体类，那么还是强耦合的；所以通常应用程序声明注入的都是接口，这才能发挥Spring IoC的作用。 例如：注入UserService接口后可以方便的切换实现类以实现不同的目标。 public interface UserService &#123;&#125;@Componentpublic class UserServiceMemoryImpl implements UserService &#123;&#125;// @Componentpublic class UserServiceDatabaseImpl implements UserService &#123;&#125; 应用程序使用时声明注入的是接口，具体实现可以通过打开和关闭@Component注解切换 @AutowiredUserService userService; 注入Bean通常有两种方式：byType和byName，按照类型注入或者按照名字注入。按照类型注入是典型的面向接口编程思想，byType时一般class类型为接口，容器负责查找实现了接口的Bean对象。 IoC使用Bean配置既然Spring容器负责管理类对象，那么它就得知道哪些类对象需要被管理。随着Spring的发展，配置bean对象的方法也在变化，可以使用XML配置文件，也可以使用注解或者JavaConfig，下面我们就来看一下配置方式的进化过程。 XML配置把需要创建的对象（Spring称之为Bean）定义在一个xml文件里面，每个bean指定ID和对应类。IoC容器读取这个xml文件，通过反射创建类对象，通过ID返回类对象。Bean里面可以通过property属性显式定义bean的依赖，也可以不定义，让Spring完成自动配置。 例如：配置/resources/spring-context.xml如下：定义了car和wheel两个bean，car依赖wheel &lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans&gt; &lt;bean id="car" class="cn.lu.spring.ioc.Car" scope="singleton"&gt; &lt;!--constructor-arg ref="wheel" /--&gt; &lt;property name="wheel" ref="wheel" /&gt; &lt;/bean&gt; &lt;bean id="wheel" class="cn.lu.spring.ioc.Wheel"/&gt;&lt;/beans&gt; Bean对象如下： public class Car &#123; private Wheel wheel; public void setWheel(Wheel wheel) &#123; this.wheel = wheel; &#125;&#125;public class Wheel &#123;&#125; 注意：这里Car类必须实现setWheel()方法。 使用如下： ApplicationContext类可以理解为IoC容器，ClassPathXmlApplicationContext类是从classpath目录读取XML文件来解析Bean的IoC容器实现； 调用容器类的getBean()方法就可以从容器中获取Bean对象了，传入的参数可以是ID，也可以是类名； Bean对象之间的依赖关系可以在XML中定义bean时通过property属性设置，相当于调用set方法，也可以使用constructor-arg设置，相当于在构造函数中传入依赖对象。 @RunWith(BlockJUnit4ClassRunner.class)public class IoCTest &#123; private ApplicationContext context; @Before public void before() &#123; context = new ClassPathXmlApplicationContext("classpath:spring-context.xml"); &#125; @Test public void testContext() &#123; Car car = (Car)context.getBean("car"); // Car car = context.getBean(Car.class); &#125;&#125; 以上这种用法非常好理解，ApplicationContext类读取XML文件并构造Bean对象，通过getBean()返回对象，ApplicationContext类就是IoC容器。容器需要做的就是解析XML文件，通过反射构造对象。 以上方法实际上没有实现依赖注入，需要自己主动获取。 注解配置如上所述，我们需要把所有用到的bean对象都定义在xml文件中，xml文件将越来越庞大。Spring 2.5以后出现了注解方式，使用注解意味着将集中的bean配置（xml文件）分散到各个bean对象中。个人觉得没有两种用法没有好坏之分。 注解@Component注解起到XML文件中&lt;bean/&gt; 一样的作用，下面两种写法是等同的。 @Component("car")public class Car &#123;&#125; &lt;bean id="car" class="Car"/&gt; @Component注解的value属性等同于bean的id属性，@Component的value默认值为首字母小写的类名，一般可以省略。从@Component又衍生出@Controller、@Service和@Repository注解，用在不同层，本质是一样的。 @Autowired/@Resource注解起到XML文件中&lt;bean.property&gt;和&lt;bean.constructor-arg&gt;的作用，@Autowired注解可以修饰类的成员变量，也可以修饰类的构造函数和成员方法。 @Autowired和@Resource的区别： @Autowired默认通过bean的类型注入； @Resource默认通过bean的名字注入。 引入@Autowired注解后真正实现了依赖注入，当我们需要使用一个对象时，直接将其声明为@Autowired，容器负责帮我们构造这个对象的实例。@Autowired注解默认是按照类型构造的，也就是说容器负责查找实现类并通过反射进行构造，所以通常@Autowired注解修饰的是接口。 进一步思考一下，如果一个@Autowired注解修饰的接口有多个实现类，那么容器就不知道应该构造哪个类了，怎么办？这个时候我们可以增加@Qualifier注解来指定bean的名称。下面以UserService为例，有UserServiceMemoryImpl和UserServiceDatabaseImpl两个实现类，实现选择数据库实现，代码如下： @Autowired@Qualifier("userServiceDatabaseImpl")UserService userService; 因为@Component默认bean名称为首字母小写的类名，所以可以使用userServiceDatabaseImpl，如果UserServiceDatabaseImpl在@Component中自定义了bean名称，那么要使用自定义的。 例子引入注解后需要增加一个新的配置，就是到哪里去查找注解，所以使用注解后的xml配置文件如下： &lt;beans&gt; &lt;context:component-scan base-package="cn.lu.spring.ioc" /&gt;&lt;/beans&gt; Bean对象如下： @Componentpublic class Car &#123; @Autowired private Wheel wheel;&#125;@Componentpublic class Wheel &#123;&#125; 注意：这里Car类不用实现setWheel()方法就可以注入wheel，这和反射的实现有关。 使用如下：我们通过@Autowired注解直接注入Car对象，这才是真正的依赖注入。 @RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations = &#123;"spring-context.xml"&#125;)public class IoCTest &#123; private Logger logger = LoggerFactory.getLogger(this.getClass()); @Autowired private Car car; @Test public void testAnnotation() &#123; logger.info(car.toString()); &#125;&#125; 注意：这里我们没有显式创建ApplicationContext，是 @Runwith(SpringJUnit4ClassRunner.class)和@ContextConfiguration起了相同的作用。 Java配置从Spring 3.0开始提供了Java Config也叫做Java配置，Spring Boot建议使用Java配置替代XML配置。 Java配置引入了@Configuration、@Bean、@ImportResource和@Value等注解。 @Configuration注解就相当于一个xml文件，@Bean注解就相当于xml文件中的一个&lt;bean/&gt; ，@ComponentScan注解相当于xml文件中的&lt;context:component-scan /&gt; 。 例如：Java配置 @Configurationpublic class Config &#123; @Bean public Wheel wheel() &#123; return new Wheel(); &#125; @Bean public Car car(Wheel wheel) &#123; Car car = new Car(); car.setWheel(wheel); return car; &#125;&#125; 等同于如下xml配置 &lt;beans&gt; &lt;bean id="wheel" class="cn.lu.spring.ioc.Wheel"/&gt; &lt;bean id="car" class="cn.lu.spring.ioc.Car"&gt; &lt;property name="wheel" ref="wheel" /&gt; &lt;/bean&gt;&lt;/beans&gt; 使用时和前面基本一样，只需要把@ContextConfiguration配置的xml文件替换为class类 @RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(classes = &#123;Config.class&#125;)public class IoCTestWithJavaConfig &#123;&#125; 选择现在我们有三种方法定义一个Bean，选择哪一个呢？ &lt;bean id="car" class="cn.lu.spring.ioc.Car"/&gt; // @Componentpublic class Car &#123;&#125; @Configurationpublic class JavaConfiguratoin &#123; @Bean public Car car() &#123; return new Car(); &#125; &#125; 习惯上，我们使用第二种方法@Component注解（实际更多使用@Controller、@Service等注解）来配置我们的业务Bean，XML不再使用，Java配置用来完成非业务Bean的配置。 个人理解：@Component注解是侵入式的，XML和Java配置是不需要侵入源代码的，这是他们的优势。 SpringBoot下面看看在SpringBoot中如何使用IoC管理Bean对象。 @SpringBootApplicationpublic class ServiceDemoApplication &#123;&#125; @Controllerpublic class UserController &#123; @Autowired UserService userService;&#125; @Servicepublic class UserServiceImpl implements UserService &#123;&#125; 上面的例子代码展示了最常见的用法： Spring容器扫描到@Service注解后创建UserServiceImpl类实例对象； Spring容器扫描到@Controller注解后创建UserController类实例对象； Spring容器扫描到@Autowired注解后将UserServiceImpl类实例对象注入到UserController类实例对象的userService属性中。 上面过程很好理解，但仔细一想你会发现代码中没有出现@ComponentScan注解，Spring容器怎么知道去哪里扫描注解呢？还有，容器类ApplicationContext是如何创建的呢？ @SpringBootApplication问题的答案就在@SpringBootApplication注解中。 @Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@SpringBootConfiguration@EnableAutoConfiguration@ComponentScan(excludeFilters = &#123; @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class), @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) &#125;)public @interface SpringBootApplication &#123;&#125; @Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Configurationpublic @interface SpringBootConfiguration &#123;&#125; @SpringBootApplication注解组合了@Configuration、@ComponentScan和@EnableAutoConfiguration三个最重要的注解，所以拥有了它们的功能。 我们知道一个@Configuration类文件对应一个XML配置文件，所以当Spring扫描到@Configuration注解后就会创建ApplicationContext容器类，并扫描@Component注解创建Bean对象放入容器类中。 @ComponentScan注解默认扫描当前包及其子目录下的源代码，所以Application类通常都是放在包的最外层，这样才可以保证web/service等目录下的注解可以被扫描到。 例如：新建应用在com.test.demo包下，引用的common项目在com.test.common包下，那么common项目中的@Component等注解是不生效的，因为Spring没有扫描它们。如果希望common包下的注解也生效，需要显式配置scanBasePackages，样例代码如下： @SpringBootApplication(scanBasePackages = &#123;"com.test.demo", "com.test.common"&#125;)public class DemoApplication &#123;&#125; @EnableAutoConfiguration是SpringBoot特性，和IoC无关，这里不展开。 高级使用前面介绍了IoC的最基本用法，帮助我们的应用程序创建类实例对象，下面看看其他用法。 初始化实际开发中，有时需要在Bean对象创建后和销毁前做一些操作，可以使用下面两个注解： @PostConstruct，在构造函数完成之后执行； @PreDestroy，在析构函数执行之前执行； 除了使用@PostConstruct注解，还可以实现InitializingBean接口和afterPropertiesSet()方法。 @Controllerpublic class UserController implements InitializingBean &#123; public UserController() &#123; System.out.println("UserController()"); &#125; @PostConstruct public void postConstruct() &#123; System.out.println("UserController @PostConstruct"); &#125; @PreDestroy public void preDestroy() &#123; System.out.println("UserController @PreDestroy"); &#125; @Override public void afterPropertiesSet() throws Exception &#123; System.out.println("UserController afterPropertiesSet"); &#125;&#125; 上面代码的输出日志顺序为： UserController()UserController @PostConstructUserController afterPropertiesSetUserController @PreDestroy @Scope常用的Scope有两种：Singleton和Prototyp，默认是Singleton： Singleton，一个容器只创建一个Bean实例，每次getBean()都返回相同的实例； Prototyp，每次getBean()都新创建一个Bean实例； Session，每个HTTP Session创建一个Bean实例。 注意：Singleton强调一个容器只有一个Bean实例，不同容器可以有不同Bean实例。 @Profile@Profile注解为我们提供了在不同环境下创建不同Bean实例的能力。 一般用在配置类中，例如：生产环境MySQL和Redis需要使用集群配置，开发和测试环境使用单点配置就好了，这两种情况下的配置可能是不同的，这个时候@Profile就派上用场了。 @Configurationpublic class DatabaseConfig &#123; @Bean @Profile("dev") public DataSource getDevDataSource() &#123; return new DevDataSource(); &#125; @Bean @Profile("prod") public DataSource getProdDataSource() &#123; return new ProdDataSource(); &#125;&#125; @AutowiredDataSource dataSource; DataSource是接口，DevDataSource和ProdDataSource是具体实现，根据运行环境的不同返回不同的实现。运行环境通过配置application.properties切换。 spring.profiles.active=dev @Value使用@Value注解可以注入属性值，最常见的是从application.properties中读取配置。 @Componentpublic class Book &#123; @Value("$&#123;book.name&#125;") private String bookName;&#125; @Value(&quot;${book.name}&quot;) 表示读取配置文件中book.name 的值，application.properties配置如下： book.name=Spring 不要忘了@Component注解，只有Spring容器管理的Bean才可以使用@Value注解。 使用@Value注解还可以读取其他Bean的属性 ，例如：以下代码从company这个Bean中读取name字段并赋值到Book的bookPub字段，和前面的区别是$换成了# 。 @Componentpublic class Book &#123; @Value("#&#123;company.name&#125;") private String bookPub;&#125; @ImportResource使用@ImportResource注解可以直接导入xml配置文件，这是从xml配置到java配置过渡的最简单方案。 @Configuration@ImportResource(locations=&#123;"classpath:applicationContext.xml"&#125;)public class XmlConfiguration &#123;&#125; ApplicationContextAware有时候我们需要读取容器中的其他类实例对象，例如：自定义注解后，需要扫描注解来实现自定义逻辑。以下以RocketMQ自定义的@RocketMQProduer注解为例： 实现ApplicationContextAware接口的setApplicationContext()方法获得容器； 在构造函数完成后调用ApplicationContext的getBeansWithAnnotation()方法获得所有声明了@RocketMQProducer注解的类实例对象。 public class MQProducerAutoConfiguration implements ApplicationContextAware &#123; protected ApplicationContext applicationContext; @Override public void setApplicationContext(ApplicationContext applicationContext) &#123; this.applicationContext = applicationContext; &#125; @PostConstruct public void init() throws Exception &#123; Map&lt;String, Object&gt; beans = null; beans = applicationContext.getBeansWithAnnotation(RocketMQProducer.class); &#125;&#125; BeanPostProcessorBeanFactoryPostProcessorIoC原理Tomcat应用的IoC容器早期Spring经常和Tomcat一起使用，使用的是XML配置，但我们并没有像前面例子代码那样显式调用new ClassPathXmlApplicationContext() ，那么Tomcat是如何创建Spring的IoC容器的呢？ 答案就在webapp/WEB-INF/web.xml中，关键点就是ContextLoaderListener &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt;&lt;/listener&gt; Tomcat中使用的是ApplicationContext的另外一个子类WebApplicationContext，ContextLoaderListener是Tomcat的一个ServletContext，当它初始化的时候创建WebApplicationContext容器类。 package org.springframework.web.context;import javax.servlet.ServletContextListener;public class ContextLoaderListener extends ContextLoader implements ServletContextListener &#123; public void contextInitialized(ServletContextEvent event) &#123; this.initWebApplicationContext(event.getServletContext()); &#125; public void contextDestroyed(ServletContextEvent event) &#123; this.closeWebApplicationContext(event.getServletContext()); ContextCleanupListener.cleanupAttributes(event.getServletContext()); &#125;&#125; 当Servelt容器启动时触发contextInitialized()方法，它执行基类ContextLoader的方法来构造容器 package org.springframework.web.context;public class ContextLoader &#123; private WebApplicationContext context; public WebApplicationContext initWebApplicationContext(ServletContext servletContext) &#123; if(this.context == null) &#123; this.context = this.createWebApplicationContext(servletContext); &#125; return this.context; &#125;&#125; 这里可以看到最终调用createWebApplicationContext()方法返回WebApplicationContext类实例对象，这就是Tomcat中的IoC容器。后面的操作大家都了解了，WebApplicationContext容器负责管理Bean对象。 SpringBoot应用的IoC容器我们再来看看目前流行的SpringBoot是如何创建Spring的IoC容器的。 SpringBoot其实更好理解一点，我们从程序入口开始看 @SpringBootApplicationpublic class SpringbootApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringbootApplication.class, args); &#125;&#125; 入口是SpringApplication的run()方法 package org.springframework.boot;public class SpringApplication &#123; public ConfigurableApplicationContext run(String... args) &#123; ConfigurableApplicationContext context = null; context = this.createApplicationContext(); this.refreshContext(context); return context; &#125;&#125; 这里只截取了和IoC相关代码，可以看到run()方法中创建了context容器，并调用refreshContext()方法加载Bean对象。 package org.springframework.boot;public class SpringApplication &#123; private boolean webEnvironment; protected ConfigurableApplicationContext createApplicationContext() &#123; Class&lt;?&gt; contextClass = this.applicationContextClass; if(contextClass == null) &#123; if (this.webEnvironment) &#123; contextClass = Class.forName("AnnotationConfigEmbeddedWebApplicationContext"); &#125; else &#123; contextClass = Class.forName("AnnotationConfigApplicationContext"); &#125; &#125; return (ConfigurableApplicationContext)BeanUtils.instantiate(contextClass); &#125;&#125; 类名太长，这里省略了包名。 由于我们大部分是web应用，所以使用的是AnnotationConfigEmbeddedWebApplicationContext，从名字上可以看出，这个ApplicationContext（容器）是基于注解创建的，支持嵌入式web应用。 Spring IoC源码分析入口是AbstractApplicationContext的refresh()方法，我们从这里开始。 package org.springframework.context.support;public abstract class AbstractApplicationContext &#123; public void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; // 创建BeanFactory ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // Allows post-processing of the bean factory in context subclasses. postProcessBeanFactory(beanFactory); // Invoke factory processors registered as beans in the context. invokeBeanFactoryPostProcessors(beanFactory); // Register bean processors that intercept bean creation. registerBeanPostProcessors(beanFactory); // 实例化Bean finishBeanFactoryInitialization(beanFactory); &#125; &#125;&#125; 最重要的两个方法是obtainFreshBeanFactory()和finishBeanFactoryInitialization()，前者读取Bean相关配置信息，后者创建Bean实例。 package org.springframework.context.support;public abstract class AbstractApplicationContext &#123; protected ConfigurableListableBeanFactory obtainFreshBeanFactory() &#123; refreshBeanFactory(); return this.beanFactory; &#125;&#125; package org.springframework.context.support;public abstract class AbstractRefreshableApplicationContext extends AbstractApplicationContext &#123; @Override protected final void refreshBeanFactory() throws BeansException &#123; DefaultListableBeanFactory beanFactory = createBeanFactory(); loadBeanDefinitions(beanFactory); synchronized (this.beanFactoryMonitor) &#123; this.beanFactory = beanFactory; &#125; &#125;&#125; package org.springframework.beans.factory.support;public class DefaultListableBeanFactory extends AbstractBeanFactory &#123; private final Map&lt;String, BeanDefinition&gt; beanDefinitionMap = new ConcurrentHashMap&lt;String, BeanDefinition&gt;(256);&#125; 以XML配置为例，AbstractApplicationContext类的子类AbstractXmlApplicationContext实现了loadBeanDefinitions()方法，完成加载和解析XML文件的操作，并将BeanDefinition信息放入到BeanFactory中。其中，BeanDefinition与XML文件中的一个&lt;bean /&gt; 相对应，BeanFactory接口的默认实现类是DefaultListableBeanFactory，可以看到DefaultListableBeanFactory中使用ConcurrentHashMap来保存Bean信息。 这就完成了第一步工作，解析XML文件读取配置信息到BeanFactory的Map中保存。 接下来看看如何根据上面的信息实例化对象。 package org.springframework.context.support;public abstract class AbstractApplicationContext &#123; protected void finishBeanFactoryInitialization(ConfigurableListableBeanFactory beanFactory) &#123; // Stop using the temporary ClassLoader for type matching. beanFactory.setTempClassLoader(null); // Allow for caching all bean definition metadata, not expecting further changes. beanFactory.freezeConfiguration(); // Instantiate all remaining (non-lazy-init) singletons. beanFactory.preInstantiateSingletons(); &#125; AbstractApplicationContext调用BeanFactory的方法来实例化对象。 package org.springframework.beans.factory.support;public class DefaultListableBeanFactory extends AbstractBeanFactory &#123; @Override public void preInstantiateSingletons() throws BeansException &#123; List&lt;String&gt; beanNames = new ArrayList&lt;String&gt;(this.beanDefinitionNames); for (String beanName : beanNames) &#123; getBean(beanName); &#125; &#125; @Override public Object getBean(String name) throws BeansException &#123; return doGetBean(name, null, null, false); &#125;&#125; package org.springframework.beans.factory.support;public abstract class AbstractBeanFactory implements BeanFactory &#123; protected &lt;T&gt; T doGetBean(final String name, final Class&lt;T&gt; requiredType, final Object[] args, boolean typeCheckOnly) &#123; final RootBeanDefinition mbd = getMergedLocalBeanDefinition(beanName); if (mbd.isSingleton()) &#123; sharedInstance = getSingleton(beanName, new ObjectFactory&lt;Object&gt;() &#123; @Override public Object getObject() throws BeansException &#123; try &#123; return createBean(beanName, mbd, args); &#125; catch (BeansException ex) &#123; destroySingleton(beanName); throw ex; &#125; &#125; &#125;); bean = getObjectForBeanInstance(sharedInstance, name, beanName, mbd); &#125; else if (mbd.isPrototype()) &#123; // It's a prototype -&gt; create a new instance. Object prototypeInstance = null; try &#123; beforePrototypeCreation(beanName); prototypeInstance = createBean(beanName, mbd, args); &#125; finally &#123; afterPrototypeCreation(beanName); &#125; bean = getObjectForBeanInstance(prototypeInstance, name, beanName, mbd); &#125; return (T) bean; &#125;&#125; DefaultListableBeanFactory类的getBean()方法会调用AbstractBeanFactory类的doGetBean()方法，里面通过createBean()方法创建实例对象。 package org.springframework.beans.factory.support;public abstract class AbstractAutowireCapableBeanFactory extends AbstractBeanFactory &#123; @Override protected Object createBean(String beanName, RootBeanDefinition mbd, Object[] args) &#123; Object beanInstance = doCreateBean(beanName, mbdToUse, args); return beanInstance; &#125; protected Object doCreateBean(final String beanName, final RootBeanDefinition mbd, final Object[] args) &#123; BeanWrapper instanceWrapper = null; instanceWrapper = createBeanInstance(beanName, mbd, args); final Object bean = instanceWrapper.getWrappedInstance(); &#125; protected BeanWrapper createBeanInstance(String beanName, RootBeanDefinition mbd, Object[] args) &#123; &#125; protected BeanWrapper instantiateBean(final String beanName, final RootBeanDefinition mbd) &#123; &#125;&#125; AbstractAutowireCapableBeanFactory类的createBean()方法 package org.springframework.beans.factory.support;public class SimpleInstantiationStrategy implements InstantiationStrategy &#123; @Override public Object instantiate(RootBeanDefinition bd, String beanName, BeanFactory owner) &#123; Constructor&lt;?&gt; ctor = clazz.getDeclaredConstructor((Class[]) null); ctor.setAccessible(true); return ctor.newInstance(null); &#125;&#125; package org.springframework.beans.factory.support;public abstract class AbstractAutowireCapableBeanFactory extends AbstractBeanFactory &#123; protected void populateBean(String beanName, RootBeanDefinition mbd, BeanWrapper bw) &#123; applyPropertyValues(beanName, mbd, bw, pvs); &#125; protected void applyPropertyValues(String beanName, BeanDefinition mbd, BeanWrapper bw, PropertyValues pvs) &#123; MutablePropertyValues mpvs = null; List&lt;PropertyValue&gt; original; for (PropertyValue pv : original) &#123; &#125; bw.setPropertyValues(new MutablePropertyValues(deepCopy)); &#125;&#125; package org.springframework.beans;public class BeanWrapperImpl implements BeanWrapper &#123; private class BeanPropertyHandler extends PropertyHandler &#123; private final PropertyDescriptor pd; @Override public void setValue(final Object object, Object valueToApply) throws Exception &#123; final Method writeMethod = (this.pd instanceof GenericTypeAwarePropertyDescriptor ? ((GenericTypeAwarePropertyDescriptor) this.pd).getWriteMethodForActualAccess() : this.pd.getWriteMethod()); if (!Modifier.isPublic(writeMethod.getDeclaringClass().getModifiers()) &amp;&amp; !writeMethod.isAccessible()) &#123; if (System.getSecurityManager() != null) &#123; AccessController.doPrivileged(new PrivilegedAction&lt;Object&gt;() &#123; @Override public Object run() &#123; writeMethod.setAccessible(true); return null; &#125; &#125;); &#125; else &#123; writeMethod.setAccessible(true); &#125; &#125; final Object value = valueToApply; if (System.getSecurityManager() != null) &#123; try &#123; AccessController.doPrivileged(new PrivilegedExceptionAction&lt;Object&gt;() &#123; @Override public Object run() throws Exception &#123; writeMethod.invoke(object, value); return null; &#125; &#125;, acc); &#125; catch (PrivilegedActionException ex) &#123; throw ex.getException(); &#125; &#125; else &#123; writeMethod.invoke(getWrappedInstance(), value); &#125; &#125; &#125;&#125; Spring探秘|妙用BeanPostProcessor]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
        <tag>IoC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【置顶】Java多线程一篇就够]]></title>
    <url>%2F2018%2F05%2F21%2Fknowledge-thread%2F</url>
    <content type="text"><![CDATA[线程线程是操作系统任务调度的基本单位，Java进程至少有一个[main]线程。需要知道如何创建和启动一个线程，如何停止线程以及线程常见的属性。 启动线程public class Task extends Thread &#123; @Override public void run() &#123;&#125;&#125;new Task().start(); public class Task implements Runnable &#123; @Override public void run() &#123;&#125;&#125;Thread thread = new Thread(new Task());thread.start();thread.join(); public class Task implements Callable&lt;Integer&gt; &#123; @Override public Integer call() throws Exception &#123; return 1; &#125;&#125;FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;Integer&gt;(new Task());new Thread(futureTask).start();int value = futureTask.get(); new Thread() 只接受Runnable参数，FutureTask implements Runnable 。 FutureTask.get()方法起到和Thead.join()相同的效果，阻塞当前线程直到子线程执行完成并返回执行结果。 Thread.currentThread() 静态方法获取当前线程。 停止线程使用标志位主动退出线程，需要自己编码实现 public class Task implements Runnable &#123; private volatile boolean stop = false; @Override public void run() &#123; while (!stop) &#123;&#125; &#125;&#125; 能主动退出是最好的，但不是所有情况都可以主动退出，例如：调用了wait()方法后当前线程被阻塞，就无法判断标志位了，这个时候需要通过外部调用Thread.interrupt()方法来中断线程。 public class Task implements Runnable &#123; @Override public void run() &#123; while (true) &#123; if (Thread.currentThread().isInterrupted()) &#123; break; &#125; try &#123; // Thread.sleep(); // Object.wait(); &#125; catch (InterruptedException e) &#123; break; // Thread.currentThread().interrupt(); &#125; &#125; &#125;&#125;Thread thread = new Thread(new Task());thread.start();thread.interrupt(); 注意这种代码写法：如果线程正常执行中，那么可以判断isInterrupted()标志位；如果线程阻塞中，外部调用interrupt()方法的效果是中断阻塞操作，抛出InterruptedException异常，捕获异常后需要自己处理退出。换句话说，调用Thread.interrupt()方法后系统不会杀死这个线程，如果当前线程是running状态，系统修改isInterrupted()标志位，如果当前线程是blocked状态，系统抛出InterruptedException异常。捕获异常后，我们可以选择直接退出break ，也可以Thread.currentThread().interrupt(); 重置标志位退出。 线程属性每个线程可以设置一个名字，主线程默认名字是[main]，线程池启动线程默认名字是[pool-1-thread-1]。 线程可以设置优先级，最大MAX_PRIORITY=10，最小MIN_PRIORITY=1，默认NORM_PRIORITY=5。 通过设置daemon属性可以将一个线程设置为守护线程，与守护线程相对的是用户线程，当所有用户线程结束的时候，守护线程自动结束。GC线程是典型的守护线程，用户线程没了，GC线程也没有存在的意义了。 线程状态 如果我们输出Thread.currentThread().getState()，与上图是对不上的，下面是源码中线程状态的定义。 public enum State &#123; NEW, RUNNABLE, BLOCKED, WAITING, TIMED_WAITING, TERMINATED;&#125; getState()不区分RUNNABLE和RUNNING状态，我们只能通过日志输出NEW，RUNNABLE和TERMINATED三个状态。 线程池实战中一般不会使用new Thread().start() 来启动一个线程，通常都使用线程池。使用线程池的原因是创建和销毁线程是有开销的，所以当然就会想到线程的复用，一次创建，多次使用。同时线程池也可以保证在突发大量任务时不会因为创建大量线程耗尽系统资源。 ExecutorService线程池实现ExecutorService接口，主要有以下四个启动线程的方法： execute(Runnable)，不关注返回值，也不与启动的线程交互； submit(Runnable)，得不到返回值，但可以通过Future与启动的线程交互； submit(Runnable, T)，Runnable非要得到返回值（直接用Callable吧） submit(Callable)，有返回值，可以通过Future与启动的线程交互。 public interface ExecutorService extends Executor &#123; void execute(Runnable command); // 从Executor继承 Future&lt;?&gt; submit(Runnable task); &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result); &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task); &#125; 一般常用的就两种，启动任务就行，那就execute(Runnable)；关心返回值，需要交互，那就submit(Callable)。 public class Task implements Callable&lt;Integer&gt; &#123; @Override public Integer call() throws Exception &#123; return 1; &#125;&#125;ExecutorService executor = Executors.newSingleThreadExecutor();Future&lt;Integer&gt; future = executor.submit(new Task());Integer result = future.get(); 不用创建FutureTask了，Callable用线程池更直观。 Executors使用Executors可以得到ExecutorService接口，常见的有如下三种。Executors实际创建ThreadPoolExecutor实例，但屏蔽了参数细节，不建议使用，建议自己创建ThreadPoolExecutor。 public class Executors &#123; // 线程池中就1个核心线程，忙就排队 public static ExecutorService newSingleThreadExecutor() &#123;&#125; // 核心线程数是nThreads的线程池，无界排队队列 public static ExecutorService newFixedThreadPool(int nThreads) &#123;&#125; // 核心线程数0，接收任务就创建新线程执行 public static ExecutorService newCachedThreadPool() &#123;&#125;&#125; newSingleThreadExecutor()和newCachedThreadPool()基本无实战价值。 ThreadPoolExecutor几个最重要的参数： corePoolSize，核心线程数 maximumPoolSize，最大线程数 workQueue，排队策略 handler，饱和策略 首先，当线程池中的线程数小于核心线程数时，会为新任务创建新线程，直到达到核心线程数；核心线程完成任务后不会回收；当有新任务到来时，从线程池中选择空闲的核心线程来执行任务，当无核心线程空闲时进入排队逻辑。 排队逻辑ArrayBlockingQueue 有界队列，核心线程无空闲时开始排队，队列满以后开启非核心线程，直到最大线程数，超过最大线程数进入饱和逻辑。 LinkedBlockingQueue 无界队列，核心线程无空闲时开始排队，由于队列无界，会一直排队到资源耗尽，最大线程数不起作用。 SynchronousQueue 零界队列，相当于长度为0的队列，不排队直接开启非核心线程，超过最大线程数进入饱和策略。 非核心线程开启的非核心线程是可以回收的，当空闲时间超过设定时间keepAliveTime+unit即可回收。线程池不会标记哪个线程是核心线程，哪个线程是非核心线程，线程池关心的是数量。 饱和逻辑AbortPolicy 默认的饱和策略，抛出RejectedExecutionException异常。 DiscardPolicy 丢弃当前任务，就当没提交过。 CallerRunsPolicy 在调用者线程中执行run()方法。 我觉得默认就很好，一般就不要修改饱和策略了。 线程同步前面一直关注如何创建和启动线程来完成任务，线程同步关心的是多个线程之间通信的交互的事情。这部分的难度要大一些。 竞态条件首先引入竞态条件和临界区的概念，当多个线程同时访问共享变量时，如果执行顺序不同导致结果可能不同，那么我们就说存在竞态条件（Race Condition），引起竞态条件的代码就称为临界区（Critical Section）。 线程同步的三个问题：原子性、可见性和有序性。 synchronizedsynchronized关键字起到锁的作用，可以保证原子性、可见性和有序性。synchronized语句块同时只能有一个线程执行，其他线程阻塞等待。synchronized本质上是对一个对象加锁，可以显示声明这个对象，也可以是隐式的。synchronized修饰类的成员方法，相当于对类的实例对象加锁；synchronized修饰类的静态方法，相当于对类对象加锁。 public synchronized int add(int value) &#123;&#125; 等价于 public int add(int value) &#123; synchronized(this) &#123;&#125;&#125; 同样的， public class Math &#123; public static synchronized void add(int value) &#123;&#125;&#125; 等价于 public class Math &#123; public static void add(int value) &#123; synchronized(Math.this) &#123;&#125; &#125;&#125; 偏向锁Synchronized实现原理：每个对象有一个监视器锁（monitor），当monitor被占用时就会处于锁定状态。进入同步代码块是通过monitorenter指令获取锁，退出同步代码块时通过monitorexit指令释放锁。monitor本身基于操作系统的Mutex和Lock来实现，成本高，所以通常我们称Synchronized为重量级锁。 但是，从JDK1.6开始逐步优化Synchronized的实现，将实现方式分为三级：偏向锁、轻量级锁和重量级锁。加锁过程是一个失败后的升级过程：先尝试加偏向锁，不成功再尝试加轻量级锁，还不成功才使用重量级锁。 轻量级锁是为了在线程交替执行同步块时提高性能，而偏向锁则是在只有一个线程执行同步块时进一步提高性能,以下为个人理解。 偏向锁相当于在Object对象锁上记录线程ID，实际上就是最后一个锁定这个对象的线程ID。加锁时先判断偏向锁，也就是把当前线程ID和锁上记录的最后访问线程ID做比较，如果一样说明只有一个线程在使用，不用加锁。偏向锁在只有一个线程访问synchronized同步块代码时提高了效率。如果线程ID不一样，使用CAS操作（更新LockRecord指针）来抢锁，抢锁成功即加上了轻量级锁，抢锁的操作是自旋的，多次失败进入重量级锁逻辑。 volatilevolatile关键字比synchronized轻量级，可以保证可见性和有序性，但不能保证复合操作的原子性。synchronized相当于限制同一段代码同一时刻只有一个线程执行，把并行改成了串行，所以可以保证没有竞态条件。volatile并不互斥，多线程可以同时直接。volatile修饰的变量保证在写入时立即更新到主内存中，在读取时从主内存中读取，所以volatile可以保证在多个线程中这个变量的值是一样的。 由于volatile关键字不能保证复合操作的原子性，所以volatile最适合修饰boolean变量。 public static volatile boolean ready = false; 下面的count++就是复合操作的例子，虽然volatile可以保证count值立即刷新到主内存中，但是由于++操作不是原子操作，所以count++的原子性无法保证。 public static volatile int count = 0;public void add() &#123; count++;&#125; 虽然在实际工作中volatile的使用远比synchronized少，但理解volatile原理是非常重要的。 wait/notify通过修改共享变量的值可以完成线程间通信，但这样读取线程需要一直尝试读取，无法让出CPU，所以我们要引入wait()和notify()方法。 调用wait()方法将使当前线程进入等待状态，直到有其他线程调用了notify()或者notifyAll()方法后唤醒。这里有几点必须注意： 虽然实现了线程阻塞和唤醒，但wait()和notify()不是Thread类的方法，是Object类的方法； wait()和notify()必须在synchronized代码块内使用，也就是说你的先得到对象的锁，然后才可以阻塞或唤醒它； 调用一个对象的notify()方法后，将唤醒一个在这个对象上wait()的线程，如果有多个线程等待，操作系统决定唤醒哪一个；notifyAll()方法唤醒所有在这个对象上wait()的线程； 由于存在虚假唤醒和信号丢失等可能，所以实战中建议使用notifyAll()，比较安全。 ThreadLocalThreadLocal可以认为是一种特殊的线程同步操作，为避免共享变量出问题，在每个线程中都创建一个不同的副本，互不影响，实际上就是不共享了。 代码看上去是共享的，但实际上给每个线程创建了一个对象，最后以线程为key放到一个map中使用。 在Thread里面有一个静态成员变量ThreadLocal.ThreadLocalMap threadLocals = null; threadLocals是一个所有线程共享的map，这个map的key是Thread.currentThread()，value是ThreadLocal的值。 public class ThreadLocal&lt;T&gt; &#123; public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); &#125; ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals; &#125; public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; T result = (T)e.value; return result; &#125; &#125; return setInitialValue(); &#125; &#125; 重写initialValue()方法可以初始化ThreadLocal的值。 ThreadLocal&lt;String&gt; uuid = new ThreadLocal&lt;String&gt;()&#123; @Override protected String initialValue() &#123; return UUID.randomUUID().toString(); &#125;&#125;; finalfinal关键字也是避免多线程共享出现竞态条件的一种方法，把共享变量声明为final，不变当然不会出问题。 Java并发包Java从1.5开始提供了并行开发包java.util.concurrent，也有人简称JUC。ThreadPoolExecutor就是并发包中的类，下面来看看其他重要的类。 AtomicInteger保证读写是原子操作的Integer。 如果只是为了避免int共享变量的竞态条件，可以使用AtomicInteger。因为synchroznied虽然可以实现，但是太重量级，volatile又不能保证++操作原子性。AtomicInteger类的核心方法是compareAndSet()，也就是CAS。 CAS由AtomicInteger引出了CAS，compare and swap，比较并交换。CAS乐观锁机制是Java并行包中很多实现的基础。CAS对应Unsafe类中的compareAndSwap方法，这个方法有三个参数：(1)内存地址、(2)当前值、(3)新值；执行compareAndSwap方法时会判断当前内存地址，如果等于当前值，那么替换为新值并返回成功；如果不等于当期值，那么不做任务操作返回失败。 以AtomicInteger类的getAndIncrement()方法为例，实现原子++，并且返回原值。 public class AtomicInteger extends Number implements java.io.Serializable &#123; public final int getAndIncrement() &#123; return unsafe.getAndAddInt(this, valueOffset, 1); &#125;&#125; 原子++操作实际上是调用Unsafe类的getAndAddInt()方法实现的：这个方法一直尝试compareAndSwapInt()。 public final class Unsafe &#123; public final native boolean compareAndSwapInt(Object obj, long offset, int expect, int update); public final int getAndAddInt(Object obj, long offset, int update) &#123; int expect; do &#123; expect = this.getIntVolatile(obj, offset); &#125; while(!this.compareAndSwapInt(obj, offset, expect, expect + update)); return var5; &#125; &#125; Unsafe的CAS操作实际上对应了硬件的CAS型指令，这个指令具有原子性。 自旋上面代码中do {} while(compareAndSwap()) 这种操作被称为CAS自旋，自旋这个名词在多线程中经常用到，个人理解就是while(true) 一直尝试的意思，其实很简单，但起了个高大上的名字。 ABA问题compare时虽然内存地址上的值是A，与compareAndSwap前读取到的值一样，但这不能说明内存值没有变化，可能发生了A-&gt;B-&gt;A的变化。增加版本号或者时间戳信息可以解决ABA问题。 个人认为，如果内存地址上存储的是int值，那么ABA也不会带来太大问题。但是，如果内存地址上存储的是链表指针，可能就会出大问题。例如：已知链表A-&gt;C，head为头指针指向A元素，需求compareAndSwap(A, C)将head移动到下一个元素C。如果在移动前链表发生了变化，变成了：A-&gt;B，那么compareAndSwap(A, C)判断head还是A，将head=C。实际上C元素已经在A-&gt;B时被删除了，所以这个时候head指到了链表外，就错了。 ReentrantLockReentrantLock类实现了Lock接口，顾名思义实现了可重入锁。从一定意义上讲，可以将ReentrantLock类视作synchronzied的替代者。ReentrantLock提供了显示锁，synchronzied提供了隐式锁；ReentrantLock功能更强大，也更复杂，synchronzied简单好理解，并且也在逐步优化。 两者没有好坏之分，synchronzied简单，如果使用synchronzied可以满足要求，那么使用synchronzied就行；如果synchronzied不能满足要求，那么使用ReentrantLock。 不要想当然认为synchronzied效率低下，synchronzied做了轻量级和偏向锁优化，效率不低。 ReentrantLock常规用法如下，建议在finally中释放锁。 Lock lock = new ReentrantLock();try &#123; lock.lock(); ......&#125; finally &#123; lock.unlock();&#125; lock()方法是阻塞的，也可以使用不阻塞的tryLock()方法 Lock lock = new ReentrantLock();try &#123; int count = 0; int maxCount = 5; while(!lock.tryLock(100, TimeUnit.MILLISECONDS) &amp;&amp; count &lt; maxCount) &#123; count++; &#125; ......&#125; finally &#123; lock.unlock();&#125; tryLock()也是解决死锁问题的一种办法，可以先tryLock()全部资源，都成功后才开始执行。 ReentrantLock提供了公平锁FairSync和非公平锁NonfairSync两种实现，默认使用非公平锁，可通过参数fair选择使用。ReentrantLock基于AbstractQueuedSynchronizer实现，AQS单独讲。 public class ReentrantLock implements Lock, java.io.Serializable &#123; private final Sync sync; public ReentrantLock() &#123; sync = new NonfairSync(); &#125; public ReentrantLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync(); &#125; public void lock() &#123; sync.lock(); &#125; public void unlock() &#123; sync.release(1); &#125; static final class FairSync extends Sync &#123;&#125; static final class NonfairSync extends Sync &#123;&#125; abstract static class Sync extends AbstractQueuedSynchronizer &#123;&#125;&#125; ReentrantLock是可重入锁，每lock()一次，计数器加1，每unlock()一次，计数器减1。lock()和unlock()一定要成对出现。 ConditionReentrantLock对应synchronized，ReentrantLock.Condition对应wait/notify，都可以达到相同效果。wait和notify必须在synchronized语句块内，所以Condition对象通过ReentrantLock对象创建。 public class ReentrantConditionDemo &#123; private static AtomicInteger sum = new AtomicInteger(0); private final static ReentrantLock lock = new ReentrantLock(); private final static Condition condition = lock.newCondition(); public static class Consumer implements Runnable &#123; @Override public void run() &#123; try &#123; lock.lock(); condition.await(); logger.info("sum=" + sum.get()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125; &#125; public static class Producer implements Runnable &#123; @Override public void run() &#123; try &#123; lock.lock(); sum.getAndIncrement(); Thread.sleep(1000); condition.signalAll(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125; &#125;&#125; 几个注意的地方： 使用lock.newCondition(); 创建Condition，一个lock可以创建多个不同的Condition； Condition.await=Object.wait Condition.signal=Object.notify Condition.signalAll=Object.notifyAll 调用Condition方法前必须lock.lock()； wait和notify是Object类的方法，所以Condition类也有这两个方法，不要写错。 ReentrantLock.Condition相对wait/notify的增强点： wait/notify是基于Object的，也就是说一个Ojbect被lock以后，如果有多个等待条件，notifyAll都可以触发；例如生产者-消费者中锁定数组对象后，有数组空和数组满两个判断条件，都通过notifyAll触发； ReentrantLock.Condition的颗粒度比wait/notify小，一个Lock对象可以new多个Condition，也就是说数组空和数组满可以是两个Condition，分别signalAll触发。 AQS由ReentrantLock引出了AbstractQueuedSynchronizer同步器，简称AQS。不仅ReentrantLock，BlockingQueue、CountDownLatch和Semaphore等类都是基于AQS实现的，所以AQS是JUC中最重要的一个类。 先从字面理解，AQS是抽象队列同步器。首先这是一个抽象类，使用时需要像ReentrantLock一样继承抽象基类并实现相应方法；其次，AQS目的是同步，所以基于AQS可以实现各种同步功能；最后，AQS是基于队列实现的。 AQS有两种模式：独占模式和共享模式。独占的意思是只有一个线程能够得到锁，其他线程需要在队列里面排队，ReentrantLock就是独占模式。共享的意思是同时可以有多个线程得到锁，Semaphore就是共享模式。 AQS里面有一个volatile修饰的int型变量state，记录了当前锁的状态。以独占模式为例，通过CAS操作更新state状态保证并发时只能有一个线程得到锁，其他线程放到一个queue里面排队。这个queue是通过双向链表实现的，每个节点是一个Node，Node里面记录了排队Thread信息，前一个Node的指针和后一个Node的指针。AQS里面记录了双向链表的头指针head和尾指针tail。 public abstract class AbstractQueuedSynchronizer &#123; static final class Node &#123; volatile int waitStatus; volatile Node prev; volatile Node next; volatile Thread thread; Node nextWaiter; &#125; private transient volatile Node head; private transient volatile Node tail; private volatile int state; protected final boolean compareAndSetState(int expect, int update) &#123; return unsafe.compareAndSwapInt(this, stateOffset, expect, update); &#125; public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); &#125; public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false; &#125; public final void acquireShared(int arg) &#123; if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg); &#125; public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; doReleaseShared(); return true; &#125; return false; &#125; protected boolean tryAcquire(int arg) &#123; throw new UnsupportedOperationException(); &#125; protected boolean tryRelease(int arg) &#123; throw new UnsupportedOperationException(); &#125; protected int tryAcquireShared(int arg) &#123; throw new UnsupportedOperationException(); &#125; protected boolean tryReleaseShared(int arg) &#123; throw new UnsupportedOperationException(); &#125;&#125; 注意：这里有一个小技巧。AbstractQueuedSynchronizer是一个抽象基类，独占模式的接口是acquire和release，共享模式的接口是acquireShared和releaseShared。从代码可以看出，独占模式必须实现tryAcquire和tryRelease方法，由于AQS有两种模式，所以tryAcquire和tryRelease方法没有被声明为abstract，而是采用了抛出异常的方法。也就是说，共享模式不会进入tryAcquire和tryRelease代码，没有问题；独占模式如果子类没有实现这两个方法，将抛出异常。 compareAndSetState()方法通过CAS操作更新state状态，通过state状态就可以判断锁定状态。 head是队列的头指针，head声明为volatile是由于指针的移动也是CAS操作。 AQS是Java并发包的基础，CAS又是AQS的基础。 独占模式独占模式加锁的处理流程如下： 入口acquire()方法； 调用tryAcquire()方法（子类实现）尝试加锁，如果加锁成功直接返回成功； 加锁失败，将线程信息封装到Node节点中，并添加到队列的队尾（CAS+自旋入队尾）； 再次尝试tryAcquire()获取锁，失败后线程进入阻塞； 独占模式解锁的处理流程如下： 入口release()方法； 调用 tryRelease()方法尝试释放锁； 解锁成功唤醒后继线程； 共享模式 TODO LockSupportAQS的线程阻塞和唤醒没有使用Object类的wait()和notify()方法，使用的是LockSupport类的park()和unpark()方法。底层通过Unsafe类native的park()和unpark()方法实现。 wait()和notify()是基于Object的，park()和unpark()是基于Thread的，语义上更好理解。 BlockingQueueBlockingQueue是一个FIFO的阻塞队列，put()方法往队列末尾增加元素，take()方法从队列头读取元素。BlockingQueue有三种实现：ArrayBlockingQueue、LinkedBlockingQueue和SynchronousQueue。 ArrayBlockingQueue基于数组实现有界队列，底层基于ReentrantLock实现，notEmpty判断空，notFull判断满。 public class ArrayBlockingQueue&lt;E&gt; extends AbstractQueue&lt;E&gt; implements BlockingQueue&lt;E&gt; &#123; final Object[] items; int count; public ArrayBlockingQueue(int capacity, boolean fair) &#123; this.items = new Object[capacity]; lock = new ReentrantLock(fair); notEmpty = lock.newCondition(); notFull = lock.newCondition(); &#125; public void put(E e) throws InterruptedException &#123; final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; while (count == items.length) notFull.await(); enqueue(e); &#125; finally &#123; lock.unlock(); &#125; &#125; public E take() throws InterruptedException &#123; final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; while (count == 0) notEmpty.await(); return dequeue(); &#125; finally &#123; lock.unlock(); &#125; &#125; &#125; LinkedBlockingQueue基于链表实现无界队列，读和写使用了两个锁，count使用AtomicInteger。 public class LinkedBlockingQueue&lt;E&gt; extends AbstractQueue&lt;E&gt; implements BlockingQueue&lt;E&gt; &#123; private final int capacity; private final AtomicInteger count = new AtomicInteger(); private final ReentrantLock takeLock = new ReentrantLock(); private final Condition notEmpty = takeLock.newCondition(); private final ReentrantLock putLock = new ReentrantLock(); private final Condition notFull = putLock.newCondition(); public LinkedBlockingQueue() &#123; this.capacity = Integer.MAX_VALUE; last = head = new Node&lt;E&gt;(null); &#125; static class Node&lt;E&gt; &#123;&#125; transient Node&lt;E&gt; head; private transient Node&lt;E&gt; last; public void put(E e) throws InterruptedException &#123; int c = -1; Node&lt;E&gt; node = new Node&lt;E&gt;(e); final ReentrantLock putLock = this.putLock; final AtomicInteger count = this.count; putLock.lockInterruptibly(); try &#123; while (count.get() == capacity) &#123; notFull.await(); &#125; enqueue(node); c = count.getAndIncrement(); if (c + 1 &lt; capacity) notFull.signal(); &#125; finally &#123; putLock.unlock(); &#125; if (c == 0) signalNotEmpty(); &#125; public E take() throws InterruptedException &#123; E x; int c = -1; final AtomicInteger count = this.count; final ReentrantLock takeLock = this.takeLock; takeLock.lockInterruptibly(); try &#123; while (count.get() == 0) &#123; notEmpty.await(); &#125; x = dequeue(); c = count.getAndDecrement(); if (c &gt; 1) notEmpty.signal(); &#125; finally &#123; takeLock.unlock(); &#125; if (c == capacity) signalNotFull(); return x; &#125; &#125; SynchronousQueue零界队列。 TODO CountDownLatch倒计数锁。每次调用countDown() 计数器减1，await(); 方法阻塞到计数器为0时返回，起到和join()方法一样的效果。CountDownLatch比Thread.join()更灵活，Thread.join()只能在线程结束后返回，CountDownLatch可以在任何位置调用countDown()方法。另外，我们通常使用线程池启动子线程，子线程只需要实现runnable接口，这种情况下Thread类对象是封装在线程池里面的，我们不方便拿到，也就不方便调用它的join()方法；使用CountDownLatch就简单多了，只需要在run()方法退出前调用countDown()方法即可。 public static class Task implements Runnable &#123; private CountDownLatch counter; public Task(CountDownLatch counter) &#123; this.counter = counter; &#125; @Override public void run() &#123; counter.countDown(); &#125;&#125;CountDownLatch counter = new CountDownLatch(2);Task task = new Task(counter);ExecutorService executorService = Executors.newFixedThreadPool(2);for (int i=0; i&lt;2; i++) &#123; executorService.execute(task);&#125;counter.await(); Semaphore信号量和锁有点类似，区别是ReetrantLock是独占锁，只能锁一次，Semaphore是共享锁，可以锁多次。 Semaphore的acquire()/release()方法和lock()/unlock()方法一样需要成对使用。区别在于lock()方法只能有1个线程通过，acquire()方法可以有多个线程通过。 Semaphore semaphore = new Semaphore(5);public void run() &#123; try &#123; semaphore.acquire(); ...... semaphore.release(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;&#125; CyclicBarrier循环栅栏，所有等待线程等到最后一个执行完成后再同步前进，可以指定下一步任务。不常用。 CyclicBarrier barrier = new CyclicBarrier(2, new MainTask());public void run() &#123; barrier.await();&#125; 多线程活性问题死锁两个线程互相等待对方的资源而被阻塞。线程1锁定资源A，申请资源B，线程2锁定资源B，申请资源A，就出现死锁。典型的例子：哲学家进餐问题、父节点和子节点互相添加。 哲学家进餐问题：五个哲学家做在一个圆桌上，只有五支筷子，哲学家需要左右手各拿到一支才可以进餐。哲学家全都先拿起左手筷子，再拿起右手筷子，然后再进餐。可能出现五个哲学家全部左手拿筷子的情况，形成死锁。 解决方法一：锁定全部筷子 一次拿走全部筷子，然后再进餐，这样不会死锁，但同时只能有一个人进餐，虽然还富余三支筷子。 解决方法二：严格锁定顺序 都按照一个顺序来加锁。这点可能感到奇怪，先加左手筷子锁，再加右手筷子锁，顺序是一样的啊。主要原因是圆桌，左手和右手是相对的，A的右手可能就是B的左手。解决方案：给所有筷子从1到5编号，先加小号锁，再加大号锁。编号是绝对的，保证从小到大的加锁顺序可以避免死锁。 解决方法三：尝试加锁 使用ReentrantLock类的tryLock()方法尝试给两支筷子加锁，都成功才可以进餐。 活锁一直尝试加锁，一直失败得不到锁，就是活锁现象。 线程饥饿多个线程竞争同一个锁，如果一直有新的线程加入竞争，可能出现某个线程永远得不到锁的情况。 使用ReentrantLock的公平锁可以解决线程饥饿问题，公平锁保证按照排队顺序唤醒下一个线程。 Lock lock = new ReentrantLock(true); 注意：公平锁带来了额外的成本，所以通常实现统计意义上的公平即可，无需实现排队公平。 虚假唤醒调用wait()方法后处于blocked状态的线程，在没有其他线程调用notify()方法的情况下被系统唤醒，称为虚假唤醒。 为避免虚假唤醒带来的问题，进入wait()的判断条件不用if，用while，这样唤醒后会再判断一遍。 while(condition) &#123; object.wait();&#125; 信号丢失调用wait()方法后等待notify()方法唤醒，但是不幸的是notify()方法已经在wait()方法执行前执行了，那么wait()永远等不到唤醒信息。 生产者/消费者wait/notify实现public class ProducerConsumerDemo &#123; private final static Logger LOGGER = LoggerFactory.getLogger(ProducerConsumerDemo.class); public static void main(String[] args) &#123; LinkedList&lt;String&gt; storeList = new LinkedList&lt;&gt;(); Producer producer = new Producer(storeList, "producer" + (i+1)); Consumer consumer = new Consumer(storeList, "consumer" + (i+1)); producer.start(); consumer.start(); &#125; // 生产者 public static class Producer extends Thread &#123; private LinkedList&lt;String&gt; storeList; private final static int MAX = 10; private static AtomicInteger count = new AtomicInteger(1); public Producer(LinkedList&lt;String&gt; storeList, String name) &#123; this.storeList = storeList; this.setName(name); &#125; @Override public void run() &#123; while(true) &#123; synchronized (storeList)&#123; // 库存满了阻塞等待消费 while(storeList.size() == MAX) &#123; LOGGER.info("库存满了"); try &#123; storeList.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; // 生产20个以后退出 if (count.intValue() &gt; 20) &#123; break; &#125; // 生产数据 String data = String.format("%04d", count.getAndIncrement()); storeList.add(data); LOGGER.info("生产 " + data); // 等一会 try &#123; Thread.sleep(500); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; // 唤醒等待消费的线程 storeList.notifyAll(); &#125; &#125; &#125; &#125; // 消费者 public static class Consumer extends Thread &#123; private LinkedList&lt;String&gt; storeList; public Consumer(LinkedList&lt;String&gt; storeList, String name) &#123; this.storeList = storeList; this.setName(name); &#125; @Override public void run() &#123; while(true) &#123; synchronized (storeList)&#123; // 库存空了阻塞等待生产 while(storeList.size() == 0) &#123; LOGGER.info("库存空了"); try &#123; storeList.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; // 消费掉第一个数据 String data = storeList.get(0); LOGGER.info("消费 " + data); storeList.remove(0); // 等一会 try &#123; Thread.sleep(500); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; // 唤醒等待生产的线程 storeList.notifyAll(); &#125; &#125; &#125; &#125;&#125; Lock/Condition实现public class ProducerConsumerDemo &#123; private static int count = 0; private final static Logger logger = LoggerFactory.getLogger(ProducerConsumerDemo.class); public static void main(String[] args) &#123; LinkedList&lt;Integer&gt; store = new LinkedList(); Lock lock = new ReentrantLock(); Condition full = lock.newCondition(); Condition empty = lock.newCondition(); ExecutorService executorService = Executors.newCachedThreadPool(); Producer producer = new Producer(store, lock, full,empty); Consumer consumer = new Consumer(store, lock, full,empty); executorService.submit(producer); executorService.submit(consumer); &#125; // 生产者 public static class Producer implements Runnable &#123; private final LinkedList&lt;Integer&gt; store; private final Lock lock; private final Condition full; private final Condition empty; public Producer(LinkedList store, Lock lock, Condition full, Condition empty) &#123; this.store = store; this.lock = lock; this.full = full; this.empty = empty; &#125; @Override public void run() &#123; while (count &lt; 20)&#123; try &#123; lock.lock(); while (store.size() &gt;= 10) &#123; full.await(); &#125; count++; Integer data = new Integer(count); store.add(data); logger.info("生产 " + data); Thread.sleep(500); empty.signalAll(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125; &#125; &#125; // 消费者 public static class Consumer implements Runnable &#123; private final LinkedList&lt;Integer&gt; store; private final Lock lock; private final Condition full; private final Condition empty; public Consumer(LinkedList store, Lock lock, Condition full, Condition empty) &#123; this.store = store; this.lock = lock; this.full = full; this.empty = empty; &#125; @Override public void run() &#123; while (true) &#123; try &#123; lock.lock(); while (store.size() == 0) &#123; empty.await(); &#125; Integer data = store.get(0); store.remove(0); logger.info("消费 " + data); Thread.sleep(500); full.signalAll(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125; &#125; &#125;&#125; BlockingQueue实现public class ProducerConsumerDemo &#123; private final static Logger logger = LoggerFatory.getLogger(ProducerConsumerDemo.class); public static void main(String[] args) throws InterruptedException &#123; BlockingQueue queue = new ArrayBlockingQueue(10); Producer producer = new Producer(queue); Consumer consumer = new Consumer(queue); new Thread(producer).start(); new Thread(consumer).start(); &#125; // 生产者 public static class Producer implements Runnable&#123; protected BlockingQueue queue = null; protected int count = 0; public Producer(BlockingQueue queue) &#123; this.queue = queue; &#125; @Override public void run() &#123; while (count &lt; 20) &#123; try &#123; count++; queue.put(new Integer(count)); logger.info("生产 " + count); Thread.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; // 消费者 public static class Consumer implements Runnable&#123; protected BlockingQueue queue = null; public Consumer(BlockingQueue queue) &#123; this.queue = queue; &#125; @Override public void run() &#123; while (true) &#123; try &#123; logger.info("消费 " + queue.take()); Thread.sleep(500); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;&#125; Java内存模型参考资料Java并发编程：Synchronized底层优化（偏向锁、轻量级锁） AbstractQueuedSynchronizer 原理分析 - 独占/共享模式 【Java并发编程】—–“J.U.C”：LinkedBlockingQueue]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot热部署]]></title>
    <url>%2F2018%2F05%2F18%2Fspringboot-devtool-deploy%2F</url>
    <content type="text"><![CDATA[Java热加载 Java热部署]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>热部署</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[并行包源码分析]]></title>
    <url>%2F2018%2F05%2F17%2Fthread-java-concurrent-sourcecode%2F</url>
    <content type="text"><![CDATA[基础理论CASCAS是英文Compare And Swap的简称，从字母也能够理解其含义：比较并替换。回想一下数据库中经常使用的乐观锁就是CAS的思想。CAS同时也是Java并行包的基础，可以简单认为syschronized是悲观锁，基于CAS的Java并行包是乐观锁。 CAS对应Unsafe类中的compareAndSwap方法，这个方法实际上需要三个参数：(1)数据的内存地址、(2)预期当前值和(3)即将更新值；执行compareAndSwap方法时会判断当前内存值，如果等于预期当前值，那么替换为新值并返回成功；如果不等于预期当期值，那么不做更新操作，返回失败。 这里的comapre和swap是一组原子操作，不会被打断。 我们知道，syschronized可以实现原子性，为避免多个线程同时修改一个数据引发问题，我们在每个线程修改数据前加锁，保证同时只有一个线程操作数据，这样肯定是线程安全的，但是效率低。因为，大多数情况下不存在多个线程同时修改数据的情况，所以大多数情况下加锁和解锁操作是废操作。CAS的思路默认没有线程同时执行，如果出现线程并发修改情况，只有一个线程可以compareAndSwap成功，其他线程出错后重试。 凡事没有绝对，如果真的存在多个线程频繁修改同一个数据的业务场景，那么syschronized效率是高于CAS的，因为一旦CAS需要频繁重试，效率自然下降。 Unsafe类CAS的核心实现是Unsafe类，Unsafe类功能强大，使Java拥有了像C一样直接访问内存空间的能力，所以是非常危险的，慎用。Unsafe类的核心方法都是native的，下面看看代码。 package sun.misc;public final class Unsafe &#123; private static final Unsafe theUnsafe; public static Unsafe getUnsafe() &#123; return theUnsafe; &#125; static &#123; theUnsafe = new Unsafe(); &#125; private Unsafe() &#123;&#125; public final native boolean compareAndSwapObject(Object obj, long offset, Object expect, Object update); public final native boolean compareAndSwapInt(Object obj, long offset, int expect, int update); public final native boolean compareAndSwapLong(Object obj, long offset, long expect, long update); public final int getAndAddInt(Object obj, long offset, int update) &#123; int expect; do &#123; expect = this.getIntVolatile(obj, offset); &#125; while(!this.compareAndSwapInt(obj, offset, expect, expect + update)); return var5; &#125; public native int getIntVolatile(Object var1, long var2);&#125; 我们以compareAndSwapInt 为例，这个方法有四个参数： Object obj，类实例对象； long offset，变量相当于类实例对象的偏移地址（obj+offset定位int变量的内存地址）； int expect，预期当前int值； int update，即将更新int值。 如果有一点C语言知识，就很好理解这种定位内存地址的方法了。 我们再来看一下getAndAddInt 方法，也很好理解 getIntVolatile(obj, offset) 方法可以理解为读取int变量的值（obj+offset定位int变量的内存地址）； 首先，读取内存中变量的当前值放入expect中； 下一步，执行compareAndSwapInt()，比较并交换，预期当前值为expect，新值为expect+update； 如果compareAndSwapInt()成功直接返回； 如果compareAndSwapInt()失败，重新尝试，直至成功为止。 再来看一下Unsafe的源码 sun::misc::Unsafe::compareAndSwapInt (jobject obj, jlong offset, jint expect, jint update)&#123; jint *addr = (jint *)((char *)obj + offset); return compareAndSwap(addr, expect, update);&#125;static inline bool compareAndSwap (volatile jint *addr, jint old, jint new_val)&#123; jboolean result = false; spinlock lock; if ((result = (*addr == old))) *addr = new_val; return result;&#125; ABA问题CAS存在一个很明显的问题，即ABA问题。也就是说，compare时虽然内存地址上的值是A，与compareAndSwap前读取到的值一样，但这不能说明内存值没有变化，可能发生了A-&gt;B-&gt;A的变化。 ABA问题本身不难理解，但是这样就一定出问题吗？对于数值来说，一般也没啥问题。但是，对于链表来说就有问题了。例如： 线程1读取当前链表结构为A-&gt;B，head指向A，线程1试图执行compareAndSwap(A, B)，将链表头指针head指向A的下一个元素B； 当线程1读取链表完成执行compareAndSwap前被挂起，线程2开始执行； 线程2从链表中删除了元素A和元素B，又加入了元素A和元素C，链表结构为A-&gt;C； 此时线程1开始执行，头指针head还是执行C，但链表内容已经变了；如果还是执行head=B就出错了。 ABA问题一般通过加入版本号或者时间戳就可以解决。 AQS源码解析AtomicInteger明白了CAS原理，AtomicInteger类就很容易理解了。 package java.util.concurrent.atomic;public class AtomicInteger extends Number implements java.io.Serializable &#123; private static final Unsafe unsafe = Unsafe.getUnsafe(); private static final long valueOffset; static &#123; valueOffset = unsafe.objectFieldOffset(AtomicInteger.class.getDeclaredField("value")); &#125; private volatile int value; public AtomicInteger(int initialValue) &#123; value = initialValue; &#125; public final int getAndIncrement() &#123; return unsafe.getAndAddInt(this, valueOffset, 1); &#125;&#125; 我们以getAndIncrement()方法为例，目标为实现自增加1操作： 在AtomicInteger类构造时获取了Unsafe单例，并计算value变量的内存地址偏移量valueOffset； 当调用自增+1方法时，实际调用了Unsafe的getAndAddInt()方法，前两个参数定位到类实例对象的value变量内存地址，变化值为1； getAndAddInt()方法在CAS中介绍过，一直尝试compareAndSwapInt()，直到成功为止； 读取value变量的当前值； 执行比较和交换操作，预期值为刚刚读到的value值，更新值为value+1； 如果没有其他线程竞争，那么成功写入value+1； 如果已经有其他线程修改了value的内存值，那么比较和交换操作失败；重新读取value变量值重试比较和交换； 理论上，如果一直有其他线程在修改，会陷入死循环出不来？ AtomicInteger类存在ABA问题，并行包提供了带时间戳的AtomicStampedReference类解决ABA问题。 AbstractQueuedSynchronizerReentrantLockReentrantLock顾名思义表示可重入锁，一般视为synchronized的替代者。 废话不说，直接上代码，从代码中可以看出： ReentrantLock有两种实现：公平锁FairSync和非公平锁NonfairSync。 默认实现是非公平锁NonfairSync； 构造ReentrantLock对象时可以传入boolean型参数fair显示指定使用公平锁还是非公平锁； 无论公平锁还是非公平锁都集成AbstractQueuedSynchronizer类； 结论：关键看AbstractQueuedSynchronizer、FairSync和NonfairSync三个类如何实现。 package java.util.concurrent.locks;public class ReentrantLock implements Lock, java.io.Serializable &#123; public ReentrantLock() &#123; sync = new NonfairSync(); &#125; public ReentrantLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync(); &#125; private final Sync sync; public void lock() &#123; sync.lock(); &#125; public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireNanos(1, unit.toNanos(timeout)); &#125; public void unlock() &#123; sync.release(1); &#125; abstract static class Sync extends AbstractQueuedSynchronizer &#123; abstract void lock(); &#125; static final class FairSync extends Sync &#123;&#125; static final class NonfairSync extends Sync &#123;&#125;&#125; NonfairSyncReentrantLock类的默认实现是NonfairSync，我们先看非公平锁。NonfairSync是ReentrantLock的静态内部类。 我们发现NonfairSync类非常简单，以下已经是这个类的全部代码，核心实现不再这里，继续向下深入。 static final class NonfairSync extends Sync &#123; final void lock() &#123; if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1); &#125; protected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires); &#125; &#125; 看了AbstractQueuedSynchronizer代码以后，我们解释一下lock()方法 compareAndSetState()是Unsafe的一个CAS方法，AQS初始化的state=0，lock()将state=1 package java.util.concurrent.locks;public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer &#123; private volatile int state; private static final Unsafe unsafe = Unsafe.getUnsafe(); private static final long stateOffset; static &#123; stateOffset = unsafe.objectFieldOffset (AbstractQueuedSynchronizer.class.getDeclaredField("state")); &#125; protected final boolean compareAndSetState(int expect, int update) &#123; // See below for intrinsics setup to support this return unsafe.compareAndSwapInt(this, stateOffset, expect, update); &#125; &#125; 第一步相当于抢占了一个开关，抢到以后把当前线程对象赋值给了AQS对象作为当前排他线程，仅此而已； package java.util.concurrent.locks;public abstract class AbstractOwnableSynchronizer implements java.io.Serializable &#123; private transient Thread exclusiveOwnerThread; protected final void setExclusiveOwnerThread(Thread thread) &#123; exclusiveOwnerThread = thread; &#125; protected final Thread getExclusiveOwnerThread() &#123; return exclusiveOwnerThread; &#125;&#125; 第二次执行lock()方法时，compareAndSetState()由于stateOffset=1和预期值0不一样，返回false，进入acquire(1)逻辑；acquire()是AbstractQueuedSynchronizer类的方法，tryAcquire()回到NonfairSync类执行nonfairTryAcquire(1) package java.util.concurrent.locks;public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer &#123; public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); &#125;&#125; nonfairTryAcquire()是基类Sync的方法，从基类AbstractQueuedSynchronizer中getState()；由于之前lock()时已经将AQS置为1，这里c==1且current != exclusiveOwnerThread，返回false； abstract static class Sync extends AbstractQueuedSynchronizer &#123; final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error("Maximum lock count exceeded"); setState(nextc); return true; &#125; return false; &#125;&#125; package java.util.concurrent.locks;public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer &#123; private volatile int state; protected final int getState() &#123; return state; &#125; protected final void setState(int newState) &#123; state = newState; &#125; &#125; tryAcquire()返回false，执行acquireQueued(addWaiter(Node.EXCLUSIVE), 1) package java.util.concurrent.locks;public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer &#123; private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; enq(node); return node; &#125;&#125; AQSAbstractQueuedSynchronizer类就是与CAS齐名、大名鼎鼎的AQS。 先看AbstractQueuedSynchronizer基类AbstractOwnableSynchronizer，基类很简单，只记录一个线程对象，从变量名看这个线程对象是排他的。 这里的transient是不参加序列化的意思。 package java.util.concurrent.locks;public abstract class AbstractOwnableSynchronizer implements java.io.Serializable &#123; private transient Thread exclusiveOwnerThread; protected final void setExclusiveOwnerThread(Thread thread) &#123; exclusiveOwnerThread = thread; &#125; protected final Thread getExclusiveOwnerThread() &#123; return exclusiveOwnerThread; &#125;&#125; 下面是AbstractQueuedSynchronizer代码 package java.util.concurrent.locks;public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer &#123; private static final Unsafe unsafe = Unsafe.getUnsafe(); private static final long stateOffset; static &#123; stateOffset = unsafe.objectFieldOffset (AbstractQueuedSynchronizer.class.getDeclaredField("state")); &#125; private volatile int state; protected final int getState() &#123; return state; &#125; protected final void setState(int newState) &#123; state = newState; &#125; protected final boolean compareAndSetState(int expect, int update) &#123; // See below for intrinsics setup to support this return unsafe.compareAndSwapInt(this, stateOffset, expect, update); &#125; public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); &#125;&#125; 原理分析lock时，调用AQS的compareAndSetState(0,1)方法将AQS的state=1， AQS Java并行包的锁机制基于AQS框架实现 参考ReentrantLock实现原理深入探究 Java 重入锁 ReentrantLock 原理分析 AbstractQueuedSynchronizer 原理分析 - 独占/共享模式 https://segmentfault.com/a/1190000008471362]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Reentrantlock</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并行包]]></title>
    <url>%2F2018%2F05%2F16%2Fthread-basic-java-concurrent%2F</url>
    <content type="text"><![CDATA[并行包使用Java从1.5开始提供了并发工具包java.util.concurrent，极大简化了多线程编程的难度。源码来自大神Doug Lea的个人贡献，如果你在JDK1.4.2下做过多线程网络编程，你就知道这有多重要。 并发包中提供了高性能且线程安全的集合类以及并发场景中常用的并发锁和原子操作类。本文仅介绍如何使用并发包中的类，对于其底层原理和实现，将另开章节进行讨论。 具体介绍每一个类之前，先做一个横向对比，可以更容易理解并行包引入这些类的目的。 基础类或方法 并行包类 作用 HashMap ConcurrentHashMap Map wait()/notify() BlockingQueue 线程通信 join() CountDownLatch 一个线程等待其他线程 CyclicBarrier 多个线程互相等待，到一个点后共同执行 synchronized Semaphore 控制多线程并发数量 synchronized ReentrantLock 并发锁 Integer AtomicInteger 原子操作类 ConcurrentHashMap先做一个对比 Map类 说明 HashMap 线程不安全，多线程扩容可能出现循环链表导致get()方法空转（JDK1.8以前） HashTable 线程安全，用synchronized锁定读写方法，锁住整个Map，效率低 ConcurrentHashMap 线程安全，使用Segment减小锁的颗粒度，效率高 使用方法和HashMap一样，只需要把new HashMap() 改成new ConcurrentHashMap() 即可。 BlockingQueue顾名思义，这是一个阻塞队列。使用BlockingQueue可以方便的实现线程之间的通信，典型的就是生产者-消费者模式。BlockingQueue一般都是FIFO先进先出的，和排队一样。从下图中可以看出，这就是producer和consumer，换句话说，之前我们通过wait()/notify()自己实现了生产者和消费者，直接使用BlockingQueue也可以达到同样的效果，而且更简单。 下面看看如何使用BlockingQueue实现生产者-消费者 public class BlockingQueueExample &#123; private final static Logger logger = LoggerFactory.getLogger(BlockingQueueExample.class); public static void main(String[] args) throws InterruptedException &#123; // 有界阻塞队列 BlockingQueue queue = new ArrayBlockingQueue(5); // 无界阻塞队列 // BlockingQueue queue = new LinkedBlockingQueue(); // 0阻塞队列 // BlockingQueue queue = new SynchronousQueue(); Producer producer = new Producer(queue); Consumer consumer = new Consumer(queue); new Thread(producer).start(); new Thread(consumer).start(); &#125; public static class Producer implements Runnable&#123; protected BlockingQueue queue = null; protected int count = 0; public Producer(BlockingQueue queue) &#123; this.queue = queue; &#125; public void run() &#123; while (count &lt; 20) &#123; try &#123; count++; queue.put(new Integer(count)); logger.info("put " + count); Thread.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; public static class Consumer implements Runnable&#123; protected BlockingQueue queue = null; public Consumer(BlockingQueue queue) &#123; this.queue = queue; &#125; public void run() &#123; while (true) &#123; try &#123; logger.info("get " + queue.take()); Thread.sleep(500); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;&#125; 首先，创建一个线程共享的BlockingQueue对象， 然后，生产者调用put()方法往队列里放数据，消费者调用take()方法从队列中取数据； 数据按照FIFO的规则先进先出，put()方法新增数据到队列末尾，take()方法从队列头读取并移除数据； put()方法和take()方法都可以阻塞：如果队列满了，put()方法阻塞；如果队列空了，take()方法阻塞。 BlockingQueue是一个接口 package java.util.concurrent;public interface BlockingQueue&lt;E&gt; extends Queue&lt;E&gt; &#123; // Inserts the specified element into this queue, waiting up // to the specified wait time if necessary for space to become available. void put(E e) throws InterruptedException; // Retrieves and removes the head of this queue, waiting if necessary // until an element becomes available. E take() throws InterruptedException;&#125; ArrayBlockingQueue 使用数组实现阻塞队列，队列大小有上限。 LinkedBlockingQueue 使用链表实现阻塞队列，每个元素通过next指针链接到下一个元素；队列默认最大Integer.MAX_VALUE，也可以自定义； SynchronousQueue 队列中最多只能有一个元素，效果和ArrayBlockingQueue(1)是一样的。 看上去很眼熟吧，这就是ThreadPoolExecutor的三种排队策略：有界队列、无界队列和0队列。 CountDownLatchlatch[lætʃ] 是门闩的意思，CountDownLatch就是倒数的门闩。我的理解就是：有N个门锁，一个一个打开，都打开就可以离开了。中文翻译我觉得应该是倒计数锁 。 下面看一个例子：初始化counter计数为2，每次调用counter.countDown(); 计数器减1，counter.await(); 方法阻塞到计数器为0时返回，起到和join()方法一样的效果。 public class CountDownLatchExample &#123; public static void main(String[] args) throws InterruptedException &#123; CountDownLatch counter = new CountDownLatch(2); Task task1 = new Task(1000, counter); Task task2 = new Task(2000, counter); task1.start(); task2.start(); // task1.join(); // task2.join(); counter.await(); System.out.print("done"); &#125; public static class Task extends Thread &#123; private long time = 0; private CountDownLatch counter; public Task(int time, CountDownLatch counter) &#123; this.time = time; this.counter = counter; &#125; @Override public void run() &#123; try &#123; Thread.sleep(time); this.counter.countDown(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; CountDownLatch与join()的联系和区别： CountDownLatch和join()都可以实现主线程等待子线程完成后再继续的效果，例如：我们的测试例子中很多时候main()方法都需要启动子线程，通过CountDownLatch和join()可以准确等到子线程执行完成后输出测试信息，否则我们只能在主线程中Thread.sleep()，看上去就很弱，另外sleep多长时间很不好确定； 调用thread.join()方法必须等thread线程执行完成才返回，而CountDownLatch只要检测到计数器为0就可以返回（thread线程可以在执行过程中进行countDown()操作），所以CountDownLatch通过计数器提供了更灵活的控制机制； 我们通常使用线程池启动子线程，子线程只需要实现runnable接口，这种情况下Thread类对象是封装在线程池里面的，我们不方便拿到，也就不方便调用它的join()方法；使用CountDownLatch就简单多了，只需要在run()方法退出前调用countDown()方法即可； 综上，实战中CountDownLatch的应用场景比join()多。 CyclicBarrier循环栅栏，和CountDownLatch有点像。CountDownLatch是一个线程等待其他线程的任务全部完成或者部分完成，然后才能继续进行。例如：厨艺比赛，大厨有几个助手分别做主菜、配菜、甜点，都好了，大厨宣布完成。CyclicBarrier也是线程等待，但不是一个线程等待其他线程，而是多个线程之间互相等待，都等到一个时间点以后再继续进行。例如：集体旅游，所有人都到达第一个景点以后，再出发去第二个景点。 还是看代码更容易理解 public class CyclicBarrierExample &#123; public static void main(String[] args) &#123; CyclicBarrier barrier = new CyclicBarrier(2, new MainTask()); Task task1 = new Task(1000, barrier); Task task2 = new Task(2000, barrier); task1.start(); task2.start(); &#125; public static class MainTask implements Runnable &#123; @Override public void run() &#123; System.out.println("MainTask run()"); &#125; &#125; public static class Task extends Thread &#123; private long time = 0; private CyclicBarrier barrier; public Task(int time, CyclicBarrier barrier) &#123; this.time = time; this.barrier = barrier; &#125; @Override public void run() &#123; try &#123; Thread.sleep(time); this.barrier.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (BrokenBarrierException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 首先，CyclicBarrier可以指定一个barrierAction，当所有线程都到达barrier后执行； 也可以不指定barrierAction，那么CyclicBarrier看上去就和CountDownLatch很像了。 CyclicBarrier和CountDownLatch的区别： CyclicBarrier是子线程之间的互相等待，在子线程内调用barrier.await(); 相当于这个子线程已经到达栅栏点，等到所有子线程全部到达栅栏点时，所有这些子线程全部同时被唤醒，继续执行； CountDownLatch是主线程等待子线程，各个子线程之间没有关系； CyclicBarrier如果设置了barrierAction，相当于可以触发主线程继续操作。 Semaphore信号量这个词用的比较多，Java中的含义是控制并发线程数量。我们知道synchronized同步代码块有加锁和释放锁的机制，可以认为synchronized只有1把锁，而Semaphore是N把锁。 Semaphore最多可以被锁N次，以后再试图加锁就会失败，必须等前面的线程释放锁。 public class SemaphoreExample &#123; private static Semaphore semaphore = new Semaphore(5); private final static Logger logger = LoggerFactory.getLogger(SemaphoreExample.class); public static void main(String[] args) &#123; ExecutorService threadPool = Executors.newFixedThreadPool(30); for (int i = 0; i &lt; 20; i++) &#123; threadPool.execute(new Runnable() &#123; @Override public void run() &#123; try &#123; logger.info("run"); semaphore.acquire(); Thread.sleep(1000); semaphore.release(); logger.info("done"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); &#125; &#125;&#125; 调用acquire()方法获得锁，计数加1； 调用release()方法释放锁，计数减1； 没有空闲锁的时候acquire()方阻塞等待； ThreadPoolExecutor单独有说明，这里不再重复。 AtomicInteger保证读写是原子操作的Integer。i++ 不是原子操作，实际是三步：第一步从内存读取数据到寄存器，第二步寄存器数值加1，第三步回写寄存器数值到内存。 package java.util.concurrent.atomic;public class AtomicInteger extends Number implements java.io.Serializable &#123; // 增加并返回增加后的值 public final int addAndGet(int delta) &#123;&#125; // 增加并返回增加前的值 public final int getAndAdd(int delta) &#123;&#125; // 等同于addAndGet(1) public final int incrementAndGet() &#123;&#125; // 等同于getAndAdd(1) public final int getAndIncrement() &#123;&#125; // 如果当前值等于expect，将其更新为update，并返回true；否则返回false public final boolean compareAndSet(int expect, int update) &#123;&#125;&#125; 为什么用AtomicInteger替换Integer？还是线程安全问题。 下面的代码，启动100个任务，每个任务自增100次，正确的计算结果应该是10000。但是，如果我们像这么这样写代码，最后输出的sum结果很可能不是10000。原因就在于sum++操作不是线程安全的。 例如：当前主内存中sum的值是100，两个线程同时把100读取到自己的工作内存中，实现+1操作，最后两个线程都回写101到主内存，实际上我的期望值是102。 public class AtomicIntegerExample &#123; private static int sum = 0; public static void main(String[] args) &#123; Task task = new Task(); ExecutorService executorService = Executors.newFixedThreadPool(100); for (int i=0; i&lt;100; i++) &#123; executorService.execute(task); &#125; try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("sum=" + sum); &#125; public static class Task implements Runnable &#123; @Override public void run() &#123; for (int i=1; i&lt;=100; i++) &#123; sum ++; &#125; &#125; &#125;&#125; 使用synchronized可以实现线程安全，但是基于悲观锁的思路，效率太低。可以将int替换为AtomicInteger，既实现线程安全，又保证了效率（基于CAS的乐观锁）。 public class AtomicIntegerExample &#123; private static AtomicInteger integer = new AtomicInteger(); // 改动 public static class Task implements Runnable &#123; @Override public void run() &#123; for (int i=1; i&lt;=100; i++) &#123; integer.incrementAndGet(); // 改动 &#125; &#125; &#125; &#125; 注意：这里使用volatile是不能保证线程安全的，因为++操作线程不安全。 private static volatile int sum = 0; 虽然给sum增加了volatile关键字，但是最后的计算结果也可能不是10000。volatile关键字保证可见性和不重排序，就是每次读数据时，从主内存同步到工作内存，每次回写数据时，立即同步到工作内存。但++操作是在CPU寄存器内的操作，不会立即同步到工作内存，当然也不会立即同步到主内存。 对于任意单个volatile变量的读写具有原子性，但类似于volatile++这种复合操作不具有原子性。 ReentrantLock并发包提供了重入锁，用来代替synchronized public class LockExample &#123; private final static Logger logger = LoggerFactory.getLogger(LockExample.class); public static void main(String[] args) &#123; Lock lock = new ReentrantLock(); Task task1 = new Task(1000, lock); Task task2 = new Task(2000, lock); task1.start(); task2.start(); &#125; public static class Task extends Thread &#123; private long time = 0; private Lock lock; public Task(int time, Lock lock) &#123; this.time = time; this.lock = lock; &#125; @Override public void run() &#123; try &#123; logger.info("run"); lock.lock(); Thread.sleep(time); logger.info("done"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125; &#125;&#125; 以下两种代码是等价的，都可以起到同步锁的作用 使用synchronized synchronized (Task.class) &#123; try &#123; Thread.sleep(time); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;&#125; 使用ReentrantLock try &#123; lock.lock(); Thread.sleep(time);&#125; catch (InterruptedException e) &#123; e.printStackTrace();&#125; finally &#123; lock.unlock();&#125; 注意：请在finally里释放锁。 ReentrantLock能替换synchronized吗 道理上讲，肯定是可以的，实战中根据实际情况选择，没有必要教条的一定要用ReentrantLock。首先，ReentrantLock能实现synchronized的全部功能，而且还提供了更多方法，功能更强大，某些情况下效率也更高。不多，synchronized就一无是处吗？synchronized的好处是简单，在实战中简单就意味着bug少。试想，如果使用ReentrantLock忘记调用lock.unlock(); 或者某些异常情况下lock.unlock(); 没有执行怎么办。功能强大的副作用就是复杂，容易出错。 下面再来看看ReentrantLock增加的功能 并行包中的Lock接口提供了tryLock()功能，注意lock()和unlock()方法都是没有返回值的，lock()如果得不到锁会一直阻塞。tryLock()方法试图立即锁定Lock实例，如果锁定成功 true，如果Lock实例已被锁定返回 false。 package java.util.concurrent.locks;public interface Lock &#123; void lock(); void unlock(); // 如果加锁成功立即返回true // 等待time时间得不到锁返回false boolean tryLock(long time, TimeUnit unit) throws InterruptedException;&#125; tryLock()方法可以避免某个线程由于线程饥饿得不到锁，一直阻塞在lock()，为我们提供了错误处理的机会。 public static class Task extends Thread &#123; private long time = 0; private Lock lock; public Task(int time, Lock lock) &#123; this.time = time; this.lock = lock; &#125; @Override public void run() &#123; boolean getLock = false; try &#123; logger.info("run"); int count = 0; while(!getLock) &#123; getLock = lock.tryLock(100, TimeUnit.MILLISECONDS); count++; if (count &gt; 5) &#123; break; &#125; &#125; if (!getLock) &#123; logger.error("lock failed"); return; &#125; Thread.sleep(time); logger.info("done"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; if (getLock) &#123; lock.unlock(); &#125; &#125; &#125;&#125; 上面为使用tryLock()方法的代码，比使用lock()要复杂一些，但是更加实战。尤其在分布式环境中，抢不到锁时返回错误比阻塞在那里等HTTP调用超时要好得多。 ReadWriteLock读写锁就是两个锁，一个读锁，一个写锁，适合读多写少的情况。读锁可以加锁多次，写锁智能加锁一次。 ReadWriteLock lock = new ReentrantReadWriteLock();lock.readLock().lock();lock.readLock().unlock();lock.writeLock().lock();lock.writeLock().unlock(); 参考并发编程 – Concurrent 用户指南 面试必问的 CAS ，要多了解]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>ConcurrentHashMap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot整合RocketMQ]]></title>
    <url>%2F2018%2F05%2F15%2Frocketmq-starter%2F</url>
    <content type="text"><![CDATA[集成RocketMQ基本实现我们先来回顾一下前面提过的基本用法。 生产者// 启动Producer，可共用DefaultMQProducer producer = new DefaultMQProducer(producerGroupName);producer.setNamesrvAddr(nameServerAddr);producer.start();// 发消息，根据返回状态判断发送是否成功// 默认同步发送，重试次数和超时时间可在创建DefaultMQProducer时配置Message message = new Message(topic, tag, msgKey, msgBody);SendResult sendResult = producer.send(message); 消费者// 创建消息者DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(consumerGroupName);consumer.setNamesrvAddr(nameServerAddr);consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_LAST_OFFSET);// 多个标签中间通过"||"分隔，例如："tag1||tag2||tag3"// 注意：不可以多次调用subscribe()方法，效果为后者替换前者// 例如：consumer.subscribe(topic, tag1); consumer.subscribe(topic, tag2); 只订阅了tag2consumer.subscribe(topic, tags);// 注册消息回调处理方法consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage() &#123; return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125;&#125;// 启动consumer.start(); 官方StarterRocketMQ在2018年给出了官方集成Spring Boot实现 rocketmq-spring-boot-starter 用法如下： 引入pom &lt;dependency&gt; &lt;groupId&gt;org.rocketmq.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;rocketmq-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.0.0.RELEASE&lt;/version&gt;&lt;/dependency&gt; 配置 spring.rocketmq.name-server=192.168.75.159:9876 加注解 @EnableRocketMQpublic class ServiceApplication &#123;&#125; consumer @Slf4j@Service@RocketMQListener(topic = "topic-1")public class MyConsumer1 &#123; @RocketMQMessage(messageClass = String.class,tag = "tag-1") public void onMessage(String message) &#123; log.info("received message: &#123;&#125;", message); &#125;&#125; 从文档和代码都可以看出，官方starter还处于起步阶段，目前只实现了consumer的消息触发机制，还没有封装producer，配置也非常简单，没有幂等性等处理，所以还是等到它成熟以后再用吧。 我的Starter我做的starter在这里 ，目前比官方的功能多一些，也提供Test例子代码。 Github上readme写的挺详细的，这里就不再复述了，欢迎使用、打star、提issue。 下面说一下主要思路和重点。 Producer先说生产者，生产者相对简单一些。思路就是创建一个单例的DefaultMQProducer，在系统启动时start()，以后@Autowired注入以后就可以使用了，非常简单。剩下的就是配置DefaultMQProducer参数的问题了。 DefaultMQProducer本身是支持异步消息发送机制的，这里我只使用了同步发送消息机制，默认重试3次。 Consumer消费者要比生产者复杂，一个AbstractMQProducer对应一个DefaultMQProducer，但是因为Tag的存在，可能多个AbstractMQConsumer对应一个DefaultMQPushConsumer，如果看代码，这里是比较绕的地方。 首先，官方提供了DefaultMQPushConsumer和DefaultMQPullConsumer。虽然从名字上看，应该一个是push，另外一个是pull，但实际上都是pull。我选择的是DefaultMQPushConsumer，用上去更像push。 细心的人可能注意到，消息回调方法consumeMessage()的参数是List&lt;MessageExt&gt; list ，但我们是一个一个消息处理的，这样没有问题吗？现在没有问题是因为默认consumer.setConsumeMessageBatchMaxSize(1); 也就是说这个list的默认长度是1，只有1个元素，如果我们调整了consumeMessageBatchMaxSize参数，那么实现逻辑就需要修改了。 还有，ConsumeFromWhere也是非常重要的一个参数，我现在固定使用CONSUME_FROM_MAX_OFFSET，也就是从最新数据开始消费；实际上还支持CONSUME_FROM_FIRST_OFFSET和CONSUME_FROM_TIMESTAMP，也就是从头消费或者从固定时间点开始消费，现在没有实现。 最后就是扫描注解是如何实现的，其实就一行代码 Map&lt;String, Object&gt; beans = applicationContext.getBeansWithAnnotation(RocketMQConsumer.class);]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>mq</tag>
        <tag>rocketmq</tag>
        <tag>springboot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从JDBC到MyBatis]]></title>
    <url>%2F2018%2F05%2F11%2Fmybatis-step%2F</url>
    <content type="text"></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HashMap源码分析]]></title>
    <url>%2F2018%2F05%2F08%2Fjava-basic-hashmap-sourcecode%2F</url>
    <content type="text"><![CDATA[HashMap解析基本用法分析HashMap源码前，先看看怎么使用。 Map接口首先看一下Map接口，Map接口里面定义了常用的方法。 public interface Map&lt;K,V&gt; &#123; // 大小 int size(); // 是否包含key boolean containsKey(Object key); // 读 V get(Object key); // 写 V put(K key, V value); // 删除 V remove(Object key); // 返回所有key Set&lt;K&gt; keySet(); // 返回所有value Collection&lt;V&gt; values(); // 遍历 Set&lt;Map.Entry&lt;K, V&gt;&gt; entrySet(); // 内部类 interface Entry&lt;K,V&gt; &#123; // 遍历读取key K getKey(); // 遍历读取value V getValue(); &#125;&#125; Map遍历方法一，我认为最正统的写法 for(Map.Entry&lt;String, Object&gt; entry : map.entrySet()) &#123; String key = entry.getKey(); Object value = entry.getValue();&#125; 方法二，意思和上面的方法是一样的，看上去绕一些 Iterator it = map.entrySet().iterator();while (it.hasNext()) &#123; Map.Entry&lt;String, Object&gt; entry = (Map.Entry&lt;String, Object&gt;)it.next(); String key = entry.getKey(); Object value = entry.getValue();&#125; 方法三，先拿到key，再通过get()方法读取value，绕了一圈 for(String key : map.keySet()) &#123; Object value = map.get(key);&#125; 方法四，只能获取value，得不到key for(Object value : map.values()) &#123;&#125; 源码分析基于JDK1.8的源码进行分析。 数据结构先上源码 package java.util;public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt; &#123; // 默认容量16 static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16 // 默认加载因子3/4,当容量到达12时开始扩容 static final float DEFAULT_LOAD_FACTOR = 0.75f; transient int modCount; // 大小 transient int size; // 下一个需要扩容的阈值 int threshold; // 数据存储，是一个数组，数组的大小就是容量 transient Node&lt;K,V&gt;[] table; // 加载因子,默认3/4 final float loadFactor; // 红黑树转换 static final int TREEIFY_THRESHOLD = 8;&#125; table：数组，保存数据； threshold：阈值，当数组中的数据达到这个值以后，对数组进行扩容； HashMap采用了链地址法来解决冲突问题，简单说，就是数组加链表的结合。在每个数组元素上都一个链表结构，当数据被Hash后，得到数组下标，把数据放在对应下标元素的链表上。 如上图所示，HashMap的基本存储结构是一个数组，根据key的hash值取模可以定位到数组的某一个元素，如果有多个key定位到同一个元素，通过链表连接(p1-&gt;next=p2)。读取数据时先根据key的hash值定位到元素，然后再遍历链表查找。如果分布不均匀导致某一个链表很长，就会降低效率。或者说，HashMap的容量间接决定了它的效率：当容量大时，每个key容易落到不同的数组位置上，一次就能读取到；当容量小时，多个key容易发生哈希碰撞，就需要遍历链表，效率自然就降低了。当然，大容量就占用了空间，还是典型的空间换时间。 static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next; Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125;&#125; Node是真实存储键值对的数据结构：Node是HashMap的内部类，实现了Map.Entry接口，其中hash是key的原始哈希值，当扩容时需要用它重新计算数组下标位置，next指向下一个元素，默认为null，也就是说Node可以组成一个链表。 PUT流程先看一下我总结的PUT操作流程，再看源码 GET操作流程 PUT源码第一步，计算哈希值 public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125; static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; 首先需要计算key的哈希值 调用hashCode()方法获取对象的int型哈希值； &gt;&gt;&gt; 16 意思是无符号右移16位； ^ 意思是异或操作，两位相同为0，不同为1（异或可以实现两数交换）； 高16位与0做异或，高位值不变；低16位与高16位做异或，混合高16位和低16位信息（称为扰动）； 为什么要异或（或者为什么要扰动）？ 我们知道hashCode()方法的返回值是int，范围是很大的，如果直接以这个返回值作为数组下标显然内存是不够用的，所以会采用类似取模的办法； 我们知道默认的数组大小是16，那么就是对16取模，相当于hashCode()返回值中只有最后4位起了作用，其他位都没有起到作用；即使int数比较分散，但是最后四位可能碰撞严重；换句话说，精心设计了哈希算法，计算出了分散的32位整数，但实际上只有最后4位起作用，效果可能还不好； 所以在JDK1.7中是这么做的，进行了多次扰动；（让高位与最后四位进行异或运算） h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4); JDK1.8认为四次扰动不必要，一次就够了，所以拿高16位与低16位进行异或计算； 我理解：如果数组大小为16，那么实际上是[0,4)和[16,20)位上的值决定了数组下标位置，其他位的计算是没有用的；当然，数组大小是可以扩容的，如果扩容到64，那么起作用的就是[0,6)和[16,22)位了。 上图充分说明了哈希和取模的过程。 如果容量选择31这样的质数，hash冲突就会小很多，但是取模计算和扩容就复杂了。HashMap才用16这样的非质数容量，必然导致冲突比31这样的质数多，中庸之道就是通过异或运算进行扰动综合。 第二步，取模 if ((p = tab[i = (n - 1) &amp; hash]) == null) &#123; tab[i] = newNode(hash, key, value, null);&#125; i = (n - 1) &amp; hash，假设n=16，那么&amp;15就相当于&amp;00001111，也就是保留hash的后四位的意思。 p=tab[i]就是根据key的hash值最终计算出来数组下标位置。 如果这个位置上的元素是空的，直接创建Node对象放到这里即可。 当n为2的x次方时，&amp; (n-1)操作就起到了取模的作用，这就是为什么HashMap的容量总是2的x次方的原因。如果不是，那么%取模操作效率是很低的。 第三步，元素链表 if ((p = tab[i = (n - 1) &amp; hash]) == null) &#123; tab[i] = newNode(hash, key, value, null);&#125; else &#123; Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; // 如果当前元素hash值和key的hash值一样，直接返回e e = p; &#125; else if (p instanceof TreeNode) &#123; // 红黑树特殊处理 e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); &#125; else &#123; // 遍历链表 for (int binCount = 0; ; ++binCount) &#123; // 找到链表最后一个元素 if ((e = p.next) == null) &#123; // 新数据加入到链表末尾 p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st // 当元素个数达到8个时，转换为红黑树存储 treeifyBin(tab, hash); break; &#125; // 链表里某个元素hash值和key的hash值一样，直接返回e if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; // 如果元素已经存在（hash值存在），直接返回 if (e != null) &#123; // existing mapping for key V oldValue = e.value; // 返回的一定是旧值，是否替换为新值需要onlyIfAbsent=false，默认false替换 if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125;&#125; 定位到数组位置后，遍历链表查找key是否存在，如果key存在直接返回value，不存在把新元素加入到链表末尾。 如果key存在，返回值一定是旧的value，至于是否使用新value替换旧value可以设置，默认是替换的。 put()方法是有返回值的，如果返回null不是说put()操作失败了，说明key不存在；如果返回值不为空，说明key存在，没有写入新数据，直接返回了存在的value。 key可以是null的，定位到数组0位置，但key是唯一的，所以只能有一个null的key。 比较key的时候是根据hash值进行比较的，所以使用String做key感觉比使用Object做key更放心一些。 第四步，扩容 // 简化代码final Node&lt;K,V&gt;[] resize() &#123; // 旧数据 Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; // 扩容一倍 newCap = oldCap &lt;&lt; 1; &#125; else &#123; // 使用默认值初始化 newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr == 0) &#123; // 重新计算阈值=容量*因子 newThr = (float)newCap * loadFactor; &#125; threshold = newThr; // 扩容后的新数据 Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; // 数据迁移 if (oldTab != null) &#123; // 遍历旧数据 for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) &#123; // 只有一个元素，直接复制，根据key的原始哈希值重新计算数组下标 newTab[e.hash &amp; (newCap - 1)] = e; &#125; else if (e instanceof TreeNode) &#123; // 红黑树特殊处理 ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); &#125; else &#123; // preserve order // 链表情况 Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; // 遍历链表 next = e.next; if ((e.hash &amp; oldCap) == 0) &#123; // 位置不变 if (loTail == null) loHead = e; else // 顺序不变 loTail.next = e; loTail = e; &#125; else &#123; // 位置+oldCap if (hiTail == null) hiHead = e; else // 顺序不变 hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; // 低位链表 newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; // 高位链表 newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab; &#125; 扩容优化这部分代码是JDK1.8优化过的，需要解释一下。 Map&lt;String, Integer&gt; map = new HashMap(4);map.put("A", 90);map.put("E", 85);map.put("I", 80);map.put("M", 70); 我们通过上面的实际例子来说明。为了简单，初始化容量为4，默认因子0.75，阈值为3。当put(“M”)时容量超过阈值，启动扩容操作。 扩容从4增加到8，我们看一下数组下标计算的变化： hash(A)=01000001, hash(E)=01000101, hash(I)=01001001, hash(M)=01001101 容量为4的情况，截取最后两位，AEIM的最后两位都是01，对应的数组 01000001&amp;0011=01, 01000101&amp;0011=01, 01001001&amp;0011=01, 01001101&amp;0011=01 容量为8的情况，截取最后三位，AI的最后三位是001，EM的最后三位是101 01000001&amp;0111=001, 01000101&amp;0111=101, 01001001&amp;0111=001, 01001101&amp;0111=101 以上，可以看出：扩容以后，由于只是多截取了一位，所以数组下标或者不变，或者增加4（旧容量）。 因此，扩容时就不需要重新计算链表中每一个元素的新位置，要么不变，要么增加旧容量，所以才有了上面的算法：设立两个指针，loHead指向位置不变的，hiHead指向增加4的。了解了原理以后，我们再来看代码。 if ((e.hash &amp; oldCap) == 0) 注意，oldCap第一位是1，其他位都是0，所以&amp; oldCap相当于判断hash值中新增加的哪一位的值。例如：继续上面的例子oldCap=100，hash(A)=01000001，01000001&amp;100=0，其实就是在判断hash(A)的倒数第三位的值。我们知道原来只截取后两位，倒数第三位就新增的截取位。如果这一位等于0，数组下标就不变，如果这一位等于1，数组下标就加4。 所以，当(e.hash &amp; oldCap) == 0时，将元素添加到loHead链表中，== 1时，将元素添加到hiHead链表中。 这样，遍历完旧数据后，就根据倒数第三位的值把就数据分为两份：loHead和hiHead，最后把它们放到数组中。 newTab[j] = loHead;newTab[j + oldCap] = hiHead; 红黑树注意到put()代码里面有对TreeNode的特殊处理，这是JDK1.8新增加的红黑树。当链表很长时，遍历链表必然降低效率，所以当链表中元素个数超过8个时，不再使用链表，而改为使用红黑树存储，这样在get()时可以提高效率。 死循环HashMap是线程不安全的，下面来具体分析一下多线程put()操作引起的get()方法死循环问题。 这个问题也可以描述成HashMap引发的CPU 100%问题，查看堆栈程序都Hang在HashMap.get()这个方法上，因为get()出现死循环，所以一直占用CPU。 首先，死循环的原因一定是链表出了问题，出现了循环链表。如果多线程并发put()操作出了问题，导致出现了循环列表，那么当get()查询到这个链表时，就会进入死循环出不来。 原理清楚了，下面看看具体的实例。 注意，例子是基于JDK1.7的，因为JDK1.7及以下才有这个问题。 void resize(int newCapacity) &#123; Entry[] oldTable = table; int oldCapacity = oldTable.length; // 创建一个新的Hash表 Entry[] newTable = new Entry[newCapacity]; // 数据迁移 transfer(newTable); table = newTable;&#125;void transfer(Entry[] newTable) &#123; int newCapacity = newTable.length; // 遍历旧数据 for (Entry&lt;K,V&gt; e : table) &#123; while(null != e) &#123; Entry&lt;K,V&gt; next = e.next; // 重新计算新容量下的数组下标 int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; &#125; &#125;&#125; JDK1.8保持了链表的顺序不变，所以不会出现循环链表的情况了，也就不会出现死循环了。虽然不会出现死循环了，但是还有可能出现其他问题，所以仍然不是线程安全的，在多线程环境下不建议使用。 首先来看单线程的情况： 旧数据容量2，key的哈希值是3、7、5，都存储在table[1]，新数据容量4，table[1]=5，table[3]=3、7； 数据迁移算法：遍历全部旧数据，将其从旧链表中摘下，插入到新链表的最前面。 接下来考虑多线程的情况，假设两个线程A和B，A线程执行到next = e.next; 时被挂起，B线程一直执行完成，那么当前状态如下：粉色表示线程A、天蓝色表示线程B。 接下来线程A继续执行，当前e=3,next=7。将3插入到table[3]开头，然后，e=next=7。 下一个循环，e=7，next=3，将7插入到table[3]开头，然后e=next=3。 下一个循环，e=3，next=null，将3插入到table[3]开头，e=next=null。循环结束，最后的结果如下，形成了循环链表。 此时，如果线程A调用get(11)就会进入无限循环，问题重现。 Debug默认debug时是不能调试JDK源码的，具体体现就是单步执行和加断点失败，为了调试JDK源码需要修改配置： Setting –&gt; Build,Execution,Deployment –&gt; Debugger –&gt; Stepping 把Do not step into the classes中的java.* 和javax.* 取消勾选 参考JDK 源码中 HashMap 的 hash 方法原理是什么？ Java集合：HashMap源码剖析 Java8系列之重新认识HashMap 疫苗：Java HashMap的死循环 漫画：什么是HashMap？ 漫画：高并发下的HashMap s=>start: 开始 hash=>operation: 计算key的哈希值 table=>condition: 数组是否为空? init=>operation: 初始化数组(16) mod=>operation: 去模计算数组下标 node=>condition: 下标位置元素是否为空? newNode=>operation: 创建Node对象放入数组 nodeLink=>operation: 遍历链表到末尾 newLinkNode=>operation: 创建Node对象加入链表末尾 addSize=>operation: 增加容量 size=>condition: 容量达到阈值？ resize=>operation: 扩容 e=>end: 结束 s->hash->table table(yes)->init->mod table(no)->mod mod->node node(yes)->newNode node(no)->nodeLink->newLinkNode newNode->addSize newLinkNode->addSize addSize->size size(yes)->resize size(no)->e resize->e{"theme":"simple","scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12} var code = document.getElementById("flowchart-0-code").value; var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-0-options").value)); var diagram = flowchart.parse(code); diagram.drawSVG("flowchart-0", options);]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Hashmap</tag>
        <tag>哈希冲突</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库原理]]></title>
    <url>%2F2018%2F05%2F07%2Fdatabase-theory%2F</url>
    <content type="text"><![CDATA[数据库原理基础知识时间复杂度时间频度用以描述一个算法处理一定量数据需要花多长时间。这里的时间不是常规意义上的时分秒，那依赖于硬件环境，没有意义；这里的时间指的是运算次数，运算次数的多少决定了时间多少的相对值，运算次数多的相对执行时间就长。 数据量不同，运算次数就不同，所以比较绝对运算次数也是没有意义的；实际上比较的是当数据量增加时，运算次数增加的趋势，这就是时间复杂度；好的算法不会随着数据量的增加和翻倍增加运算次数。 下图列出了常见的时间复杂度，展示了当数据量增加时，运算次数增加的趋势。 从低到高解释一下上述算法时间复杂度，以需要处理2000条数据为例： O(1)：只需要执行一次运算； O(log(n))：需要执行7次运算； O(n)：需要执行2000次运算； O(n*log(n))：需要执行14,000次运算； O(n^2)：需要执行4,000,000次运算； O(n!)：溢出了。 以查找为例，查找不同数据的情况所需的运算次数是不一样的；当我们讨论一个算法的时间复杂度时，都以平均情况为例进行讨论。 常见排序和查找方法的时间复杂度 算法 平均时间复杂度 最坏时间复杂度 冒泡排序 O(n^2) O(n^2) 快速排序 O(n^2) O(n*log(n)) 二叉树排序 O(n^2) O(n*log(n)) 堆排序 O(n*log(n)) O(n*log(n)) 顺序查找 O(n) 二分查找 O(log(n)) 二叉排序树查找 O(log(n)) 哈希表法 O(1) 合并排序排序树二叉查找树是带有特殊属性的二叉树，每个节点的关键字必须： 比保存在左子树的任何键值都要大 比保存在右子树的任何键值都要小 B+树哈希表数据库数据库是由多种互相交互的组件构成的。 客户端管理器客户端管理器是处理客户端通信的。 查询管理器事务管理器一个ACID事务是一个工作单元，它要保证4个属性： 原子性（Atomicity）: 事务『要么全部完成，要么全部取消』，即使它持续运行10个小时。如果事务崩溃，状态回到事务之前（事务回滚）。 隔离性（Isolation）: 如果2个事务 A 和 B 同时运行，事务 A 和 B 最终的结果是相同的，不管 A 是结束于 B 之前/之后/运行期间。 持久性（Durability）: 一旦事务提交（也就是成功执行）,不管发生什么（崩溃或者出错），数据要保存在数据库中。 一致性（Consistency）: 只有合法的数据（依照关系约束和函数约束）能写入数据库，一致性与原子性和隔离性有关。 经典的例子是从账户A到账户B的汇款。假设有2个事务： 事务1（T1）从账户A取出100美元给账户B 事务2（T2）从账户A取出50美元给账户B 我们回来看看ACID属性： 原子性确保不管 T1 期间发生什么（服务器崩溃、网络中断…），你不能出现账户A 取走了100美元但没有给账户B 的现象（这就是数据不一致状态）。 隔离性确保如果 T1 和 T2 同时发生，最终A将减少150美元，B将得到150美元，而不是其他结果，比如因为 T2 部分抹除了 T1 的行为，A减少150美元而B只得到50美元（这也是不一致状态）。 持久性确保如果 T1 刚刚提交，数据库就发生崩溃，T1 不会消失得无影无踪。 一致性确保钱不会在系统内生成或灭失。 原子性和一致性太像了？ SQL一般定义4个隔离级别： 串行化(Serializable，SQLite默认模式）：最高级别的隔离。两个同时发生的事务100%隔离，每个事务有自己的『世界』。 可重复读（Repeatable read，MySQL默认模式）：每个事务有自己的『世界』，除了一种情况。如果一个事务成功执行并且添加了新数据，这些数据对其他正在执行的事务是可见的。但是如果事务成功修改了一条数据，修改结果对正在运行的事务不可见。所以，事务之间只是在新数据方面突破了隔离，对已存在的数据仍旧隔离。举个例子，如果事务A运行”SELECT count(1) from TABLE_X” ，然后事务B在 TABLE_X 加入一条新数据并提交，当事务A再运行一次 count(1)结果不会是一样的。这叫幻读（phantom read）。 读取已提交（Read committed，Oracle、PostgreSQL、SQL Server默认模式）：可重复读+新的隔离突破。如果事务A读取了数据D，然后数据D被事务B修改（或删除）并提交，事务A再次读取数据D时数据的变化（或删除）是可见的。这叫不可重复读（non-repeatable read）。 读取未提交（Read uncommitted）：最低级别的隔离，是读取已提交+新的隔离突破。如果事务A读取了数据D，然后数据D被事务B修改（但并未提交，事务B仍在运行中），事务A再次读取数据D时，数据修改是可见的。如果事务B回滚，那么事务A第二次读取的数据D是无意义的，因为那是事务B所做的从未发生的修改（已经回滚了嘛）。这叫脏读（dirty read）。 TODO 结合事务 参考 如果有人问你数据库的原理，叫他看这篇文章]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从短地址说起]]></title>
    <url>%2F2018%2F05%2F07%2Fweb-short-url%2F</url>
    <content type="text"><![CDATA[短地址短地址（也叫Short URL）就是为了让一个很长的网站链接缩短为一个短的链接，短地址最初的出现是因为微博内有字数限制，现在短地址的应用领域越来越广泛。 小型业务中，我们通常使用免费的第三方服务来实现短地址转换。如果需要自己实现，该怎么做呢，本文给出方案和思考。单纯就短地址服务来说，的确不需要自己来实现，但仔细思考一下其实现原理和细节，对于我们理解哈希、分片等概念都有帮助。 需求业务上有发营销短信的需求，短信内容中带有APP下载地址。由于短信字数有限制（100个左右），很可能一个链接地址长度就超过了总字数限制，所以要使用短地址。 例如：下面为客户端1.5.1安卓版本的下载地址，仅链接地址就超过了100个字符。 http://imtt.dd.qq.com/16891/EB45FB72BADD5F2C0EBF02C906AAFCD6.apk?fsname=com.zjinv.kingold_1.5.1_15.apk&amp;csr=1bbd 进一步，还可以根据短地址生成二维码。 托管实现实际工作中，我们可以通过短地址服务平台来实现。这些平台提供了将长地址转换为短地址的功能。 新浪: http://sina.lt/ sina.lt/t.cn/ 百度: http://dwz.cn/ dwz.cn 例如：通过新浪提供的服务，我们把一篇博客的长地址转换为短地址，然后使用即可，新浪帮我们完成页面跳转。 长地址：https://my.oschina.net/didispace/blog/1807876 短地址：http://t.cn/Rukpf81 自己实现以上是通过第三方服务实现短链接，下面来看看如何自己实现。 哈希首先，容易想到调用String类的hashCode()方法，将一个字符串转换为一个int值，然后再将10进制的int值转换为16进制字符串就实现了短地址。下面为例子代码： public class HashExample &#123; public static void main(String[] args) &#123; String url = "https://my.oschina.net/didispace/blog/1807876"; int hashCode = url.hashCode(); String code = String.format("%x", hashCode); System.out.println("http://t.cn/" + code); &#125;&#125; 输出如下 http://t.cn/70fcf5cf 我们已经实现了长地址到短地址的映射（当然，还需要存储起来供查询）。但是，这种做法是有问题的。因为有可能产生冲突，也就是说两个不一样的url地址，计算出来的hash值一样，导致它们的短地址一样。 我们把两个对象生成的hash值一样的情况成为哈希冲突，哈希冲突需要做专门的处理，请参考HashMap的做法。 hashCode()下面我们先来看看hashCode()方法是如何实现的。 通常意义上，hashCode()是Object类的方法，返回的是对象在JVM堆上的内存地址，不同对象的堆内存地址不同，hash值就不同。也就是说，在一个JVM内我们能够保证不同对象的hashCode()不同，但是不同JVM之间就不能保证了。 public class Object &#123; public native int hashCode(); &#125; 但是，String类重载了Object类的hashCode()方法，没有使用内存地址，自定义了自己的实现，代码如下： public final class String&#123; public int hashCode() &#123; int h = hash; if (h == 0 &amp;&amp; value.length &gt; 0) &#123; char val[] = value; for (int i = 0; i &lt; value.length; i++) &#123; h = 31 * h + val[i]; &#125; hash = h; &#125; return h; &#125;&#125; 算法如下，从第一个字符开始，第i字符转换为int，然后乘以31的n-i次方，然后加和，计算哈希值。 hashCode=s[0]*31^(n-1)+s[1]*31(n-2)+s[2]*31^(n-3)+......+31*s[n-1]+s[n] ASCII码表如下，这里可以查看到每个字符对应的int值 字符 10进制 16进制 字符 10进制 16进制 A 65 0x41 a 97 0x61 B 66 0x42 b 98 0x62 Z 90 0x5A z 122 0x7A 0 48 0x30 . 46 0x2E 1 49 0x31 / 47 0x2F 9 57 0x39 : 58 0x3A 字符串”ab”的hashCode 97*31+98=3105 字符串”ABC”的hashCode 65*31*31+66*31+67=64578 这种算法有可能出现两个字符串的哈希值一样的情况，例如：”hierarch”和”crinolines”的哈希值一样，”buzzards” 和 “righto”和哈希值也相同。 为什么是31为什么乘以31的n次方，不是2，不是32，不是101呢？ 31是一个不大不小的质数，是作为 hashCode 乘子的优选质数之一。另外一些相近的质数，比如37、41、43等等，也都是不错的选择。选择质数作为因子是数学理论，可以保证： 冲突率尽量低； 分布率尽量广，计算出来的hash值分散广泛，自然冲突就少，本质和冲突率低是一样的。 31可以被 JVM 优化，方便计算，31 * i = (i &lt;&lt; 5) - i。 一定不能选取2的整数幂，例如：2，4，16，32，64等，因为乘以2的整数幂，相当于左移；左移时丢弃高位，地位补零，相当于丢失了信息，特别容易发生冲突。 自增既然哈希可能有冲突，不能使用，那么我们来看看另外一种思路，使用数据库自增ID的方法。 建一张表，主键是bigint自增ID，内容是长地址即可。短地址只需要将10进制bigint转换成62进制即可。 为什么62进制？A-Z(26)+a-z(26)+0-9(10)=62。 每收到一个地址转换请求，就往数据库表里面增加一条记录，建立对应关系。访问时将62进制短地址转换为ID就可以根据主键快速查询到长地址。 使用这个方法，每收到一个请求就往数据库中添加一条新的记录，长地址是可以重复的。多个短地址都指向同一个长地址，操作不会出错，但是占用的多余的存款空间。 改进下面看看如何改进，保证每个长地址对应唯一的短地址： 方案一：首先，最容易想到：每次插入前先查询一次数据库表，如果长地址存在，直接返回主键，如果长地址不存再添加；当数据库量大时，这么操作效率太低，首先排除。 方案二：再进一步，查询数据库太慢，我们可以把长地址和短地址的对应关系冗余存储到redis中，插入数据库前先查询redis；这种方法减小了数据库压力，但是redis中使用hash表存储所有对应关系，占用空间也很大； 方案三：继续优化，既然redis的问题是占用空间太大，那么我们是否可以不保存所有的对应关系，只保留最近的对应关系；使用LRU算法可以在保证一定命中率的前提下减少存储空间占用。（可以这么做的前提是我们认为有些地址热度较高，经常会被引用到）。 前面都只考虑了单机的情况，如果并发量巨大，一台数据库服务器处理不过来，那么就需要继续优化了： 方案一：数据库分片，例如：分4个db，每个起始值+1（1，2，3，4），步长4。 方案二：使用snowflake等分布式ID生成器生成ID。 重定向最后，还有一个页面重定向的问题，我们来看看操作过程： 用户访问短地址http://t.cn/Rukpf81 t.cn服务器收到请求，将Rukpf81 转换为主键3038198013989 查询到长地址https://my.oschina.net/didispace/blog/1807876 t.cn服务器返回HTTP 302，在HTTP的Location中设置长地址 浏览器重定向请求到长地址 注意：HTTP 301和302重定向的区别： 301永久重定向，SEO用新页面替换旧页面 302临时重定向，SEO认为是新旧是两个页面 进制转换62进制转10进制的源码： 也可以设置因子factor=1，从最后一位开始计算，每次factor = factor*62； 代码算法参考了String类的hashCode()实现，因为每次都有value 62，所以第一位实际上做了n-1次 62操作，与乘以62的n-1次方结果是一样的。 public final char[] array = "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ" .toCharArray();private long _62_to_10(String code) &#123; long value = 0; for (int i=0; i&lt;code.length(); i++) &#123; value = value * 62 + _62_2_10(code.charAt(i)); &#125; return value;&#125;private int _62_2_10(char c) &#123; for (int i=0; i&lt;array.length; i++) &#123; if (c == array[i]) &#123; return i; &#125; &#125; return 0;&#125; 计算结果 Rukpf81=3038198013989 10进制转62进制的源码： 每一次计算出来的余数是当前最低位的值，商用于下一次计算； 最后做字符串反转。 static String _10_to_62(long value) &#123; StringBuffer buffer = new StringBuffer(); while(value &gt; 0) &#123; int v = (int)(value % 62); buffer.append(array[v]); value = value / 62; &#125; return buffer.reverse().toString();&#125; 注意：int v = (int)(value % 62); 不能写成int v = (int)value % 62; ，精度截断后计算结果就错了。]]></content>
      <categories>
        <category>WEB</category>
      </categories>
      <tags>
        <tag>WEB</tag>
        <tag>短地址</tag>
        <tag>哈希</tag>
        <tag>hashCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL索引]]></title>
    <url>%2F2018%2F05%2F04%2Fmysql-index%2F</url>
    <content type="text"><![CDATA[MySQL索引索引和事务是MySQL最重要的两个概念，而Innodb存储引擎的索引结构又是事务的基础，可谓重中之重。本文从二叉搜索树说起，直到B+树，详细解释MySQL索引的数据结构，试图从底层探究索引原理。 数据结构基础从查找说起，数据库查询就是查找的一种，不同的存储结构（数据结构）决定了查找的方法和效率。先从数据结构的角度看看为什么选用B树作为索引的数据结构。 二叉树二叉树：每个节点最多有两个子节点。 节点的度：一个节点拥有的子树的个数。 满二叉树：除叶子节点外，其他节点都有两个子节点。满二叉树的最大特点是每一层次的结点数都达到最大值。 完全二叉树：只有最底层不满，最底层从左侧开始没有空的。 二分查找树也叫二叉搜索树（BST树），首先是二叉树，其次每个节点上的值是有规律的： 左子树上所有结点的值均小于它的根结点的值； 右子树上所有结点的值均大于它的根结点的值。 查找的时候，从根节点开始比较，小于根的值就从左子树中递归查找，大于根的值就从右子树中递归查找。 添加节点也是一样，从根节点开始，递归找到合适的节点位置并添加。 删除节点麻烦一些，如果删除叶子节点比较简单，直接删除即可；如果删除非叶子节点，需要对数进行调整。 先序遍历二分查找树输出的结果就是排序结果。 下图为一颗二分查找树的例子。 AVL树高度平衡二叉树，也叫平衡二叉树，在AVL树中任何节点的两个子树的高度最大差为一，这里不展开。 红黑树前面提到的都是基础知识，在实战中使用的不多，常见的是由它们逐步引出的红黑树，JDK1.8中TreeMap和HashMap都用到了红黑树(Red Black Tree)。 从二叉树的发展来看，红黑树是一颗相对平衡的二叉树；二叉树–&gt;二叉搜索树–&gt;平衡搜索二叉树–&gt; 红黑树；红黑树具有如下特点： 节点要么是黑色，要么是红色； 根和叶子节点都是黑色的； 不能有连续两个红色的节点； 从任一节点到它所能到达得叶子节点的所有简单路径都包含相同数目的黑色节点。 下图为一颗红黑树的例子，本文重点为了引出B+树，红黑树不展开。 为什么要引入红黑树？ 二分查找树时间复杂度是O(log(n))，不是效率就已经够高了吗，直接使用不行吗？为什么还要发展到红黑树呢？因为二分查找树的运行时间取决于树的形状，树的高度越高，查询效率越低。试想最极端的情况，所有节点都只有右子树，那么查找最大的树需要遍历所有节点，相当于顺序查找。所以有了平衡的概念，越平衡的二分查找树效率越高。 想一下，二分查找树的高度就是最大的查询次数，所以树越高，效率越低。AVL树是高度平衡二叉树，红黑树是相对平衡二叉树，都是为了减小树的高度，提供查找效率。 以上可知，引入红黑树就是为了平衡。平衡的方法有三种：变色、左旋、右旋。 B树(B-tree)B通常认为是Balance的简称，B树不是二叉树。一棵m阶B树(balanced tree of order m)是一棵平衡的m路搜索树。一颗M阶B树是一颗平衡的M路搜索树，它或者是空树，或者满足下列条件： 根结点至少有两个孩子； 每个中间节点都包含k-1个元素和k个孩子，其中 M/2 &lt;= k &lt;= M；(向上取整) 每个叶子节点都包含k-1个元素，其中 M/2 &lt;= k &lt;= M；(向上取整) 每个节点中的元素从小到大升序排列；节点当中k-1个元素正好是k个孩子包含的元素的值域划分； 所有的叶子节点都在同一层。 B树在插入时可能需要调整节点进行自平衡，删除也是一样；添加和删除节点后，可能导致不满足B+树条件，这个时候就需要调整，这个调整的过程称为自平衡。 我认为，二分查找树可以看作2阶的B树：每个节点都只有1个键值，2个子节点，左边子节点键值小于父节点键值，右边子节点键值大于父节点键值。以此类推，3阶的情况如下：每个节点有1-2个键值，1个键值的情况同上；如果有2个键值，那么有3个子节点。第N个子节点的键值位于父节点[N-1,N]键值之间。 以5阶B树为例，每个节点最多有4个元素，5个孩子。假设元素值为 (10, 20, 30, 40)，那么5个子节点的元素值范围是c0 &lt;10，10 &lt; c1 &lt; 20，20 &lt; c2 &lt;30，30 &lt; c3 &lt; 40，c4 &gt; 40 ，也就是分布于左右。 为什么引入B树？ 我认为，B树是红黑树的升级版，更合适外部排序。换句话说，如果排序和查找都在内存中完成，那么红黑树就够用了，是很优秀的方案；如果排序和查找涉及到外部数据，也就是在磁盘上的数据，那么红黑树就不能满足要求了，所以引入了B树。B树在自平衡等很多算法上和红黑树是一样的，但是B树中一个节点可以保存更多的键值，一是减少了磁盘I/O，二是大大减小了树的高度。 B+树B树有很多变种，B+树就是其中一种，MySQL使用B+树(实际上是B*树)作为索引的数据结构。 B+树与B树最重要的区别： B树所有节点都保存数据，B+树只有叶子节点保存数据； B*树基于B+树继续优化，增加顺序指针。 每个叶子节点增加一个指向相邻叶子节点的指针；这样可以提高区间查询的效率，例如：where age &gt;= 30 and age &lt; 50； MySQL索引基础索引分为聚簇索引和非聚簇索引两种，聚簇索引是按照数据存放的物理位置为顺序的，而非聚簇索引就不一样了；聚簇索引能提高多行检索的速度，而非聚簇索引对于单行的检索很快。 索引类型 按照索引数据和源数据是否分开存储，索引分为聚簇索引和非聚簇索引两种。 聚簇索引：索引数据和源数据存储在一起，或者说源数据就是按照主键作为索引组织的，Innodb存储引擎使用聚簇索引。 非聚簇索引：索引数据和源数据分开存储，MyISAM存储引擎使用非聚簇索引，数据文件有三个：.frm 文件存储表结构，.MYD 文件存储表数据，.MYI 文件存储索引数据。 按照使用类型，索引可以分为普通索引、唯一索引、全文索引和复合索引 普通索引 CREATE INDEX index_name ON table_name(column(length));ALTER TABLE table_name ADD INDEX index_name ON (column(length));DROP INDEX index_name ON table_name; 唯一索引 与普通索引类似，不同的是索引列的值必须唯一，但允许有空值（注意和主键不同）。 CREATE UNIQUE INDEX indexName ON table_name(column(length));ALTER TABLE table_name ADD UNIQUE indexName ON (column(length)); 全文索引 FULLTEXT索引只适用于 MyISAM，一般不用。 复合索引 顾名思义，复合索引是由2个或者更多字段组合而成的索引。普通索引和唯一索引都是单字段的。 CREATE INDEX index_name ON table_name(column1(length1), column2(length2));ALTER TABLE table_name ADD INDEX index_name (column1(length1), column2(length2)); 注意，复合索引遵循最左前缀原则，上面的SQL实际上建立了column1和column1+column2两个索引。 最左前缀原则，就是从最左侧开始组合，如果创建了column1、column2、column3复合索引，那么实际上已经有了如下三个索引，无需在单独在column1上建索引，但是column2和column3是没有索引的： column1 column1+column2 column1+column2+column3 安装数据结构，索引可以分为BTREE索引和HASH索引 BTREE索引，就是使用B+/B*树存储索引，前面说过。 HASH索引， MySQL索引原理MySQL索引使用改进的B+树来实现。 为什么用B+树存储索引为什么不使用二分查找树来实现索引呢？二分查找树效率也很高啊，时间复杂度O(log(n))。 如果索引全部在内存中，那么使用二分查找树是没有问题的。但实际情况中，索引文件可能很大，不可能全部加载到内存中，这就意味着对索引的访问涉及到磁盘I/O。也就是说，虽然二分查找树算法的比较次数少，但是需要去和磁盘上的索引数据进行比较，访问太慢，虽然次数少，但是时间长。 简单分析一下磁盘I/O，磁盘由磁片和磁头组成，磁片旋转 那么，B+树难道就不需要访问磁盘I/O了，内存同样放不下啊。实际操作中，我们每次加载磁盘一页的数据到内存中，MySQL索引B+树的每一个节点就保存一页数据，可以一次加载到内存中。这样，虽然比较次数多了，但是磁盘I/O次数少了，整体还是高效的。 二分查找树（二叉搜索树）本质上是二叉树，当数据量比较大时，树的高度一定非常高。B+树是多路搜索树，当阶数比较大时，树的高度可以很低。如果索引数据需要从磁盘加载，那么树的高度就决定了磁盘I/O的次数，也就决定了执行速度。 以查找数据10为例，二分查找树需要4次比较和4次磁盘I/O； MyISAM实现MyISAM引擎使用B+Tree作为索引结构，叶节点的data域存放的是数据记录的地址。MyISAM的索引方式也叫做“非聚簇索引”。 在MyISAM中，主索引和辅助索引（Secondary key）在结构上没有任何区别，只是主索引要求key是唯一的，而辅助索引的key可以重复。 InnoDB实现虽然InnoDB也使用B+Tree作为索引结构，但具体实现方式却与MyISAM截然不同。 第一个重大区别是InnoDB的数据文件本身就是索引文件。从上文知道，MyISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址。而在InnoDB中，表数据文件本身就是按B+Tree组织的一个索引结构，这棵树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。 因为InnoDB的数据文件本身要按主键聚集，所以InnoDB要求表必须有主键（MyISAM可以没有），如果没有显式指定，则MySQL系统会自动选择一个可以唯一标识数据记录的列作为主键，如果不存在这种列，则MySQL自动为InnoDB表生成一个隐含字段作为主键，这个字段长度为6个字节，类型为长整形。所以，表必须要有主键。 第二个与MyISAM索引的不同是InnoDB的辅助索引data域存储相应记录主键的值而不是地址。换句话说，InnoDB的所有辅助索引都引用主键作为data域。聚集索引这种实现方式使得按主键的搜索十分高效，但是辅助索引搜索需要检索两遍索引：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录。 知道了InnoDB的索引实现后，就很容易明白为什么不建议使用过长的字段作为主键，因为所有辅助索引都引用主索引，过长的主索引会令辅助索引变得过大。 B+Tree 中的B是指 balance ，意为平衡。需要注意的是，B+树索引并不能找到一个给定键值的具体行，它找到的只是被查找数据行所在的页，接着数据库会把页读入到内存，再在内存中进行查找，最后得到要查找的数据。 MySQL索引使用高效使用索引的首要条件是知道什么样的查询会使用到索引，这个问题和B+Tree中的“最左前缀原理”有关，下面通过例子说明最左前缀原理。 复合索引索引失效索引命中 &lt;，&lt;=，=，&gt;，&gt;=，BETWEEN，IN, like &#39;xx%&#39; 索引不能命中 &lt;&gt;，not in ，!=，like &#39;%xx&#39; 1.索引不存储null值 更准确的说，单列索引不存储null值，复合索引不存储全为null的值。索引不能存储Null，所以对这列采用is null条件时，因为索引上根本 没Null值，不能利用到索引，只能全表扫描。 为什么索引列不能存Null值？ 将索引列值进行建树，其中必然涉及到诸多的比较操作。Null值的特殊性就在于参与的运算大多取值为null。 这样的话，null值实际上是不能参与进建索引的过程。也就是说，null值不会像其他取值一样出现在索引树的叶子节点上。 2.不适合键值较少的列（重复数据较多的列） 假如索引列TYPE有5个键值，如果有1万条数据，那么 WHERE TYPE = 1将访问表中的2000个数据块。 再加上访问索引块，一共要访问大于200个的数据块。 如果全表扫描，假设10条数据一个数据块，那么只需访问1000个数据块，既然全表扫描访问的数据块 少一些，肯定就不会利用索引了。 3.前导模糊查询不能利用索引(like ‘%XX’或者like ‘%XX%’) 假如有这样一列code的值为’AAA’,’AAB’,’BAA’,’BAB’ ,如果where code like ‘%AB’条件，由于前面是 模糊的，所以不能利用索引的顺序，必须一个个去找，看是否满足条件。这样会导致全索引扫描或者全表扫 描。如果是这样的条件where code like ‘A % ‘，就可以查找CODE中A开头的CODE的位置，当碰到B开头的 数据时，就可以停止查找了，因为后面的数据一定不满足要求。这样就可以利用索引了。 4.索引失效的几种情况 1.如果条件中有or，即使其中有条件带索引也不会使用(这也是为什么尽量少用or的原因) 要想使用or，又想让索引生效，只能将or条件中的每个列都加上索引 2.对于多列索引，不是使用的第一部分，则不会使用索引 3.like查询以%开头 4.如果列类型是字符串，那一定要在条件中将数据使用引号引用起来,否则不使用索引 5.如果mysql估计使用全表扫描要比使用索引快,则不使用索引 5.MySQL主要提供2种方式的索引：B-Tree索引，Hash索引 B树索引具有范围查找和前缀查找的能力，对于有N节点的B树，检索一条记录的复杂度为O(LogN)。相当于二分查找。 哈希索引只能做等于查找，但是无论多大的Hash表，查找复杂度都是O(1)。 显然，如果值的差异性大，并且以等值查找（=、 &lt;、&gt;、in）为主，Hash索引是更高效的选择，它有O(1)的查找复杂度。 如果值的差异性相对较差，并且以范围查找为主，B树是更好的选择，它支持范围查找。 Innodb插入优化InnoDB使用聚集索引，数据记录本身被存于主索引（一颗B+Tree）的叶子节点上。这就要求同一个叶子节点内（大小为一个内存页或磁盘页）的各条数据记录按主键顺序存放，因此每当有一条新的记录插入时，MySQL会根据其主键将其插入适当的节点和位置，如果页面达到装载因子（InnoDB默认为15/16），则开辟一个新的页（节点）。 如果表使用自增主键，那么每次插入新的记录，记录就会顺序添加到当前索引节点的后续位置，当一页写满，就会自动开辟一个新的页。这样就会形成一个紧凑的索引结构，近似顺序填满。由于每次插入时也不需要移动已有数据，因此效率很高，也不会增加很多开销在维护索引上。 如果使用非自增主键（如果身份证号或学号等），由于每次插入主键的值近似于随机，因此每次新纪录都要被插到现有索引页得中间某个位置：此时MySQL不得不为了将新记录插到合适位置而移动数据，甚至目标页面可能已经被回写到磁盘上而从缓存中清掉，此时又要从磁盘上读回来，这增加了很多开销，同时频繁的移动、分页操作造成了大量的碎片，得到了不够紧凑的索引结构，后续不得不通过OPTIMIZE TABLE来重建表并优化填充页面。 只要可以，请尽量在InnoDB上采用自增字段做主键。 参考mysql索引的实现原理 数据结构中各种树 探索B树/B+树与MySQL数据库索引的关系 平衡二叉树、B树、B+树、B*树 浅析——B树，B+树，B*树以及分析MySQL的两种引擎 mysql索引总结 由浅入深探究 MySQL索引结构原理、性能分析与优化 http://www.sohu.com/a/201923614_466939]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>索引</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux性能调优工具]]></title>
    <url>%2F2018%2F05%2F03%2Fperformance-linux%2F</url>
    <content type="text"><![CDATA[Linux性能调优CPU占用过高首先，通过top -c指令查看进程的cpu占用情况，找到cpu占用高的进程pid； 然后，通过top -Hp [pid]指令查看进程内线程运行情况，找出cpu占用高的线程pid； root@iZ2ze4k1o3ish3waeplqi8Z:~# top -Hp 14933PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 14965 root 20 0 2449044 493880 15588 S 0.3 24.1 0:05.92 java 14982 root 20 0 2449044 493880 15588 S 0.3 24.1 0:02.76 java 14984 root 20 0 2449044 493880 15588 S 0.3 24.1 0:18.18 java 14985 root 20 0 2449044 493880 15588 S 0.3 24.1 0:02.45 java 14999 root 20 0 2449044 493880 15588 S 0.3 24.1 0:13.40 java 假设第一个线程14965占用cpu最多，将[pid]=14965转换成16进制0x3a75 root@iZ2ze4k1o3ish3waeplqi8Z:~# printf "%x\n" 149653a75 最后，打印进程堆栈，过滤线程pid，查看线程栈，找出执行任务： root@iZ2ze4k1o3ish3waeplqi8Z:~# jstack 14933 | grep '0x3a75' -C5 --color"nioEventLoopGroup-2-1" #27 prio=10 os_prio=0 tid=0x00007fe5b890b800 nid=0x3a75 runnable [0x00007fe587802000] java.lang.Thread.State: RUNNABLE at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method) at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269) at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93) at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86) 本例为虚拟例子，所以当前执行的任务是poll()。 端口占用netstat -lap | grep 8051 lsof -i :8051 root@iZ2ze4k1o3ish3waeplqi8Z:~# netstat -lap | grep 8051tcp 0 0 *:8051 *:* LISTEN 14933/java tcp 0 0 172.17.134.10:8051 172.17.134.96:55014 ESTABLISHED 14933/java tcp 0 0 172.17.134.10:8051 172.17.134.96:51712 ESTABLISHED 14933/java tcp 0 0 172.17.134.10:8051 172.17.134.9:56656 FIN_WAIT2 - tcp 0 0 172.17.134.10:8051 172.17.134.9:56652 ESTABLISHED 14933/java tcp 0 0 172.17.134.10:8051 172.17.134.11:44974 ESTABLISHED 14933/java root@iZ2ze4k1o3ish3waeplqi8Z:~# lsof -i:8051COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEjava 14933 root 35u IPv4 43755096 0t0 TCP 172.17.134.10:8051-&gt;172.17.134.9:56652 (ESTABLISHED)java 14933 root 36u IPv4 43719121 0t0 TCP *:8051 (LISTEN)java 14933 root 48u IPv4 43719551 0t0 TCP 172.17.134.10:8051-&gt;172.17.134.96:51712 (ESTABLISHED)java 14933 root 59u IPv4 43751694 0t0 TCP 172.17.134.10:8051-&gt;172.17.134.96:55014 (ESTABLISHED) jmap -heap 14933jmap -histo:live 14933 | morell /proc/14933/fd/ll /proc/14933/task/ll /proc/14933/task | wc -l]]></content>
  </entry>
  <entry>
    <title><![CDATA[分布式锁]]></title>
    <url>%2F2018%2F05%2F03%2Fdistributed-system-lock%2F</url>
    <content type="text"><![CDATA[https://github.com/redisson/redisson http://redis.cn/topics/distlock.html https://blog.csdn.net/forezp/article/details/68957681 https://blog.csdn.net/forezp/article/details/70305336]]></content>
  </entry>
  <entry>
    <title><![CDATA[分布式ID生成器]]></title>
    <url>%2F2018%2F05%2F03%2Fdistributed-system-unique-id%2F</url>
    <content type="text"><![CDATA[分布式ID在分布式情况下，尤其是分库分表情况下，如何生成表的主键是一个问题。 我们对于表的主键有两个要求： 一是唯一性，这是基础，也是最重要的要求，ID必须唯一； 二是顺序性，如果表ID是有序的，越来越大的，那么ID可以起到时间排序的作用； 在单库情况下，我们通常使用自增ID作为表的主键。 分库情况下，为保证ID的唯一，就需要手工设置各个库的auto_increment值以及步长，例如：我们把user表分到4个库中，db1从1开始，db2从2开始，db3从3开始，db4从4开始，步长都是4；这样，db1上生成的ID是[1,5,9,13,……]，db2上生成的ID是[2,6,10,14,…..]。这样做问题不大，如果非要挑毛病，那么在一个db上ID是严格按照顺序创建的，但是跨db的ID顺序不能严格保证。例如，[5,6,7,8]因为在不同的db上，不一定是按照这个顺序创建的。 还有一种比较简单的办法就是直接使用UUID。UUID可以保证唯一性，并且不依赖于库。但是，UUID的问题是随机，没有顺序性，并且占用的存储空间比较大。 UUID的好处： 应用本地生成，保证唯一，数据库无感知。 UUID的坏处： 无法保证趋势递增； 32位字符串太长，占用存款空间大，占用索引存储空间大； B+树写操作时，过多的随机写操作，效率低（自增ID是顺序写）； 作为主键查询效率没有bigint高； 高并发情况下，不能100%保证一定唯一。 Snowflake算法Snowflake是Twitter生成64位自增ID的算法。 最高位不用，是0；接下来的41位是时间戳；接下来的10为是主机ID；最后12位是序列号。实际使用过程中，各组的位数可以根据实际情况进行调整。 SnowFlake的优势是本地生成，不依赖于其他任何第三方。我的理解：SnowFlake生成的自增ID有三部分组成：一、时间戳：为节省空间，可以不使用绝对时间，使用相对时间即可；例如：以2000年1月1日为时间基点，时间戳存储的是距离时间基点的毫秒数（实际上所谓绝对时间也是从1970年1月1日开始的）。二、进程标识：不同进程可能在相同时间生成ID，为了保证他们生成的ID不同，需要在ID中增加进程标志；进程标志可以是IP+Port，也可以自定义然后直接从配置文件中读取；三、进程内自增序号：解决同一个进程内并发的问题，使用AtomicInteger自增即可。 计算机元年就是1970年1月1日0时，加上时区因素，就是北京时间1970年1月1日8时。0毫秒就表示这个时间。 根据实际情况，我们也可以在上述三部分的基础上增加新的内容，例如业务类型。为保证ID具有顺序特性，通常时间戳都是放在最前面的；为了做分布式hash，通常自增序号都是放在最后面的；所以业务类型字段可以放在中间，进程标志的前后都可以。 回想一下，我们的order_bill_code其实也是类似的思路，业务类型+时间戳+自增序号(随机序号)，殊途同归。 参考Twitter-Snowflake，64位自增ID算法详解 详解Twitter开源分布式自增ID算法snowflake]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>SnowFlake</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库水平拆分]]></title>
    <url>%2F2018%2F05%2F03%2Fdatabase-sharding%2F</url>
    <content type="text"><![CDATA[数据库拆分垂直拆分数据库垂直拆分就是要把表按模块划分到不同数据库中。微服务架构中每个服务拥有自己独立的数据库，就是典型的垂直拆分。通俗说，就是根据业务类型，把一个数据库中的多张表拆分到多个数据库中，这样不同数据库的数据量和压力不同，可以有针对性的进行优化。 水平拆分垂直拆分只是把一张表拆分到另一个数据库实例中，并不会把一张表拆分为多张表。当单表的数据量增加到千万量级以上时，就需要拆表了，成为数据库水平拆分，也叫做数据库分片或者Sharding。 通常，我们认为MySQL数据库单表数据量在百万级，经过索引优化后查询效率是没有问题的。但是当数据量超过千万时，就需要考虑拆分了，如果超过五千万就肯定要拆表了。 数据库分片数据库垂直拆分相对简单一些，分片就复杂多了，本文主要讨论数据库分片遇到的各种问题和解决方案。 一般我们根据表的主键和数据类型的不同来进行表的拆分，下面分别以用户表、帖子表和订单表为例，介绍如何进行拆分表拆分的三种方法。 用户表用户表是典型的1对1例子，也就是说表的主键是user_id，1个用户只有1条记录。 背景用户表保存用户姓名、手机号码、登录名、登录密码等基本信息，主键是user_id。在业务初期，单库单表就能满足需求，但随着数据量越来越大，需要对数据库进行水平切分，常见的方法有范围法和取模法。 方案一、范围法： 将user_id设计为long型，根据user_id值的范围不同进行拆分。例如：1~1000万存储到db1中，1000万~2000万存储到db2中。 好处： 简单，读写时根据user_id可以迅速定位数据在哪个db上； 扩容简单，对历史数据无影响；每增加1000万用户，增加一个db即可。 坏处： user_id必须是整数，且自增； 数据量不均匀，前面的db满了才会新增db，新增db数据量小； 访问量不均匀，一般新注册用户活跃度高，新db的负载比旧db负载高。 二、哈希法： 对user_id取模，除以总共的db个数，根据mod值分配db。如果user_id是字符串，可以先计算出哈希值，然后再根据哈希值取模。例如：5个数据库，user_id以1/6结尾的存储到db1中，以2/7结尾的存储到db2中，依次类推（是不是可以简称为限行算法？）。 好处： 简单，最多计算user_id的哈希值就可以确定db位置； 数据均匀，哈希值均匀分布可以保证数据均匀分布到各个db上； 访问量均匀，理由同上； 坏处： 扩容复杂，扩容以后可能引起数据迁移，如何平滑进行数据迁移是一个问题。 每次2倍扩容：概率上有一半的数据不用迁移。例如：开始2个数据库，1/3/5/7/9在db1上，2/4/6/8/10在db2上；扩容2倍到4个数据库，1/5/9还在db1上，2/6/10还在db2上，60%的数据不用迁移，需要做的是把3/7移动到db3上，4/8移动到db4上。 一致性哈希：一致性哈希算法可以保证增加和减少数据库数量时，尽量少的数据需要迁移。不过一致性哈希一般基数需要大一些效果才好，至少32或64起步吧，也就是说上来就开64个数据库，相当于单表数据量在10亿量级。所以，2倍扩容应该更常见。 问题根据user_id分表以后带来的问题： 用户登录操作，需要根据登录名读取登录密码，现在有多张用户表，怎么办？都读取一遍？ 同样，还有根据用户手机号码查询用户信息的需求？ 此外，管理后台还有各种各样复杂、变态的查询需求，各种组合的，怎么办？ 解决先把查询需求分为前端需求和后台需求两种，使用不同的解决方案。 前端需求：通过登录名和手机号码查询用户，采用建立非主键属性到主键映射关系的方案。 后台需求：各种各样的复杂需求，采用前后端分离方案。 前端需求根据手机号码查询 以根据user_phone查询user表为例。 建一张user_phone_id表，主键是user_phone，内容字段是user_id。查询时先通过user_phone查询user_phone_id表找到user_id，然后再根据user_id找到用户信息。user_phone_id表可以不分片。 考虑性能，也可以把user_phone_id表的信息缓存在redis中，如果redis缓存不命中，再查数据库。 user_phone和user_id的对应关系一旦建立很少改变，适合做缓存。 根据登录名查询 假设查询字段是user_login_name，当然可以使用和user_phone相同的方法。如果user_login_name字段不是用户输入的，是系统自动生成的，那么我们有更简便的方法。 缓存的出发点是空间换时间，预先把对应关系保存起来。另外一种思路就是设计一个函数f(x)，保证f(user_login_name)=user_id，这样我们就不用查数据库了，直接结算就可以得到user_id。实际上我们不需要f(x)=user_id，因为我们不关心user_id具体是什么，我们只关系user_id在哪个db上，或者更专业点，在哪个数据库分片上。所以，我们只需要设计f(user_login_name)=db_sharding即可。这就简单了，我们创建用户记录时，根据user_id计算出db_sharding的值，然后放到user_login_name中就可以了。 如上图所示，最后三个字节保存的是user_id在那个db上（一共8个分片）。当根据登录名查询时，截取后三位就知道应该去哪个数据库查询了。 这种做法，需要考虑如果出现数据迁移怎么办，最好确定分片后就不变了。 后端需求上面都是单条数据的查询，那批量查询怎么办？回想一下，前端用户只能查询自己的数据，只有运营后台才可以批量查询用户数据，后端需要采用不同的策略。 水平切分的目的是为了提高访问速度，后台查询条件复杂，对响应时间要求不高，所以不用分库，从前端通过MQ同步数据即可。MQ同步数据机制建立以后，也可以同步到Hive等其他存储结构中。 帖子中心1对多。 订单中心以order表为例 order_id user_id product_id 首先，区分前端访问和后台访问。前端访问指用户的访问，用户下单后需要查询订单，查询条件比较简单，一般只能查询自己的订单，但是响应速度要求要快。后台访问指运营人员对订单的查询，一般查询条件比较复杂，但实时性要求低一些。 如图所示，order-center提供前端服务，order-center对应的数据库进行了水平切分；order-back提供后台服务，这里显示的存储方案是ES或者Hive，其实也可以是MySQL，总之后台服务的存储数据结构不依赖于前端，可以根据实际业务需求进行选择。如果选择了MySQL，后台存储可以选择不分库，因为后台需求往往逻辑比较复杂，但是对响应性要求不高。 前后端数据同步可以通过开源的中间件来实现，更多的时候像图中一样，通过MQ来同步。MQ异步同步意味着数据是有延迟的。MQ要保证数据送到的可靠性和幂等性。 不只是订单服务，后台可以把所有前端服务产生的数据都汇总到一个库中，可以是原始数据直接进入，也可以是经过order-back处理后的数据进入。（看上去有点像数据仓库了。） 接下来看，前端的数据库存储如何做水平拆分。 这里有一个前提，前端用户查询的都是自己的订单，不能查询别人的订单。这样，我们就可以根据user_id来分库。例如：如果分为4个库，那么最简单的办法对user_id % 4，来确定订单数据落在那个schema上面。实际操作中，我们是通过主键order_id来做水平切分的，所以要保证order_id和user_id的切分一致。所以在生成订单时，可以让order_id的最后两位和user_id 的最后两位一致，或者最简单order_id=timestamp+user_id，这样取模就肯定和user_id一致了。 https://mp.weixin.qq.com/s/PCzRAZa9n4aJwHOX-kAhtA https://blog.csdn.net/admin1973/article/details/74923283 https://blog.csdn.net/jiangzhexi/article/details/76794801 https://blog.csdn.net/admin1973/article/details/77713716]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Database</tag>
        <tag>MySQL</tag>
        <tag>Sharding</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL使用规范]]></title>
    <url>%2F2018%2F05%2F03%2Fmysql-rules%2F</url>
    <content type="text"><![CDATA[58MySQL规范 表存储引擎必须使用InnoDB 表字符集默认使用utf8，必要时使用utf8mb4（4个字节的utf8，能存储表情符号） 禁止使用存储过程、视图、触发器（扩展性差） 禁止在数据库中存储大文件，例如图片，大文件存储到分布式文件系统，数据库中保存访问地址 库名、表名、列名必须用小写，”_”分隔（MyBatis生成工具可自动转换为驼峰） 库名、表名、列名长度不要超过32个字符 表必须有主键，推荐使用unsigned整数为主键 禁止使用外键（外键影响性能，有可能造成死锁） 将大字段、访问频度低的字段拆分到单独的表中存储，分离冷热数据 根据业务区分使用tinyint/int/bigint分别占1/4/8字节 根据业务区分使用char/varchar（char查询性能高，varchar减少存储空间） 根据业务区分使用datetime/timestamp（我都使用datetime） 必须把字段定义为NOT NULL并设置默认值（NULL列使索引更复杂） 使用int unsigned存储IP4，不要使用char(15) 使用varchar(20)存储手机号码，不要使用整数（考虑+86，varchar支持模糊查询） 使用tinyint，不要使用enum 唯一索引使用uniq_命名 非唯一索引使用idx_命名 单表索引建议控制在5个以内（太多索引影响写性能，异常复杂的查询需求，可以选择ES等存储方式） 组合索引字段数不建议超过5个 不建议在频繁更新的字段上建立索引 除非必要不做join查询，join字段必须建立索引 禁止使用select *，只获取必要字段（表结构变更时，对程序无影响） insert必须指定字段（表结构变更时，对程序无影响） 隐式类型转换会使索引失效 禁止在where条件中使用函数或表达式（索引失效） 禁止以%开头的模糊查询（索引失效） 同一个字段OR使用IN ​ 赶集MySQL规范 控制列的数量，字段数控制在20个以内 避免使用NULL字段 不在数据库里存图片 不在索引列做运算 SQL语句尽可能简单 事务时间尽可能短 limit越大效率越低 ​ 阿里巴巴MySQL规范 互联网业务，能让服务层干的事情，不要交到数据库层。 删除无主键的表，如果是row模式的主从架构，从库会挂住。 TODO 如何实施数据库垂直拆分？ MySQL索引 MySQL索引失效 MySQL事务隔离级别]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Database</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Singleton]]></title>
    <url>%2F2018%2F05%2F02%2Fdesign-pattern-singleton%2F</url>
    <content type="text"><![CDATA[Singleton单例Singleton是最常见的设计模式，如何实现单例呢？如果实现线程安全的单例呢？ 单线程单例最常见的单例写法 声明一个静态实例 构造函数声明为私有，确保不能通过构造函数创建对象 getInstance()时进行null判断 public class OneThreadSingleton &#123; private static OneThreadSingleton instance = null; private OneThreadSingleton() &#123; &#125; public static OneThreadSingleton getInstance() &#123; if (null == instance) &#123; instance = new OneThreadSingleton(); &#125; return instance; &#125;&#125; 以上代码在单线程环境下进行测试，测试代码如下 public class SingletonExample &#123; public static void main(String[] args) &#123; for (int i=0; i&lt;10; i++) &#123; OneThreadSingleton singleton = OneThreadSingleton.getInstance(); System.out.println(singleton); &#125; &#125;&#125; 返回结果如下，都是一个实例，说明单例成功 cn.waterlu.java.design.OneThreadSingleton@6f75e721cn.waterlu.java.design.OneThreadSingleton@6f75e721cn.waterlu.java.design.OneThreadSingleton@6f75e721cn.waterlu.java.design.OneThreadSingleton@6f75e721cn.waterlu.java.design.OneThreadSingleton@6f75e721cn.waterlu.java.design.OneThreadSingleton@6f75e721cn.waterlu.java.design.OneThreadSingleton@6f75e721cn.waterlu.java.design.OneThreadSingleton@6f75e721cn.waterlu.java.design.OneThreadSingleton@6f75e721cn.waterlu.java.design.OneThreadSingleton@6f75e721 但是以上代码在多线程环境下是有问题的，多线程测试代码如下 public class SingletonExample &#123; public static void main(String[] args) &#123; List&lt;Task&gt; taskList = new ArrayList&lt;&gt;(); for (int i=0; i&lt;10; i++) &#123; Task task = new Task(); taskList.add(task); &#125; for (Task task : taskList) &#123; task.start(); &#125; &#125; public static class Task extends Thread &#123; @Override public void run() &#123; OneThreadSingleton singleton = OneThreadSingleton.getInstance(); System.out.println(singleton); &#125; &#125;&#125; 返回结果如下，存在不一样的情况，单例失败 注意，结果是随机的，需要多运行几次才能出现返回不一样实例的情况 错误原因在于并发进行(null==instance)判断是不准确的，可能存在多个线程判断时instance都是null的情况 cn.waterlu.java.design.OneThreadSingleton@65d2066bcn.waterlu.java.design.OneThreadSingleton@dbefcacn.waterlu.java.design.OneThreadSingleton@6464d21cn.waterlu.java.design.OneThreadSingleton@65d2066bcn.waterlu.java.design.OneThreadSingleton@65d2066bcn.waterlu.java.design.OneThreadSingleton@65d2066bcn.waterlu.java.design.OneThreadSingleton@65d2066bcn.waterlu.java.design.OneThreadSingleton@65d2066bcn.waterlu.java.design.OneThreadSingleton@65d2066bcn.waterlu.java.design.OneThreadSingleton@65d2066b 同步单例以上经典的单例代码在多线程情况是有问题的，也就是非线程安全的，如果如何写出线程安全的单例呢？ 以下代码是最容易想到的，给getInstance()方法增加synchronized关键字，这样就能保证线程安全了 首先肯定这种写法是对的，没有问题，可以实现线程安全的单例模式 这种写法虽然简单，但存在效率问题：每一次进入synchronized代码块都是需要加锁的，加锁和释放锁肯定是有开销的；绝大多数情况下，instance不等于null，加锁只在instance等于null时起作用，典型的悲观锁 既然这样，把synchronized放到if()判断里面不就行了，这就引出了另外一种实现 public class SynchronizedSingleton &#123; private static SynchronizedSingleton instance = null; private SynchronizedSingleton() &#123; &#125; public synchronized static SynchronizedSingleton getInstance() &#123; if (null == instance) &#123; instance = new SynchronizedSingleton(); &#125; return instance; &#125;&#125; 双重检查单例继续上面的思路，代码如下： synchronized代码块只在instance等于null时起作用，大多数情况下直接return instance即可 注意，这里有两个if (null == instance)判断，所以也被称为双重检查，那么为什么要做第二遍检查呢 因为synchronized虽然起到了互斥的作用，但是代码还是会执行的；假设，两个线程同时通过第一层null判断，抢到锁的线程执行了new操作；第一个线程释放锁以后第二个线程从阻塞状态唤醒执行，此时如果没有第二次判断，那么它还是会创建一个新的对象。 public class DoubleCheckSingleton &#123; private static DoubleCheckSingleton instance = null; private DoubleCheckSingleton() &#123; &#125; public static DoubleCheckSingleton getInstance() &#123; if (null == instance) &#123; synchronized (DoubleCheckSingleton.class) &#123; if (null == instance) &#123; instance = new DoubleCheckSingleton(); &#125; &#125; &#125; return instance; &#125;&#125; 静态单例其实还有更简单的单例实现方法，代码如下 代码非常简单，也是线程安全的，因为多线程只发生了读操作，当然是安全的 当然，这么做也有缺点，那就是没有延迟加载，俗称lazy load 即使StaticSingleton类没有被使用，它也创建对象并占用了内存空间；上面的例子都是延迟加载的，在第一次被使用时创建的对象 备注：我真心觉得这么写就挺好，又简单又高效，耗费那点内存空间真不算什么。 public class StaticSingleton &#123; private final static StaticSingleton instance = new StaticSingleton(); private StaticSingleton() &#123; &#125; public static StaticSingleton getInstance() &#123; return instance; &#125;&#125; 内部静态类单例 在前面代码的基础上进行改造，把创建对象操作放到内部类中实现，以完成延迟加载 头一次看到这种代码可能会感到奇怪，一步一步分析过来就了解了 public class Singleton &#123; private Singleton() &#123; &#125; private static class SingletonInner &#123; private static Singleton instance = new Singleton(); &#125; public static Singleton getInstance() &#123; return SingletonInner.instance; &#125;&#125; 这么多单例的实现方式，个人觉得这就和茴香豆的茴字有几种写法差不多，没啥意义。关键理解其中的思考方法，还有些意义。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>单例</tag>
        <tag>线程安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程高级篇(1) 线程实现]]></title>
    <url>%2F2018%2F04%2F29%2Fthread-advance-implementation%2F</url>
    <content type="text"><![CDATA[线程实现Java线程的实现有三种策略： 内核实现，Java线程相关方法声明为native，所有操作直接调用操作系统内核的API，此时的Java线程与操作系统内核线程一一对应； 用户实现，Java线程对操作系统是透明的，自己实现线程调度； 混合实现，综合上面两种实现的折中方案。 Java线程在JDK1.2之前采用用户实现策略，之后替换为内核实现。也就是说，一个Java线程就对应操作系统一个实际的线程（轻量级进程）。 Java线程使用抢占式的调度策略，由操作系统来分配执行时间。由于各个操作系统的线程优先级粒度不一样，所以Java线程优先级设置很难与操作系统线程优先级一一对应，所以就不那么靠谱。 上图中，KLT是Kernel Thread的缩小，表示这是一个操作系统内核线程；LWP是Light Weight Process的缩写，表示轻量级进程。应用程序一般不直接使用内核线程，而是使用轻量级进程作为接口；P表示一个Java进程。 所以，上图的含义为：一个Java进程中可以创建多个线程，每个线程调用LWP接口，实际对应着一个内核线程，内核线程由操作系统调度。 Linux 2.6以后有了一种新的pthread线程库–NPTL(Native POSIX Threading Library)，hotspot虚拟机就是使用NPTL来实现多线程的。]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>并发</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程中级篇(3) Java内存模型]]></title>
    <url>%2F2018%2F04%2F28%2Fthread-java-memory-model%2F</url>
    <content type="text"><![CDATA[Java内存模型共享内存模型什么是Java内存模型？Java内存模型就是Java Memory Model（以下简称JMM），是Java虚拟机规范的一部分。我们知道Java语言是跨平台的，所以JVM需要定义一个统一的规范，抽象规定Java程序如何访问内存，这就是JMM，具体讲就是JSR-133。注意，JMM不是JVM运行时数据区描述，那只是JMM的一小部分。 主内存和工作内存JMM规定：变量存储在主内存（Main Memory）中，每个线程有自己的工作内存（Working Memory），线程工作内存中保存了变量在主内存的副本拷贝。主内存变量是多线程共享的，工作内存变量是各个线程独占的。线程工作时，从主内存复制变量到线程的工作内存，然后一直在工作内存中操作变量副本，最后再把工作内存中的变量值回写到主内存中。 Java内存模型是一种共享内存模型： 线程只能直接操作工作内存，不能直接操作主内存； 每个线程只能访问自己的工作内存，不能访问其他线程的工作内存； 线程之间的数据通信必须通过主内存中转完成：线程1将工作内存变量写入到主内存，然后线程2再从主内存读取变量到工作内存，实现数据通信。 运行时数据区我们再来看一下JVM运行时数据区情况 所有原始类型的本地变量都直接保存在线程栈中，它们的值在各个线程之间是独立的； 堆包含了Java应用创建的所有对象信息，不管对象是哪个线程创建的（包括像Integer这样的原始类型封装类）；不管对象是属于一个成员变量还是方法中的本地变量，它都会被存储在堆中； 一个本地变量如果是原始类型，那么它全部存储到栈区； 一个本地变量也有可能是一个对象的引用，这种情况下：这个本地引用存储到栈中，对象本身存储在堆中； static类型的变量以及类本身相关信息都存储在堆中。 硬件内存结构前面把JAVA内存空间分为主内存和工作内存，或者分为栈和堆。无论那一种分法，都是逻辑上的概念，没有实际的物理存储空间与其一一对应。 我们再来看一下硬件内存结构：从上往下，首先在CPU内部有一组CPU寄存器，CPU操作寄存器的速度要比操作主存快得多。再往下，在CPU寄存器和主存之间还有CPU缓存，CPU操作CPU缓存的速度快于主存但慢于寄存器，某些CPU可能有多级缓存层。最下面是计算机主存，也称作RAM，所有的CPU都能够访问主存，而且主存比上面提到的缓存和寄存器的存储容量大很多。从上往下，存储容量越来越大，访问速度越来越慢。 再重复一遍，主内存、工作内存、堆、栈只是逻辑上的概念，和物理存储空间没有关系，下图可以说明这一点：堆和栈空间都有可能在RAM或者Cache上。 内存指令下面再来看看JMM定义的常见内存操作指令： 指令 作用域 说明 lock 主内存 把主内存中一个变量标识为线程锁定状态 unlock 主内存 释放主内存中一个变量的线程锁定状态 read 主内存 把一个变量从主内存传递到线程的工作内存中 load 工作内存 把read操作得到的变量值更新到工作内存的变量副本中 store 工作内存 把一个变量从线程的工作线程传递到主内存中 write 主内存 把store操作得到的变量值更新到主内存的变量中 JMM对于上述指令有如下规则： read/load和store/write必须成对出现； 一个新的变量只能从主内存中诞生； 一个变量同一时刻只允许一个线程对其进行lock操作； 对一个变量lock操作之后会触发对它的read/load操作； 对一个变量unlock操作之前触发对它的store/write操作。 可见性和有序性前面介绍了JMM共享内存模型的基本概念，共享内存模型需要解决并发过程中的原子性、可见性和有序性问题。 原子性（Atomicity） 原子性即不可拆分。JMM只保证像read/load/store/write这样很少的操作是原子性的，甚至在32位平台下，对64位数据的读取和赋值都不能保证其原子性（long变量赋值是需要通过两个操作来完成的）。简单说，int i=10; 是原子的；i = i + 1 不是原子的；甚至long v = 100L 也可能不是原子的。 可见性（Visibility） 可见性是指当一个线程修改了共享变量的值，其他线程能够立即得知这个修改。 有序性（Ordering） 有序性指程序的执行顺序与源码顺序一致，有序性和重排序相关，下面展开讲。 重排序为提高性能，编译器和处理器可能会对指令做重排序，重排序有三种类型： 编译器重排序：编译器在不改变单线程程序语义的前提下，可以重新安排字节码的执行顺序；也就是编译生成的机器码顺序和源代码顺序不一样； 处理器重排序：现代处理器采用指令级并行技术将多条指令重叠执行，如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序；也就是CPU在执行字节码时，执行顺序可能和机器码顺序不一样； 内存重排序：由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。 编译器重排序和处理器重排序比较好理解，一个是源代码编译时调整了生成的机器码顺序，另外一个是执行时调整了机器码的执行顺序，内存重排序就不那么好理解了，下面展开一下。 内存重排序也可以认为是处理器重排序的一种。 内存重排序内存访问速度虽然比硬盘访问速度快得多，但是和CPU处理器相比还是太慢。所以，现代操作系统中，CPU和内存之间还有会缓存。对于存储来说，访问速度最快的是CPU上的寄存器，速度最快，容量最小；接下来是CPU上的缓存（一般有二级缓存或者三级缓存），速度很快，容量较小；再往下是内存，速度较快，容量不小；最后是硬盘，速度最慢，容量最大。 有了缓存之后，CPU不会直接操作内存，CPU操作的是缓存，缓存数据何时更新到内存中由系统决定。所以，当我们在代码里面设置变量值的时候，只会更新写缓冲区的值，不会立即更新到内存中。这样，就可能出现先设置的值，后写入到内存的情况。 缓存中的数据与主内存的数据并不是实时同步的，各CPU（或CPU核心）间缓存的数据也不是实时同步的。这导致在同一个时间点，各CPU所看到同一内存地址的数据的值可能是不一致的。从程序的视角来看，就是在同一个时间点，各个线程所看到的共享变量的值可能是不一致的。 下面看一个具体的例子，线程1和线程2执行的代码如下，同时执行的话，输出结果是什么呢？ 线程1 线程2 a = 1; // A1 b = 2; // B1 x = b; // A2 y = a; // B2 最终可能得到x = y = 0的结果，为什么呢？ 开始a=b=0 执行语句A1，设置a=1，线程1的写缓存区中a=1，但是主内存中还是a=0 执行语句B1，设置b=2，线程2的写缓存区中b=2，但是主内存中还是b=0 执行语句A2，x=b，从主内存中读取b的值并赋值给x，x=0 执行语句B2，y=a，从主内存中读取a的值并复制给y，y=0 执行A3刷新线程1的写缓冲区，a=1 执行B3刷新线程2的写缓冲区，b=2 以线程1为例：源码顺序是A1-&gt;A2，但是由于写缓存区的存在（刷新之后A1语句才实际上起作用），导致时间上的执行顺序是A2-&gt;A1，这就是所谓的内存重排序。 什么时间刷新写缓存区数据到主内存中，是处理器自己决定的。Java本身是跨平台的，硬件无关的，所以对于Java来说就是随机的，不可控的。 怎么解决重排序问题呢？Java编译器通过插入内存屏障指令来禁止处理器重排序，这就是内存栅栏，也是volatile关键字实现的原理，我们后面再说。 我们再来看一个例子：线程1执行writer()方法，线程2执行reader()方法，结果怎样？ 由于writer()方法中的A1和A2操作没有依赖关系，所以可能被重排序，先执行A2，再执行A1，这种情况下由于a=0，所以i=0； reader()方法中的B1和B2操作是有依赖关系的，不会被重排序；但是为提高性能编译器和处理器可能会猜测执行，导致B2操作先执行，这样i还是等于0。 class ReorderExample &#123; int a = 0; boolean flag = false; public void writer() &#123; a = 1; // A1 flag = true; // A2 &#125; public void reader() &#123; if (flag) &#123; // B1 int i = a * a; // B2 &#125; &#125;&#125; 解释一下猜测执行，纯属个人理解。操作系统有2个CPU执行reader()方法，为提高性能，可能CPU1执行if(flag) 另外一个CPU2同时执行int i=a*a ；如果flag=true，那么CPU2就提前执行了，缩短了执行时间；如果flag=false，那么CPU2的执行就是废操作。在单线程情况下，这么做最多只是浪费的CPU2的操作，但是还有一半可能提高了效率。但是多线程情况下，先执行if()语句内就可能引发事实上指令重排序问题。 先行发生原则也叫happens-before原则。前面看到了各种重排序，我们怎么保证程序能够按照我们预期的顺序执行呢？所有的代码都添加volatile和synchronized吗？当然不是，实际上我们很少能够察觉到重排序，这就是先行发生原则起了作用。 Happens-before原则本身还是有些晦涩难懂，下面先列出其中几条重要的原则，后面再解读： 程序次序规则：在一个线程内，按照控制流顺序，控制流前面的操作先行发生于控制流后面的操作； 锁定规则：锁的unlock操作先行发生于后面对同一个锁的lock操作； volatile规则：对一个volatile变量的写操作先行发生于后面对这个变量的读操作； 传递原则：如果A先行发生于B，B先行发生于C，那么A必先行发生于C。 来个例子分析一下，非常简单的get()和set()方法。如果线程1执行set(1)，同时线程2执行get()，那么线程2的get()方法返回值是1还是0？套用上面的happens-before原则，一个也套不上，所以结果是不确定的，可能是0，也可能是1。首先，set()和get()方法在两个线程中执行，所以程序次序规则不生效。其次，没有使用synchronized和volatile，所以接下来的两个原则也不生效。这个方法就是线程不安全的。 private int i = 0;public void set(int i) &#123; this.i = i;&#125;public int get() &#123; return i;&#125; 如果我们给变量i添加volatile关键字，就是线程安全的了。根据volatile规则，写操作先行发生于读操作，get()一定返回1。 private volatile int i = 0; volatile语义JMM是理论，最常见的实际应用就是volatile关键字了。 volatile关键字有两个作用：一是保证内存可见性，二是保证指令不会被重排序。这么说太抽象，下面解释一下： 可见性：volatile关键字保证如果一个线程修改了volatile变量的值，此后另外一个线程读取这个变量时，立即就能够读取到变化后的最新值；可见的意思就是一个线程对共享变量的修改，另外一个线程立即就能知道； 禁止进行指令重排序，为了提高性能，编译器生成的字节码顺序可能和我们编写的源代码顺序不一样，CPU执行顺序也可能和字节码顺序不一样，重排序会导致执行结果与预期不符，volatile关键字能保证对volatile变量的操作不被重排序，在它前面的代码先执行，在它后面的代码后执行。 三个主要特性：原子性、可见性和有序性，volatile保证可见性和有序性，单个volatile变量读写具有原子性，类似volatile++这种复合操作不具有原子性。 从内存语义的角度来说，volatile的写/读操作与锁的释放/获取有相同的内存效果： 当写一个volatile变量时，JMM会把该线程工作内存中的变量值刷新到主内存； 当读一个volatile变量时，JMM会把该线程工作内存中的变量值置为无效，从主内存中读取变量值； 当lock一个变量时，JMM触发read/load操作，从主内存读取变量值到线程工作内存中； 当unlock一个变量时，JMM触发store/write操作，讲线程工作内存中的变量值刷新到主内存。 简单说，volatile变量写操作立即刷新到主内存，volatile变量读操作从主内存。 volatile解决的是多线程之间读的可见性问题，如果只有一个线程写共享变量，多个线程读取共享变量，那么volatile可以保证读线程能够即使读取到共享变量的最新值，也就是说，一旦写线程修改了共享变量的值，那么读线程可以立即读取到最新的值，没有脏读。 但是，volatile不是用来解决多线程一起写的。只有在一种情况下，使用volatile多线程写共享变量不会出问题，那就是共享变量的新值与旧值没有关联，或者说新值是直接设置的，不需要通过旧值计算得到，这个时候即使有多线程写，volatile共享变量也是正确的。例如：用volatile boolean变量做标志位。 下面看看volatile底层如何实现可见性和有序性的，之前我们先了解一下内存栅栏。 内存屏障内存屏障，也叫内存栅栏，英文名Memory Barries。编译器生成机器码时在指定位置插入内存屏障指令禁止重排序，简单说：内存屏障或者内存栅栏是一组指令，起到类似路障的作用。 JMM有四类内存屏障指令： 内存栅栏指令 使用 说明 LoadLoad Load1; LoadLoad; Load2; 确保Load1操作早于Load2操作 StoreStore Store1; StoreStore; Store2; 确保Store1操作早于Store2操作 LoadStore Load1; LoadStore; Store2; 确保Load1操作早于Store2操作 StoreLoad Store1; StoreLoad; Load2; 确保Store1操作早于Load2操作 好像不太好懂，我来解读一下。以StoreLoad为例，store的意思是把线程工作内存中变量回写到主内存中，load的意思是从主内存中读取变量到线程工作内存中生成变量副本。store早于load也就是告诉处理器看到StoreLoad指令时，立即把缓存中的数据回写到主内存中，然后再从主内存中读取数据，我理解就是强制回写缓存的意思。 处理器实际操作时只识别StoreLoad指令，不会区分缓存中哪个变量是volatile变量，而是立即把缓存中的所有变量都回写到内存中。 注意：这里线程工作内存和缓存的概念要区分清楚。缓存是物理存在的，可能是CPU的寄存器、一级缓存、二级缓存或者三级缓存；工作内存是JMM的虚拟概念，不直接对应物理存在，工作内存可能是寄存器，也可以是CPU上的二级缓存。 可见性实现volatile在编译器层面的语义如下： 在每个volatile写操作的前面插入一个StoreStore屏障，后面插入一个StoreLoad屏障； 在每个volatile读操作的后面插入一个LoadLoad屏障和一个LoadStore屏障。 这么说可能还是太抽象，我们结合代码实例看一下，下面set()和get()方法在两个线程中同时执行，我们期望get()方法返回结果3。 private boolean volatile flag = false;private int value = 0;private int a = 0;private int b = 0;public int get() &#123; if(flag) &#123; value = a + b; &#125; return value;&#125;public void set() &#123; a = 1; b = 2; flag = true;&#125; 如果flag变量没有volatile关键字修饰，那么这里存在可见性问题： flag变量在主内存中创建，初始值为false； set()线程启动，从主内存读取flag=false到工作内存，然后在工作内存中设置flag=true； get()线程启动，从主内存读取flag变量，由于此时set()线程还没有将flag变量回写到主内存中，所以get()线程读取到flag=false，最后返回value=0 使用volatile关键字后，set()方法在flag = true; 之后插入了StoreLoad内存屏障指令，意思是说在后面的load操作前先执行store操作，相当于立即执行store操作刷新主内存，这就保证主内存flag变量值立即变为true。 StoreStore;store(flag = true);StoreLoad; get()方法在读取flag变量之后插入了LoadLoad和LoadStore内存屏蔽指令，意思说在后面的读写操作前先执行load操作，相当于立即执行load操作从主内存读取变量flag。 load(flag);LoadLoad;LoadStore; 根据先行发生原则，volatile变量的写操作先于读操作，所以并发时能够保证先执行store(flag=true)，将主内存中的flag变量更新为true，然后load(flag)从主内存中读取最新的flag变量值。 有序性实现还是上面的例子，如果flag变量没有volatile关键字修饰，那么这里存在有序性问题，在两种情况下执行get()方法时可能返回value=0： set()方法被重排序，先执行了flag=true ，这个时候get()开始执行，读取到flag=true ，但是set()方法还没有执行a=1; b=2; ，所以get()返回0 get()方法猜测执行，先执行了value=a+b，然后再判断if(flag)，同样也会返回0 使用volatile关键字后，set()方法在flag = true; 之前插入StoreStore内存屏障指令，把a=1和b=2先于flag=true刷新到主内存中，阻止了第一种重排序的情况。 store(a = 1);store(b = 2);StoreStore;store(flag = true);StoreLoad; get()在读取flag变量后插入LoadLoad内存屏障指令，保证load(flag)操作先于load(a)和load(b)，阻止了第二种重排序的情况。 load(flag);LoadLoad;LoadStore;load(a);load(b); synchronized语义从语义的角度来看，synchronized和volatile是相似的。 当线程释放锁时，JMM会把该线程工作内存中的共享变量的最新值刷新到主内存中； 当线程获取锁时，JMM会把该线程工作内存置为无效，从主内存中去读取共享变量的最新值。 上述语义保证了可见性。 synchronized的执行过程如下： 获得锁； 清空线程工作内存中的共享变量； 从主内存拷贝共享变量的最新副本到线程工作内存； 执行synchronized语句块内代码； 将线程工作内存中共享变量的值刷新到主内存； 释放锁。 与volatile对比相同点 都解决了多线程下内存可见性问题； 从内存可见性角度看，volatile读操作相当于加锁，volatile写操作相当于解锁； 不同点 volatile不能保证共享变量相关操作的原子性，应用场景受限；volatile使用不如synchronized广泛； volatile不加锁，比synchronized轻量级，效率更高；能用volatile时尽量用volatile； final语义final关键字保证构造函数中对final成员变量的赋值操作不会重排序到构造函数之外，没有final关键字的成员变量赋值操作就没有这个保障了。 什么意思？构造函数也可以分为两步：第一步，创建对象，所有成员变量赋默认值；第二步，执行构造方法给成员变量赋值。多线程情况下，可能出现第一步完成，第二步执行前就读取成员变量的情况。但是如果成员变量是final的，JMM可以保证在第一步就给final成员变量赋值。 参考深入理解Java内存模型（一）——基础 Java 虚拟机 12 ：Java 内存模型 Java内存访问重排序的研究 面试必问的 volatile，你了解多少？ Java Volatile Keyword java volatile关键字解惑 http://tutorials.jenkov.com/java-concurrency/ https://blog.csdn.net/suifeng3051 https://www.jianshu.com/u/f8e9b1c246f1]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>并发</tag>
        <tag>线程</tag>
        <tag>内存模型</tag>
        <tag>内存可见性</tag>
        <tag>指令重排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程中级篇(2) 线程中断]]></title>
    <url>%2F2018%2F04%2F28%2Fthread-interrupt%2F</url>
    <content type="text"><![CDATA[我们在基础篇的线程介绍里面已经提到过如何中断线程，本文将详细展开，描述其中的细节，让大家对线程中断有一个更深刻的理解。 线程中断停止线程虽然在Thread中提供了stop()方法，但是已经声明为@Deprecated不再使用了。所以，其实Java并没有给我们提供一种简单和方便的优雅停止线程的方法。 @Deprecatedpublic final void stop() &#123;&#125; Java没有提供，那只能我们自己来实现了，比较容易想到的是加一个标志位stop=false，在线程执行过程中不断判断这个标志位，当标志为被置为true时，正常退出线程。 注意，这个标志位是典型的volatile关键字的应用场景：所有线程共享这个标志位，每个线程在自己的工作内存中有一个备份，当外部修改主内存中的标志位后，各个线程需要立即读取到变化，完成线程退出。 public class Task implements Runnable &#123; private volatile boolean stop = false; @Override public void run() &#123; while (!stop) &#123; // do something &#125; &#125; public void stop() &#123; this.stop = true; &#125;&#125; Task task = new Task();new Thread(task).start();task.stop(); 中断线程以上代码可以实现线程的正常停止，没有问题。但是有一种情况无法处理，那就是如果在while()语句块出现了I/O或者同步相关的阻塞操作，那么就无法判断stop的值了，上面停止线程的方法就失效了。怎么办呢？这个时候就需要中断线程了。 首先，这些阻塞方法是可以被中断的，一旦被中断将抛出InterruptedException异常；从下面的方法声明中可以看到，join()、sleep()和wait()都声明抛出InterruptedException异常，也就是说这些阻塞方法会检查线程的中断状态，如果发现被中断就抛出异常，变相提供了一种退出机制。 public class Thread &#123; public final void join() throws InterruptedException &#123;&#125; public static native void sleep(long millis) throws InterruptedException;&#125; public class Object &#123; public final native void wait(long timeout) throws InterruptedException; &#125; Thread类提供了方法来查询和设置中断状态。 public class Thread &#123; public boolean isInterrupted() &#123;&#125; public void interrupt() &#123;&#125;&#125; 当调用了一个线程的interrupt()方法后，当前线程的状态被置为中断状态，但是线程不会自动停止，需要我们来进行处理，停止线程的代码可以修改为： public class MyThread extends Thread &#123; @Override public void run() &#123; while (!isInterrupted()) &#123; // do something &#125; &#125;&#125; MyThread thread = new MyThread();thread.start();thread.interrupt(); 这里将while(!stop)修改为while (!isInterrupted())，停止方法由调用自定义的stop()方法改为调用Thread类实例对象的interrupt()方法。 实战中，我们不会在线程执行过程中每执行一步就判断一次isInterrupted()，所以更加贴近现实场景的情况是中断阻塞操作。前面讲过，这时会抛出异常，我们捕获异常并退出程序即可。 public class MyThread extends Thread &#123; @Override public void run() &#123; while (!isInterrupted()) &#123; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; break; &#125; &#125; &#125;&#125; 我们以sleep()阻塞为例，wait()和join()也是一样的；当外部调用myThread.interrupt()时，发现MyThread正处于sleep的阻塞状态，会让sleep()抛出InterruptedException异常，我们捕获异常退出即可。 注意，如果外部调用interrupt()方法时，线程处于非阻塞状态，那么状态被设置为interrupted；如果线程处于阻塞状态，那么抛出异常，但是线程状态不会被修改。所以，我们可以在捕获异常后自行设置中断状态，统一退出，看上去是更优雅的做法，代码如下。 public class MyThread extends Thread &#123; @Override public void run() &#123; while (!isInterrupted()) &#123; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; Thread.currentThread().interrupt(); &#125; &#125; &#125;&#125; Thread.currentThread().interrupt()手工设置中断状态，然后通过isInterrupted()判断退出。 实战原来停止或者中断一个线程如此麻烦，那实战中如何使用呢？ 其实，实战反而简单。因为实战中我们通常只实现Runnable接口，并把任务提交给Executor去处理。虽然我们自己没有创建Thread对象，但最后线程池里面保存的肯定是Thread对象，也就是说Executor帮我们创建了Thread对象，它实现了一种中断机制来保证任务可以被中断或取消。 下面通过例子代码看看如何使用。 TODO FutureTask的取消]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>并发</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程基础篇(4) 线程同步]]></title>
    <url>%2F2018%2F04%2F28%2Fthread-basic-signal%2F</url>
    <content type="text"><![CDATA[线程同步我们已经了解如何创建一个线程，以及如何交给线程池去调度，接下来看看线程之间同步的问题。之所以引入线程同步的原因是临界资源和竞争条件，我们先不讨论，放到后面去了解，这里先来看如何实现线程同步。 synchronized关键字synchronized用来标识同步语句块，同步语句块同一时间只能有一个线程执行，其他线程都必须等这个线程执行完成，起到了同步锁的作用。并发操作添加synchronized后意味着变成了串行操作，一次只能执行一个。 四种同步方法synchronized可以用在以下四个位置进行同步 类的成员方法上 静态方法上 类成员方法内部的语句块上 静态方法内部的语句块上 synchronized语义可以理解为对一个对象的锁定，同一时刻只有一个线程可以操作这个对象，其他线程被锁定。或者说，synchronized语句意味着synchronized代码块与一个对象进行了关联，需要先锁定这个对象，然后才能执行synchronized代码块，当然这个对象只能被锁定一次，当退出synchronized代码块时可以解锁这个对象。 下面依次来看一下synchronized关键字放置在不同位置的效果 类成员方法 public class Math() &#123; public synchronized void add(int value)&#123; this.count += value; &#125;&#125; 上述代码意味着，synchronized语句块（this.count += value;）的执行，必须先要获得Math类实例对象的锁，然后才可以执行。当两个线程同时执行一个Math对象的add()方法，后执行的线程加锁失败，必须等到先执行的线程操作完成，退出synchronized语句块解锁后才能开始执行。 注意，锁定的是对象，不是类，如果两个线程创建了两个Math对象，那么是可以同时调用它们的add()方法的。 静态方法 public class Math() &#123; public static synchronized void add(int value)&#123; Math.count += value; &#125;&#125; 可以认为静态方法同步锁的是类对象（区分类对象和实例对象），所以两个线程对静态同步方法的调用一定是互斥的。 方法内部语句块 public class Math &#123; public void add(int value)&#123; synchronized(this) &#123; this.count += value; &#125; &#125;&#125; 其效果和第一种把synchronized加到类成员方法上面是一样的。其实，这样写更明显，可以认为是第一种的翻译。 静态方法内部语句块 public class Math &#123; public void add(int value)&#123; synchronized(Math.this) &#123; this.count += value; &#125; &#125;&#125; 同上，这种写法和第三种是一样的，效果也一样。 思考一下：如果一个类有两个方法，一个静态，一个非静态，都加上synchronized关键字，可以同时执行吗？答案是可以。因为一个锁定的是实例对象this，另外一个锁定的是类对象Math.this，不是一个对象，所以可以同时执行。 Object对象 synchronized关键字不一定非要修饰this，也可以自己指定任何一个Object对象实例，如下也可行： public class Math &#123; private Object lock = new Object(); public void add3(int value)&#123; synchronized(lock) &#123; this.count += value; &#125; &#125;&#125; 选用哪种方法有这么多种同步方法，实战中我们应该选择哪一种呢。个人建议选择“方法内部语句块”的同步方法，这样同步对象非常明确，不容易引起混淆。此外，同步语句块的颗粒度也可以小于同步方法，减小同步语句块通常也是提升性能的方法之一。 字符串常量再来多思考一层，像下面这样写行不行呢？ public class Math &#123; private String lock = "lock"; public void add(int value)&#123; synchronized(lock) &#123; this.count += value; &#125; &#125;&#125; 说行也对，应该不会报错；说不行也对，因为这样有隐患，强烈不建议这么用。详细说一下，如果只有一个类这么用是不会出错的，但是如果有两个类这么用就出问题了。 public class Math &#123; private String lock = "lock"; public void add(int value)&#123; synchronized(lock) &#123; this.count += value; &#125; &#125;&#125;public class Work &#123; private String lock = "lock"; public void work(int value)&#123; synchronized(lock) &#123; //doSomething &#125; &#125;&#125; 如上，完全不相干的两个类，add()方法和work()的调用将会互斥，因为两个方法都将试图锁定相同的字符串实例。这里多说一下，理论上讲，虽然字符串内容一样，但是Math和Work两个类中的lock应该是不同的对象；但是，为了效率，Java提供了常量池的概念，导致两个类中的lock对象都是常量池中”lock”的引用，所以就一样了。 正常情况，String也是一个普通的类，那么lock作为String类的实例对象，应该在堆上分配空间，并且 “lock” 应该保存在堆空间上。如果是这样的话，两个类中的lock对象就不一样了。例如：把String lock = “lock”换成 Object lock = new Object()就没有问题了。但是实际情况是，创建String对象时，字符串内容没有保存到堆空间上，而是在方法区开辟了一块空间来保存，这块空间也被成为常量池。常量池是有去重逻辑的，当创建第二个lock对象时，发现常量池中已经存在就不会再创建了，直接返回已有常量字符串。 wait/nofity/notifyAll有了synchronized以后，其实我们已经可以进行线程通信了。例如：我们可以创建一个线程共享对象MySignal，一个线程在完成工作后，修改hasDataToProcess标志，另外一个线程轮询这个标志位，当第一个线程任务完成后第二个线程开始自己的任务。 public class MySignal&#123; protected boolean hasDataToProcess = false; public synchronized boolean hasDataToProcess()&#123; return this.hasDataToProcess; &#125; public synchronized void setHasDataToProcess(boolean hasData)&#123; this.hasDataToProcess = hasData; &#125;&#125; 以上模型有一个明显的问题，就是第二个线程需要一直查询，占用CPU时间，所以更常用的线程间通信机制是wait和notify，调用wait()方法后当前线程进入阻塞，让出CPU时间片。 调用wait()方法将使当前线程进入等待状态，直到有其他线程调用了notify()方法后唤醒。wait()有点像sleep()，但是也有很大的区别。 首先，一定要注意sleep()是Thread类的静态方法，wait()是Object类的成员方法，这非常重要。虽然wait和notify是用来实现线程通信的，但是它们并不是Thread类的方法。其实这也非常好理解，假设实现方案是调用Thread类的wait()方法进入等待状态，那么如何把它唤醒呢，肯定还得调用这个Thread类对象的notify()方法来唤醒；那么我们知道肯定需要在其他线程中完成某一项工作后唤醒这个线程，那就意味着另外一个线程得拥有这个线程的类实例对象，这明显是不合适的。退一步，两个线程之间共享对象就合理多了。 其次，wait()和notify()方法必须在synchronized代码块内执行，也就是说，首先你得拥有这个对象的锁，然后才可以调用wait()和notify()方法。解析一下，通常的逻辑如下：一个线程获得Object对象锁进入synchronized代码块开始自己的工作，需要时调用wait()方法进入等待；这个时候另外一个线程获得Object对象锁进入synchronized代码块，执行自己的任务，任务完成后调用notify()方法，唤醒正在等待的线程。其实，以上就是生产者-消费者基本的处理逻辑。 最后，调用一个对象的notify()方法后，将唤醒一个在这个对象上wait()的线程，如果有多个现线正在wait()，那么由操作系统来决定唤醒哪一个，可以认为是随机的；如果调用的是notifyAll()方法，那么这个对象上wait()的全部线程都将被唤醒。 需要注意，notify()唤醒只是意味着wait()线程进入runnable状态，也就是可以执行的状态，至于什么时间能够被执行，还是看操作系统调度。换句话说，notify()的确可以唤醒线程，但是被唤醒线程什么时间能够被执行是没有保障的，运气不好的话，如果CPU一直在忙，那么被唤醒线程也可能很久都得不到执行。 下面来看一个例子，这里只展示基本用法，通过生产者和消费者的例子可以看的更清楚 public class MonitorObject&#123;&#125;public class MyWaitNotify&#123; MonitorObject myMonitorObject = new MonitorObject(); public void doWait()&#123; synchronized(myMonitorObject)&#123; try&#123; myMonitorObject.wait(); &#125; catch(InterruptedException e)&#123;...&#125; &#125; &#125; public void doNotify()&#123; synchronized(myMonitorObject)&#123; myMonitorObject.notify(); &#125; &#125;&#125; 丢失问题这里同样存在使用常量字符串做为同步对象的问题。 public class WaitNotify extends Thread &#123; private String myMonitorObject = "lock"; boolean wasSignalled = false; @Override public void run() &#123; doWait(); &#125; public void doWait()&#123; System.out.println("notify doWait start"); synchronized(myMonitorObject)&#123; while(!wasSignalled)&#123; try&#123; myMonitorObject.wait(); &#125; catch(InterruptedException e)&#123; &#125; &#125; wasSignalled = false; &#125; System.out.println("notify doWait done"); &#125; public void doNotify()&#123; synchronized(myMonitorObject)&#123; wasSignalled = true; myMonitorObject.notify(); &#125; &#125;&#125; public class WaitNotify2 extends Thread &#123; private String myMonitorObject = "lock"; boolean wasSignalled = false; @Override public void run() &#123; doWait(); &#125; public void doWait()&#123; System.out.println("notify2 doWait start"); synchronized(myMonitorObject)&#123; while(!wasSignalled)&#123; try&#123; myMonitorObject.wait(); &#125; catch(InterruptedException e)&#123; &#125; &#125; wasSignalled = false; &#125; System.out.println("notify2 doWait done"); &#125; public void doNotify()&#123; synchronized(myMonitorObject)&#123; wasSignalled = true; myMonitorObject.notify(); &#125; &#125;&#125; public class ThreadSignal &#123; public static void main(String[] args) throws InterruptedException &#123; WaitNotify notify = new WaitNotify(); WaitNotify2 notify2 = new WaitNotify2(); notify.start(); notify2.start(); Thread.sleep(1000); System.out.println("send signal"); notify.doNotify(); &#125;&#125; 由于WaitNotify和WaitNotify2实际上使用的是一个锁对象，所以实际上现在myMonitorObject对象上有两个wait()，当我们调用notify.doNotify()时，会随机选择一个来唤醒。如果唤醒的是WaitNotify，那么没有问题；如果唤醒的是WaitNotify2，那么就出问题了。 生产者和消费者实例通过经典的生产者和消费者的例子，可以看到Thread类和Object类如何配合，以及线程的生命周期和状态变化。 需求 两个线程，一个线程作为生产者生产商品，一个线程作为消费者消费商品； 商品有库存，当库存满时生产者暂停生产，当库存空时消费者暂停消费。 实现主线程 创建库存列表，启动生产者线程和消费者线程 public class ProducerAndConsumer &#123; public static void main(String[] args) &#123; LinkedList&lt;String&gt; storeList = new LinkedList&lt;&gt;(); // 生产者和消费者共享库存列表 Producer producer = new Producer(storeList); Consumer consumer = new Consumer(storeList); producer.start(); consumer.start(); &#125;&#125; 生产-消费逻辑 开始库存是空的，先生产一个数据 此后如果可以抢到synchronized锁，可以继续生产数据，直到库存满 库存满了以后主动让出时间片，进入waiting状态，等待消费者notify() 如果生产完第一个数据后没有抢到synchronized锁，那么进入blocked状态，等待消费者退出synchronized代码块；当消费者完成一次消费操作退出synchronized代码块后，生产者线程进入runnable状态，等待CPU调度；抢到CPU时间片后可以继续生产 如果生产者线程一直没有抢到CPU时间片，那么消费者一直消费（一次消费一个），直到库存空 库存空以后消费者交出时间片，生产者获得时间片，继续生产数据 生产数据后通过notify()方法唤醒消费者线程 生产者notify()方法只能保证消费者线程进入runnable状态，但不一定能抢到时间片执行 大家都是runnable状态时，谁能得到CPU时间片就看人品了，操作系统就可以这么任性 生产者线程public class Producer extends Thread &#123; // 库存最大容量 private final static int MAX = 10; // 计数器，方便观察 private AtomicInteger count = new AtomicInteger(1); // 库存 private LinkedList&lt;String&gt; storeList; public Producer(LinkedList&lt;String&gt; storeList) &#123; this.storeList = storeList; &#125; @Override public void run() &#123; // 获得时间片，进入running状态 while(true) &#123; // 必须在synchronized代码块内使用wait()和notify() // 如果storeList已经被其他线程锁定，进入blocked状态 // 如果storeList没有被其他线程锁定，继续running状态 synchronized (storeList) &#123; while(storeList.size() == MAX) &#123; System.out.println("库存满了"); try &#123; // 库存满了，不能再生产了 // 让出时间片，进入waiting状态 // 操作系统负责保存当前线程状态，当恢复时从这里继续执行 storeList.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; // storeList.size() &lt; MAX 时，直接生产一个新数据 // storeList.size() = MAX 时，消费者调用storeList.notify()时, // 进入runnable状态，获得时间片后继续执行，生产一个新数据 String data = String.format("%04d", count++); storeList.add(data); System.out.println("生产 " + data); // 让出时间片，进入waiting状态 try &#123; Thread.sleep(500); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; // Sleep 500毫秒后进入runnable状态，获得时间片后继续执行 // 通知消费者，如果消费者由于库存空了进入waiting状态，此时将被唤醒 storeList.notifyAll(); // 此后重新尝试进入synchronized代码块 &#125; &#125; &#125;&#125; 消费者线程public class Consumer extends Thread &#123; // 库存 private LinkedList&lt;String&gt; storeList; public Consumer(LinkedList&lt;String&gt; storeList) &#123; this.storeList = storeList; &#125; @Override public void run() &#123; // 获得时间片，进入running状态 while(true) &#123; // 如果storeList已经被其他线程锁定，进入blocked状态 // 如果storeList没有被其他线程锁定，继续running状态 synchronized (storeList) &#123; while(storeList.size() == 0) &#123; System.out.println("库存空了"); try &#123; // 库存空了，不能再消费了 // 让出时间片，进入waiting状态 storeList.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; // storeList.size() &gt; 0 时，直接消费一个数据 // storeList.size() = 0 时，生产者调用storeList.notify()时, // 进入runnable状态，获得时间片后继续执行，消费一个数据 String data = storeList.get(0); System.out.println("消费 " + data); storeList.remove(0); // 让出时间片，进入waiting状态 try &#123; Thread.sleep(500); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; // 通知生产者，如果生产者由于库存满了进入waiting状态，此时将被唤醒 storeList.notifyAll(); // 此后重新尝试进入synchronized代码块 &#125; &#125; &#125;&#125; 输出结果分析 下表列出了输出结果和对应的线程状态 日志输出 Producer PC Producer状态 Consumer PC Consumer状态 生产 0001 storeList.add(); running runnable 消费 0001 synchronized () blocked storeList.remove(); running 库存空了 synchronized () blocked storeList.wait(); waiting 生产 0002 storeList.add(); running storeList.wait(); waiting 生产 0003 storeList.add(); running storeList.wait(); waiting synchronized () blocked 消费 0002 synchronized () blocked storeList.remove(); running 消费 0003 synchronized () blocked storeList.remove(); running 库存空了 synchronized () blocked storeList.wait(); waiting 生产 0004 storeList.add(); running storeList.wait(); waiting …… 生产 0013 storeList.add(); running synchronized () blocked 库存满了 storeList.wait(); waiting synchronized () blocked 消费 0004 storeList.wait(); waiting storeList.remove(); running 消费 0005 synchronized () blocked storeList.remove(); running 消费 0006 synchronized () blocked storeList.remove(); running 生产 0014 storeList.add(); running synchronized () blocked 生产 0015 storeList.add(); running synchronized () blocked 注意：每生产或者消费一个数据以后都通过storeList.notify()来唤醒对手方的storeList.wait()，但是唤醒只能保证对手方线程进入runnable状态；这个时候继续执行当前线程(notify)，还是切换到等待线程(wait)是由操作系统来调度的，是随机的。此外，由于synchronized的存在，多CPU情况下生产者和消费者也不会长期同时处于running状态，短暂同时处于running状态后，后进入synchronized代码块的线程将进入blocked状态，等待前进入的线程退出synchronized代码块。]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>并发</tag>
        <tag>线程</tag>
        <tag>synchronized</tag>
        <tag>wait</tag>
        <tag>notify</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【置顶】Java多线程]]></title>
    <url>%2F2018%2F04%2F27%2Fthread-catalog%2F</url>
    <content type="text"><![CDATA[引言Java多线程和锁是分布式和并发编程的基础，深入理解Java多线程是我们提升内功的重要途径。我将试图由浅入深学习Java多线程编程，从如何使用入手，掌握如何使用之后再探求其中的内部原理，需要时也会对源码进行解读。 目录以下为各个章节的目录，应用相关的我称之为基础篇，原理相关的我称之为中级篇，其中可能有部分比较复杂的，我称之为高级篇。以下内容多为原创，图是从参考资料中截取的。 多线程基础篇 以代码为例，展示最基本的应用场景和使用方法。简单说，就是怎么使用。 为什么需要多线程，多线程能够解决什么问题？多线程又带来哪些问题？如何拥有新的一个线程？ 多线程基础篇(1) 线程 有了线程之后，如何管理？线程如何调度？如何创建线程池？线程池有哪些参数，能够控制哪些行为？ 多线程基础篇(2) 线程池 多线程基础篇(3) ThreadPoolExecutor 创建了多线程之后，多线程之间如何通信？如何使用synchronized和wait/notify实现线程同步？如何编写经典的生产者-消费者代码？ 多线程基础篇(4) 线程同步 并行包java.util.concurrent如何使用？ 多线程基础篇(5) 并行包使用 ThreadLocal如何使用？ [多线程基础篇(6) ThreadLocal] 多线程中级篇 探求内部实现原理和复杂一些的用法。简单说，就是内部基本原理。 线程从创建到销毁，内部都要经过哪些状态？各个状态之间如何变化？线程状态迁移图是怎样的？ 多线程中级篇(1) 线程状态 当启动线程后，如果取消、关闭和中断一个进行中的线程？ 多线程中级篇(2) 线程中断 什么是JMM？什么是重排序？什么是内存屏障？volatile如何解决内存可见性与有序性问题？ 多线程中级篇(3) Java内存模型 多线程有哪些问题？什么是临界资源和竞争条件？什么是虚假唤醒？什么是死锁、嵌套死锁和重入死锁？什么是线程饥饿？ [多线程中级篇(4) 多线程同步问题] 并行包中 多线程高级篇 复杂原理，或者操作系统级别的实现原理。简单说，就是如果从头自己实现，需要怎么做。 线程底层是如何实现的？一个JAVA线程对应操作系统的什么？ 多线程高级篇(1) 线程实现 实现多线程有哪些常见的模型？Java采用的是哪一种模型？并发和并行的区别？ [多线程高级篇(2) 线程模型] 为什么要学习多线程并发是Java开发领域中经常被提及的问题，也是比较复杂的问题。提到并发就不得不提到多线程和锁，可以认为JVM的线程模型和加锁机制是Java并发的基础。实际工作中，我们可能不会经常去操作线程池，使用wait/notify进行线程间通信，所以对多线程感受并不强烈。这是因为我们通常都是在框架的基础上进行开发，框架帮我做了这些事情，虽然我们没有感觉到，但是从服务启动那一刻开始，Java多线程机制一直在运转。 多线程少被提及的另一个原因，我认为与现代系统都是分布式系统有关，或者说是多进程的分布式系统有关，更多被提到的是多进程之间如何通信，如果处理高并发的问题。线程间通信局限在一个JVM进程之内，所以多线程的处理机制并不能解决多进程的问题(例如：synchronized可以在一个JVM进程内加锁实现线程互斥的目的，但是当我们分布式部署时，一个服务有多个进程实例，synchronized就起不到相应的作用了)。 既然在分布式系统中多线程机制已经不能解决问题了，那我们为什么还需要去了解Java多线程的原理和应用呢？ 首先，每个服务都是一个JVM进程，由多个线程组成，虽然框架帮我们封装了线程操作，把我们从复杂的多线程调度中解放处理，专注于业务逻辑；但是当出现问题或者需要调优时，了解底层的实现机制就显得必要；可以做一个这样的类比，平时我们也可以不关注JVM GC相关的内容，通常我们的Java应用可以很好的运行，但是当出现内存不足、内存泄漏等问题时，就需要我们了解GC的原理了。 其次，初期我们通常选用开源框架搭建业务服务；但是要明白框架或者中间件的出现通常是为了满足一个具体的需求而产生的，当任务完后进行抽象、剥离，开源后形成框架的；这就意味着所谓开源框架不是为你的业务需求而生的，很可能在某些方面不能满足、或者不能完美实现我们的需求；这个时候就需要我们在开源框架的基础上进行定制化修改（例如：阿里定制化MySQL），或者完全重新实现一个（例如：阿里借鉴Kafka原理实现RocketMQ），这个时候理解多线程机制就显得尤为重要了。 最后，多线程并发和多进程并发虽然有区别，但是也有很多类似之处；虽然具体的处理方法上可能差别较大，但是如果从思路和原理的角度来看，两者有非常多的相同点。例如，我们知道JDK1.5的并发包中提供了种类丰富的锁，那么我们在实现分布式锁的时候，就可以参考JDK中实现。还有，虽然多线程解决的是一个进程内的问题，但是和多进程一样都是并发操作引发的问题，即使解决方案不同，遇到的问题也是类似的。例如，多线程里面经常提到volatile，volatile解决的是什么问题呢？我们这里不讨论如何解决，只讨论问题是什么。我认为，本质上volatile解决的是由于缓存带来的与主内存不一致的问题。接下来开一下脑洞，多线程存在这个问题，多进程是否也有同样的问题呢？当然存在，如果我们把数据库看作主内存，那么在进程中缓存数据库中的数据就和线程的工作内存没有两样，当回写时就有可能出现问题。 当我们遇到问题时，类比是一种解决问题的思路。能够创新性的发明一种新的方法来解决问题的是大师，可遇而不求；能够找到类似问题的历史解决方案并设计出相应的解决方法， 通俗的说，如果你可以熟练使用Java多线程编程，那么你就至少是中级程序员了；如果还可以明白背后的原理，并引申有自己的思考，那么我认为你自称高级程序员不会有人质疑。 关于Java并发和多线程的资料有很多，网上一搜一大堆。接下来我会按照我的理解和思路进行一番串联。我发现很多书籍都是先讲原理，再讲应用，这和我们的实践是相悖的。通常，我们都是在不完全了解的情况下先使用，在使用过程中发现问题或者不清楚的地方再去看原理，这才是正常的思维。所以，我会先从应用开始：首先，我们要达到一个什么样的目的（目标）；接下来，我们要如何做才能实现目标（应用），最后才是为什么要这么做，其背后深层次的原因是什么（原理）。 有时候想，如果现在让我重新回到大学去学习计算机组成原理、操作系统原理、编译原理等，应该有不同理解。 参考资料http://www.cnblogs.com/skywang12345/p/3479949.html https://blog.csdn.net/huzhigenlaohu/article/details/51627201 http://ifeve.com/non-blocking-algorithms/ 笔记 为什么要有多线程，多线程解决哪些问题？现代计算机拥有多个处理器，每个处理器又拥有多个核心；多线程的目的就是为了提升性能，让多个任务可以同时运行。如果只有一个线程，那么只会用到一个处理器的一个核心，CPU资源将被浪费。 多线程带来好处的同时，也带来成本和开销。 实现多线程有很多中模型，Java采用的是哪一种？（高级） 并发和并行的区别？ 多线程和多进程的区别？ 如何拥有一个线程？怎么把多线程创建出来？ 引入多线程以后，带来了哪些问题？临界资源/竞争条件/ 哪些资源是临界资源，可能在多线程执行过程中出现问题（内存、栈、堆） 多线程以后怎么办？Java内存模型。 基础篇-使用 Thread/ThreadPool/ReentrantLock/BlockingQueue/volatile/ThreadLocal/AtomicInteger/wait/notify/synchronized 中级篇-原理 JMM/指令重排序/内存屏障/线程饥饿/CAS 高级篇-分析 并行包源码，自己实现，字节码分析，汇编码分析 什么是线程，为什么要多线程 如何创建线程 如何调度多线程 多线程带来了哪些问题:只有共享才有问题，不共享就没问题,哪些变量共享？ ThreadLocal，每个线程不一样，不共享 一个一个解决多线程带来的问题:缓存/指令重排序/死锁/嵌套锁死/重入锁死/虚假唤醒（自旋锁）/饥饿 volatile，一个写，多个读 synchronized，多个写（锁，解锁） wait/notify，多线程之间的通信 以上已经实现了锁的功能，后面都是如何解决问题和提交效率了:线程饥饿/重入/读 &gt;&gt; 写 Lock显式锁:显示意味着可以控制更多 ReentreLock，可重入锁（解决了饥饿问题？） 读操作也需要锁吗？如果一个写，多个读用volatile就好，不用锁。如果只是读很多，写比较少呢？读写锁出现了 java.util.concurrent包源码分析，JDK1.5以后并行包提供了一切，直接用就行了，最好理解源码和原理 CAS乐观锁(AtomicInteger使用CAS实现) ConcurrentLinkedQueue 多个线程读，不需要锁； 一个线程写，多个线程读，volatile； 多个线程写，synchronized 读多写少，ReadWriteLock]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>并发</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程中级篇(1) 线程状态]]></title>
    <url>%2F2018%2F04%2F25%2Fthread-status%2F</url>
    <content type="text"><![CDATA[线程状态一个新线程启动后，从开始运行一直到最后任务执行完成销毁这个线程，在整个线程生命周期中有哪几个状态，各个状态之间如何流转，本文将给出详细解释。 线程状态迁移下面的这个线程状态迁移图是比较经典的，画的很详细，理解了这幅图就理解了线程状态变化。 线程的几个状态 [new]：初始状态，新建一个线程对象后的状态； [runnable]：就绪状态，调用了start()方法后，线程等待CPU资源准备执行的状态； [running]：运行状态，得到了CPU时间片，执行run()方法或者call()方法； [dead]：销毁状态，线程任务执行结束或者强制退出后的状态； [blocked]：阻塞状态，被动失去CPU时间片，等待进入runnable状态； [waiting]：等待状态，主动失去CPU时间片，等待进入runnable状态； waiting状态和blocked状态的区别在于一个是主动交出时间片，另外一个是被动交出时间片；当然前提是已经获得了时间片开始执行；从runnable状态到running状态是不受程序控制的，完全靠操作系统来调度，虽然我们可以设置线程的优先级，但是不一定达到预期。 状态变化过程 [new]：MyThread thread = new MyThread(); [new]-&gt;[runnable]：thread.start(); [runnable]-&gt;[running]：操作系统调度，runnable状态意味着任务已经做好执行的准备，但什么时间真正执行（获得时间片）需要由操作系统来控制，任务本身无法控制； [running]-&gt;[dead]：线程执行完成； [running]-&gt;[runnable]： Thread.yield(); 调用yield()方法将失去时间片，但是可以立刻进入runnable状态，运气好的话可以立刻又获得时间片进入running状态；yield()给其他任务以执行的机会； [running]-&gt;[waiting]： thread.join();调用join()方法将失去时间片，进入waiting状态，等到thread线程执行完毕后进入runnable状态； object.wait(); 调用 wait()方法将失去时间片，进入waiting状态，得到其他线程执行object.notify()方法是进入runnable状态； Thread.sleep(); 调用sleep()方法将失去时间片，进入waiting状态，sleep结束后进入runnable状态； [running]-&gt;[blocked]：进入synchronized(object){}语句块前检查object锁，如果object已经被锁定，那么当前线程进入blocked状态，当object锁被释放后，当前线程进入runnable状态； [waiting]-&gt;[runnable]： thread.join(); 引发的，其他线程执行完成后进入runnable状态； object.wait(); 引发的，其他线程调用object.notify()或者object.notifyAll()后进入runnable状态； [blocked]-&gt;[runnable]：其他线程退出synchronized{}语句块以后进入runnable状态； 我们再通过表格的形式来看一下线程状态变化过程 方法调用 线程旧状态 线程新状态 备注 new Thread(); new thread.start(); new runnable Thread.yield(); running runnable thread.join(); running waiting Thread.sleep(); running waiting object.wait(); running waiting synchronized(object){} running blocked thread.interrupt(); running dead 子线程执行完成 waiting runnable 外部线程 Sleep()时间到 waiting runnable object.notify()或notifyAll(); waiting runnable 外部线程 退出synchronized代码块 blocked runnable 外部线程 个人理解，waiting状态和blocked状态的区别并不大，粗一点的话可以不区分它们。 相关方法Thread类和Object类相关方法 注意：区分Thread类和Object类的方法，区分静态方法和普通方法。 package java.lang;public class Thread implements Runnable &#123; public static native Thread currentThread(); public static native void yield(); public static native void sleep(long millis) throws InterruptedException; public synchronized void start() &#123; start0(); &#125; public void interrupt() &#123; interrupt0(); &#125; public final void setPriority(int newPriority) &#123; setPriority0(priority = newPriority); &#125; private native void start0(); private native void interrupt0(); private native void setPriority0(int newPriority);&#125; package java.lang;public class Object &#123; public final native void notify(); public final native void notifyAll(); public final native void wait(long timeout) throws InterruptedException;&#125; 以上可以看出，所有的关键方法都是native的，基于系统底层实现的。]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>并发</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程基础篇(3) ThreadPoolExecutor]]></title>
    <url>%2F2018%2F04%2F24%2Fthread-basic-threadpoolexecutor%2F</url>
    <content type="text"><![CDATA[原理理解了ThreadPoolExecutor类的各个参数和内部原理也就理解了线程池机制。 构造参数public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123;&#125; 先来看ThreadPoolExecutor类的参数 参数名称 含义 详解 corePoolSize 核心线程数 当前线程数小于corePoolSize时，会一直创建新线程 maximumPoolSize 最大线程数 最多可以创建maximumPoolSize个线程，超过进入饱和策略 keepAliveTime 空闲时间 当超过corePoolSize时，回收线程时使用 unit 时间单位 配合keepAliveTime一起使用 workQueue 排队策略 最重要，排队策略决定了线程池的处理流程 threadFactory 工厂 创建线程时进行自定义操作 handler 饱和策略 配合workQueue使用，处理线程池满的情况 处理流程 基本逻辑 当线程池里面的线程数小于corePoolSize时，不管当前线程池中的线程是否空闲，都创建新的线程来执行任务，并加入到线程池中；这样随着任务的增加，线程池的线程数会达到corePoolSize个； 达到corePoolSize后，当新任务到来时，会选择空闲的线程来执行； 如果没有空闲线程，进入排队策略，不同的排队策略有不同逻辑； 当核心线程空闲时，会从排队队列中取出任务来执行； 当核心线程没有空闲，并且排队队列满时，创建新线程执行任务，最大不超过maximumPoolSize个； 当达到maximumPoolSize个线程，且都在忙，新任务到来时进入饱和策略，不同的饱和策略有不同逻辑；如果没有配置饱和策略，抛出RejectedExecutionException异常； 当线程数超过corePoolSize后，启动回收逻辑，空闲时间超过keepAliveTime的线程将被回收；回收时不区分核心线程和非核心线程，减少到corePoolSize个后不再回收。 排队策略不同，处理流程也不同，下面分别介绍常见三种排队策略的处理流程：SynchronousQueue、ArrayBlockingQueue和LinkedBlockingQueue。 SynchronousQueue简单说就是没有排队队列，或者队列长度为0，所以通常使用SynchronousQueue作为排队策略时，为避免出现线程执行被拒绝的情况，maximumPoolSize的值会被设置的很大。 ArrayBlockingQueue有界排队队列，必须设置队列长度；当线程数达到corePoolSize时，开始排队；当排队队列满时增加非核心线程直到maximumPoolSize。 LinkedBlockingQueueLinkedBlockingQueue如果不指定队列大小，那么就是无界队列；除非系统资源耗尽，将无限增加队列长度，因此无界队列不存在队列满的情况，也就没有非核心线程、饱和逻辑和线程回收逻辑；也就是说当设置workQueue为LinkedBlockingQueue时，keepAliveTime、unit和handler三个参数失效。 LinkedBlockingQueue也可以设置队列大小，就成了有界队列，和ArrayBlockingQueue的处理逻辑一样。 代码示例背景每个任务开始时输出“run”，结束时输出“exit”，不做具体逻辑，只是sleep1秒钟。 public static class Task implements Runnable &#123; @Override public void run() &#123; LOGGER.info("run"); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; LOGGER.info("exit"); &#125;&#125; 主线程 核心线程数2个，最大线程数4个，保活时间3秒 依次启动6个任务，每启动一个任务后都输出线程池大小 启动任务错误时输出异常信息 6个任务都启动完成后sleep 5秒，退出前再次输出线程池大小 public class ThreadExecutor &#123; private final static Logger LOGGER = LoggerFactory.getLogger(ThreadExecutor.class); public static void main(String[] args) &#123; int coreSize = 2; int maxSize = 4; long time = 3; TimeUnit unit = TimeUnit.SECONDS; ThreadPoolExecutor executor = new ThreadPoolExecutor(coreSize, maxSize, time, unit, queue, handler); for (int i=0; i&lt;6; i++) &#123; Task task = new Task(); try &#123; executor.submit(task); &#125; catch (Exception e) &#123; LOGGER.error(e.getClass().getSimpleName()); &#125; LOGGER.info("poolSize=" + executor.getPoolSize()); &#125; try &#123; Thread.sleep(5000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; LOGGER.info("poolSize=" + executor.getPoolSize()); LOGGER.info("exit"); &#125;&#125; 下面看看不同的workQueue和handler配置下的输出结果 测试结果无界队列LinkedBlockingQueue&lt;Runnable&gt; queue = new LinkedBlockingQueue&lt;&gt;(); 10:57:33:055 [pool-2-thread-1] run10:57:33:055 [main] poolSize=110:57:33:055 [main] poolSize=210:57:33:055 [main] poolSize=210:57:33:055 [pool-2-thread-2] run10:57:33:055 [main] poolSize=210:57:33:055 [main] poolSize=210:57:33:055 [main] poolSize=210:57:34:068 [pool-2-thread-2] exit10:57:34:068 [pool-2-thread-1] exit10:57:34:068 [pool-2-thread-1] run10:57:34:068 [pool-2-thread-2] run10:57:35:081 [pool-2-thread-1] exit10:57:35:081 [pool-2-thread-2] exit10:57:35:081 [pool-2-thread-1] run10:57:35:081 [pool-2-thread-2] run10:57:36:082 [pool-2-thread-1] exit10:57:36:082 [pool-2-thread-2] exit10:57:38:056 [main] poolSize=210:57:38:056 [main] exit 从日志中可以看出 当线程池达到核心线程数2后，一直保持在核心线程数不变 pool-2-thread-1和pool-2-thread-2顺序从队列中取出任务依次执行 有界队列ArrayBlockingQueue&lt;Runnable&gt; queue = new ArrayBlockingQueue&lt;&gt;(2);// LinkedBlockingQueue&lt;Runnable&gt; queue = new LinkedBlockingQueue&lt;&gt;(2); 11:01:23:147 [main] poolSize=111:01:23:147 [pool-2-thread-1] run11:01:23:147 [main] poolSize=211:01:23:147 [main] poolSize=211:01:23:147 [pool-2-thread-2] run11:01:23:147 [main] poolSize=211:01:23:147 [main] poolSize=311:01:23:147 [main] poolSize=411:01:23:147 [pool-2-thread-3] run11:01:23:147 [pool-2-thread-4] run11:01:24:147 [pool-2-thread-1] exit11:01:24:147 [pool-2-thread-1] run11:01:24:147 [pool-2-thread-2] exit11:01:24:147 [pool-2-thread-2] run11:01:24:147 [pool-2-thread-3] exit11:01:24:147 [pool-2-thread-4] exit11:01:25:158 [pool-2-thread-2] exit11:01:25:158 [pool-2-thread-1] exit11:01:28:154 [main] poolSize=211:01:28:154 [main] exit 从日志中可以看出 当队列（2个）满以后，增加了非核心线程pool-2-thread-3和pool-2-thread-4 核心线程pool-2-thread-1和pool-2-thread-2执行完第一个任务后，又从队列中取出第二个任务执行 主线程退出前线程池大小又回到了核心线程数，说明空闲线程已经被释放 同步移交+AbortSynchronousQueue&lt;Runnable&gt; queue = new SynchronousQueue&lt;&gt;();RejectedExecutionHandler handler = new ThreadPoolExecutor.AbortPolicy(); 11:07:26:130 INFO [main] poolSize=111:07:26:130 INFO [pool-2-thread-1] run11:07:26:132 INFO [main] poolSize=211:07:26:132 INFO [main] poolSize=311:07:26:132 INFO [pool-2-thread-2] run11:07:26:133 INFO [main] poolSize=411:07:26:133 ERROR [main] RejectedExecutionException11:07:26:133 INFO [main] poolSize=411:07:26:134 ERROR [main] RejectedExecutionException11:07:26:134 INFO [main] poolSize=411:07:26:135 INFO [pool-2-thread-3] run11:07:26:135 INFO [pool-2-thread-4] run11:07:27:143 INFO [pool-2-thread-3] exit11:07:27:143 INFO [pool-2-thread-2] exit11:07:27:143 INFO [pool-2-thread-4] exit11:07:27:143 INFO [pool-2-thread-1] exit11:07:31:150 INFO [main] poolSize=211:07:31:150 INFO [main] exit 从日志中可以看出 当线程数到达最大线程数4个以后，再提交的任务抛出了RejectedExecutionException异常 所以与前面的结果不同，这次只执行了4个任务 最后空闲线程被回收，线程数保持在2个 AbortPolicy是默认的饱和策略 以下已空队列为例，更换饱和策略 同步移交+DiscardSynchronousQueue&lt;Runnable&gt; queue = new SynchronousQueue&lt;&gt;();RejectedExecutionHandler handler = new ThreadPoolExecutor.DiscardPolicy(); 11:12:20:113 INFO [pool-2-thread-1] run11:12:20:113 INFO [main] poolSize=111:12:20:113 INFO [main] poolSize=211:12:20:113 INFO [pool-2-thread-2] run11:12:20:113 INFO [main] poolSize=311:12:20:113 INFO [main] poolSize=411:12:20:113 INFO [pool-2-thread-3] run11:12:20:113 INFO [main] poolSize=411:12:20:113 INFO [main] poolSize=411:12:20:113 INFO [pool-2-thread-4] run11:12:21:128 INFO [pool-2-thread-4] exit11:12:21:128 INFO [pool-2-thread-2] exit11:12:21:128 INFO [pool-2-thread-3] exit11:12:21:128 INFO [pool-2-thread-1] exit11:12:25:119 INFO [main] poolSize=211:12:25:119 INFO [main] exit 对比上面的日志可以发现 同样也是只执行了4个任务 区别在于没有抛出异常，也就是说Discard策略直接拒绝，来异常都不给，没啥用 同步移交+CallerRunSynchronousQueue&lt;Runnable&gt; queue = new SynchronousQueue&lt;&gt;();RejectedExecutionHandler handler = new ThreadPoolExecutor.CallerRunsPolicy(); 11:18:11:432 INFO [pool-2-thread-1] run11:18:11:432 INFO [main] poolSize=111:18:11:434 INFO [main] poolSize=211:18:11:434 INFO [pool-2-thread-2] run11:18:11:434 INFO [main] poolSize=311:18:11:435 INFO [main] poolSize=411:18:11:435 INFO [main] run11:18:11:435 INFO [pool-2-thread-3] run11:18:11:435 INFO [pool-2-thread-4] run11:18:12:447 INFO [pool-2-thread-4] exit11:18:12:447 INFO [main] exit11:18:12:447 INFO [pool-2-thread-3] exit11:18:12:447 INFO [pool-2-thread-2] exit11:18:12:447 INFO [pool-2-thread-1] exit11:18:12:447 INFO [main] poolSize=411:18:12:447 INFO [main] run11:18:13:448 INFO [main] exit11:18:13:448 INFO [main] poolSize=411:18:18:454 INFO [main] poolSize=211:18:18:454 INFO [main] exit 从日志中可以看出 当线程数到达最大线程数4个以后，第5个任务开始在main线程中执行 CallerRunsPolic保证了线程不会被丢弃，但交给主线程运行没有起到线程池的作用，应该也不常用 实战Executorspackage java.util.concurrent;public class Executors &#123; public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;())); &#125; public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()); &#125; public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;()); &#125; &#125; Executors类提供了常用线程池的创建方法，不过不建议使用Executors来创建线程池，因为这会隐藏最终创建ThreadPoolExecutor类的参数，还是建议手工构造ThreadPoolExecutor，显示指定参数。下面详细看看三个预定义的线程池： SingleThread，顾名思义，线程池的核心和最大线程数都是1，无界排队策略；也就是说这个线程池中只有1个线程，其他并发线程排队等待，线程池一个一个来处理，简单，但是效率比较低； FixedThread，线程池的核心线程数与最大线程数保持一致，无界排队策略；也就是说这个线程池中没有非核心线程，最多可以同时处理N个任务，其他任务排队等待；SingleThread可以看作N=1的FixedThread； CachedThread，核心线程数0，最大线程数无穷大，无排队队列，保活时间60秒；也就是说这个线程池中的线程数是动态变化的，当有新任务时就创建新线程来处理（当前线程都在忙），处理完成后1分钟回收线程；如果没有任务，线程数就是0，如果任务非常多，线程数无限增加，直到耗尽系统资源。 以上可以看出，Executors默认提供的几种线程池比较极端，实战中需要自定义ThreadPoolExecutor。 核心线程数虽然排队策略看上去比较复杂，但我认为ThreadPoolExecutor最重要的参数是核心线程数；因为考虑到不拒绝任何任务，我们可以使用LinkedBlockingQueue实现无界队列，这样其他参数基本就都失效了，而核心线程数即使当前没有任务也要保留，就变得异常重要的。 确定核心线程数，一般的思路是根据任务性质来判断的。如果是计算密集型任务，那么通常核心线程数设置为CPU个数+1，通过Runtime.getRuntime().availableProcessors();可以读取CPU个数。如果是I/O密集型任务，那么中断会多一些，核心线程数也可以多一些，一般可以设置为CPU个数的2倍。 Apache MINA 的核心线程数设置为CPU个数+1s=>start: 开始 e=>end: 结束 condCore=>condition: 小于核心线程数? condMax=>condition: 小于最大线程数? addCore=>operation: 增加核心线程 addNormal=>operation: 增加非核心线程 full=>operation: 饱和逻辑处理 s->condCore condCore(yes, right)->addCore condCore(no)->condMax condMax(yes, right)->addNormal condMax(no)->full addNormal->e addCore->e full->e{"theme":"simple","scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12} var code = document.getElementById("flowchart-0-code").value; var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-0-options").value)); var diagram = flowchart.parse(code); diagram.drawSVG("flowchart-0", options);s=>start: 开始 e=>end: 结束 condCore=>condition: 小于核心线程数? condQueue=>condition: 队列未满? condMax=>condition: 小于最大线程数? addCore=>operation: 增加核心线程 addNormal=>operation: 增加非核心线程 addQueue=>operation: 排队等待执行 full=>operation: 饱和逻辑处理 s->condCore condCore(yes, right)->addCore condCore(no)->condQueue condQueue(yes, right)->addQueue condQueue(no)->condMax condMax(yes, right)->addNormal condMax(no)->full addQueue->e addNormal->e addCore->e full->e{"theme":"simple","scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12} var code = document.getElementById("flowchart-1-code").value; var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-1-options").value)); var diagram = flowchart.parse(code); diagram.drawSVG("flowchart-1", options);s=>start: 开始 e=>end: 结束 condCore=>condition: 小于核心线程数? addCore=>operation: 增加核心线程 addQueue=>operation: 排队等待执行 s->condCore condCore(yes)->addCore condCore(no)->addQueue addQueue->e addCore->e{"theme":"simple","scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12} var code = document.getElementById("flowchart-2-code").value; var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-2-options").value)); var diagram = flowchart.parse(code); diagram.drawSVG("flowchart-2", options);]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>并发</tag>
        <tag>线程</tag>
        <tag>线程池</tag>
        <tag>排队策略</tag>
        <tag>饱和策略</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程基础篇(2) 线程池]]></title>
    <url>%2F2018%2F04%2F24%2Fthread-basic-threadpool%2F</url>
    <content type="text"><![CDATA[任务调度任务是一组逻辑工作单元，线程则是任务异步执行的机制。前面说过，实战中我们不会直接调用Thread类的start()方法来启动线程，那么线程应该如何启动呢？ Executor使用Executor.execute(task);来替代new Thread(task).start(); package java.util.concurrent;public interface Executor &#123; void execute(Runnable command);&#125; Executor将任务提交给线程池来处理，线程池的处理是异步的，任务会交给新的线程来执行，本地线程可以继续做其他事情。 ExecutorServiceExecutor只有一个没有返回值的接口execute()，为了更好的控制线程的行为，并行包中为我们提供了功能更强大的ExecutorService，实际使用过程中，更多使用的是ExecutorService的接口。 package java.util.concurrent;public interface ExecutorService extends Executor &#123; &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task); Future&lt;?&gt; submit(Runnable task); &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result); void shutdown(); List&lt;Runnable&gt; shutdownNow();&#125; 下面详细看一下ExecutorService的几个接口 submit提交任务有三个接口，区别在于任务类实现了哪个接口，以及是否需要读取返回结果 Callable：下面的例子用来计算1+2+…+N的和，任务完成后返回计算结果 public class Task implements Callable&lt;Integer&gt; &#123; private int count = 0; public Task(int count) &#123; this.count = count; &#125; @Override public Integer call() throws Exception &#123; int sum = 0; for (int i=1; i&lt;=count; i++) &#123; sum += i; &#125; LOGGER.info("done"); return sum; &#125;&#125; 再来看看任务调度，通过future.get()可以获取返回的计算结果55。future.get()是一个阻塞方法，如果task线程执行需要很长时间，那么main线程将会停在这里一直到task线程处理完成。 ExecutorService executor = Executors.newSingleThreadExecutor();Task task = new Task(10);Future&lt;Integer&gt; future = executor.submit(task);Integer result = future.get();LOGGER.info("result=" + result); 这里和new Thread().start()没有本质的区别，都达到相同的效果，区别在于这里使用了线程池。 Runnable：完成相同的功能，由于run()方法没有返回值，我们在构造Task对象时增加了Data参数 public class Task implements Runnable &#123; private final Data data; private int count = 0; public Task(int count, Data data) &#123; this.count = count; this.data = data; &#125; @Override public void run() &#123; int sum = 0; for (int i=1; i&lt;=count; i++) &#123; sum += i; &#125; data.setResult(sum); &#125;&#125;public static class Data &#123; private Integer result; public Integer getResult() &#123; return result; &#125; public void setResult(Integer result) &#123; this.result = result; &#125; &#125; 再来看看任务调度，通过future.get()可以获得Data对象，然后从Data对象中获取计算结果55。 这里调用的是submit(Runnable task, T result)方法，如果调用submit(Runnable task)方法是无法获取到计算结果的，future.get()返回null，只能表明计算任务已经完成。 ExecutorService executor = Executors.newSingleThreadExecutor();Data data = new Data();Task task = new Task(10, data);Future&lt;Data&gt; future = executor.submit(task, data);Integer result = future.get().getResult();LOGGER.info("result=" + result); 这里重点演示submit()的用法，线程池使用了最简单的SingleThreadExecutor shutdownshutdown()方法在关闭ExecutorService之前等待提交的任务执行完成，shutdownNow()方法阻止开启新的任务并且尝试停止当前正在执行的线程。 下面通过例子验证一下 定义任务：没有实际逻辑，只是sleep 1秒钟，任务开始和结束后输出日志 public class Task implements Runnable &#123; @Override public void run() &#123; LOGGER.info("run"); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; LOGGER.error(e.getMessage()); &#125; LOGGER.info("done"); &#125;&#125; 主线程：一共5个任务，为方便观察每提交一个任务后等待100毫秒；当提交完成3个任务后，分别调用shutdown()和shutdownNow()关闭线程池，然后观察日志输出 ExecutorService executor = new ThreadPoolExecutor(5, 10, 10, TimeUnit.SECONDS, new LinkedBlockingDeque&lt;&gt;(5), new ThreadPoolExecutor.AbortPolicy());for (int i=0; i&lt;5; i++) &#123; Task task = new Task(); try &#123; executor.submit(task); &#125; catch (Exception e) &#123; LOGGER.error(e.getMessage()); &#125; Thread.sleep(100); if (i == 2) &#123; executorService.shutdown(); //executorService.shutdownNow(); &#125;&#125;LOGGER.info("done"); shutdown结果 17:34:01:347 INFO [pool-2-thread-1] run17:34:01:456 INFO [pool-2-thread-2] run17:34:01:566 INFO [pool-2-thread-3] run17:34:01:675 ERROR [main] Task rejected from ThreadPoolExecutor@36b4cef0[Shutting down]17:34:01:784 ERROR [main] Task rejected from ThreadPoolExecutor@36b4cef0[Shutting down]17:34:01:894 INFO [main] done17:34:02:347 INFO [pool-2-thread-1] done17:34:02:456 INFO [pool-2-thread-2] done17:34:02:566 INFO [pool-2-thread-3] done 从日志中可以看出，shutdown()后再submit()任务时抛出了异常，提示正在“Shutting down”；正确启动了三个任务，这三个任务在shutdown()后继续执行，正常结束。 shutdownNow结果 17:37:00:663 INFO [pool-2-thread-1] run17:37:00:756 INFO [pool-2-thread-2] run17:37:00:866 INFO [pool-2-thread-3] run17:37:00:975 ERROR [pool-2-thread-3] sleep interrupted17:37:00:975 ERROR [pool-2-thread-2] sleep interrupted17:37:00:975 ERROR [pool-2-thread-1] sleep interrupted17:37:00:975 INFO [pool-2-thread-3] done17:37:00:975 INFO [pool-2-thread-1] done17:37:00:975 INFO [pool-2-thread-2] done17:37:00:975 ERROR [main] Task rejected from ThreadPoolExecutor@36b4cef0[Terminated]17:37:01:085 ERROR [main] Task rejected from ThreadPoolExecutor@36b4cef0[Terminated]17:37:01:194 INFO [main] done 首先，shutdownNow()后再submit()的任务也抛出了异常，但提示信息有差别；另外，虽然也输出了”donw”的信息，但是正确启动的三个任务并没有正常结束（时间不到1秒），日志显示中断了sleep操作，导致线程提前结束。 综上，我们应该使用shutdown()来关闭线程池。这也是web服务可以优雅关闭的基础，当tomcat接收到网络请求后，会提交给线程池进行处理，如果我们通知tomcat关闭服务，那么只需调用线程池的shutdown()方法，这样新的网络请求就没有线程来处理了（需要处理异常），而且正在工作的线程可以正常完成自己的工作后结束。 ThreadPoolExecutor平时我们最常用到的是ThreadPoolExecutor类，它实现了ExecutorService接口。 package java.util.concurrent;public class ThreadPoolExecutor extends AbstractExecutorService &#123;&#125; package java.util.concurrent;public abstract class AbstractExecutorService implements ExecutorService &#123;&#125; 我们知道，Executor接口含有execute()方法，ExecutorService接口含有submit()方法，这样就有两种方法提交任务给线程池ThreadPoolExecutor执行。当我们不关注任务的返回结果时，可以通过execute()方法提交任务；当我们需要拿到任务的返回结果时，就必须通过submit()方法提交任务了。 除了get()方法可以得到返回结果以外，Future类还提供了其他方法来查询线程的执行状态，所以当我们关系任务的执行状态时，也应该使用submit()，个人建议可以都使用submit()来提交任务。另外，submit()最后还是执行的execute()，只不过执行前做了Future的准备工作。 public abstract class AbstractExecutorService implements ExecutorService &#123; public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) &#123; if (task == null) throw new NullPointerException(); RunnableFuture&lt;T&gt; ftask = newTaskFor(task); execute(ftask); return ftask; &#125; protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Callable&lt;T&gt; callable) &#123; return new FutureTask&lt;T&gt;(callable); &#125; &#125;public interface RunnableFuture&lt;V&gt; extends Runnable, Future&lt;V&gt; &#123; void run();&#125;public class FutureTask&lt;V&gt; implements RunnableFuture&lt;V&gt; &#123; public V get() throws InterruptedException, ExecutionException &#123; int s = state; if (s &lt;= COMPLETING) s = awaitDone(false, 0L); return report(s); &#125; &#125; TODO: Future原理]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>并发</tag>
        <tag>线程</tag>
        <tag>线程池</tag>
        <tag>任务调度</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程基础篇(1) 线程]]></title>
    <url>%2F2018%2F04%2F24%2Fthread-basic-thread%2F</url>
    <content type="text"><![CDATA[进程与线程提到线程大家就会想起进程，先来看看进程和线程的联系和区别。 什么是进程？ 通俗的讲，进程就是操作系统中运行的程序，当你的程序代码被操作系统加载到内存中运行的时候，它就成为了一个进程。以Linux系统为例，每个进程有自己的进程号(pid)，有独立的地址空间。每个进程有独立的地址空间意味着，一个进程不能够访问到另外一个进程的内存空间，内存地址空间是进程私有的。 进程间可以通过共享内存通信，共享内存空间并非进程私有的。 什么是线程? 线程理解起来比进程要抽象一些。线程与操作系统的任务调用相关，可以简单认为线程是操作系统任务调度的基本单位。现在的大部分操作系统采用的都是时间片和抢占式的任务调用机制，当多个任务共享CPU资源时，一个任务执行一段时间后被挂起(这个任务执行的这段时间就称为时间片)，切换到另外一个任务开始执行。通常任务调度的单位不是进程，而是线程，也就是说，线程是进程可以独立交给CPU执行的一个任务。线程有自己的栈和程序计数器。 这样，一个进程可以包含多个线程，每个线程作为一个任务交给操作系统调用。实际上，Java进程至少要包含一个线程，如果我们没有显示的创建线程，main()方法是在[main]线程中执行的。对于Java进程来说，每个线程有自己的栈空间，多个线程共享进程的堆空间。 JAVA线程创建线程通常有三种创建线程的方法：继承Thread类，实现Runnable接口和实现Callable接口。继承Thread类和实现Runnable接口都需要实现run()方法，实现Callable接口需要实现call()方法。以下为示例代码。 可以认为run()方法和main()方法类似，都是程序的入口。main()是Java进程主线程的程序入口，run()是一个新线程的程序入口。 Thread类 public class Task extends Thread &#123; @Override public void run() &#123; int sum = 0; for (int i=1; i&lt;=10; i++) &#123; sum += i; &#125; System.out.println("sum=" + sum); &#125;&#125; Runnable接口 注意，run()方法没有返回值，且不抛出异常 public class Task implements Runnable &#123; @Override public void run() &#123; int sum = 0; for (int i=1; i&lt;=10; i++) &#123; sum += i; &#125; System.out.println("sum=" + sum); &#125;&#125; Callable接口 注意，call()方法有返回值，而且可以抛出异常，这是Callable和Runnable最重要的区别 public class Task implements Callable&lt;Integer&gt; &#123; @Override public Integer call() throws Exception &#123; int sum = 0; for (int i=1; i&lt;=10; i++) &#123; sum += i; &#125; return sum; &#125;&#125; 启动线程继承Thread类的，直接调用start()方法就可以启动线程； public class Task extends Thread &#123;&#125;Task task = new Task();task.start(); 实现Runnable接口的，需要new Thread(task).start()启动线程； public class Task implements Runnable &#123;&#125;Task task = new Task();new Thread(task).start(); 注意：虽然方法名字叫做start()，但是这个方法并不能保证线程立即开始执行，start()操作只能保证线程进入runnable状态，具体什么时间能够被执行由操作系统控制。 也可以使用匿名内部类 Thread task = new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println("run"); &#125;&#125;);task.start(); 实现Callable接口的，需要new Thread(new FutureTask&lt;&gt;(task)).start()启动线程。 FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;&gt;(new Callable&lt;Integer&gt;() &#123; @Override public Integer call() throws Exception &#123; int sum = 0; for (int i=1; i&lt;=10; i++) &#123; sum += i; &#125; return sum; &#125;&#125;);new Thread(futureTask).start(); 注意：虽然直接调用run()方法看上去也可以有正确的结果，但是这是在当前线程内执行的，没有启动一个新的线程来执行。 实战中，我们通常不会直接使用new Thread().start()来启动线程，而是交给Executor去处理。因为每次new一个新的线程显然是低效的，放到线程池里执行是更好的选择。同样原因，实际编码中很少使用继承Thread类的办法来创建线程，因为Executor只接收接口。并且由于Java不支持多重继承，实现Runnable接口是比继承Thread类更好的设计。 等待线程有时我们需要在主线程中等待新线程执行完成，并获得执行结果，这个时候可以使用join()方法。调用join()方法后当前线程被挂起，直到join线程执行完成后再被唤醒。 public class ThreadJoin &#123; private final static Logger LOGGER = LoggerFactory.getLogger(ThreadJoin.class); public static void main(String[] args) throws Exception &#123; Task1 task1 = new Task1(); Thread thread1 = new Thread(task1); thread1.start(); thread1.join(); LOGGER.info("done"); &#125; public static class Task1 implements Runnable &#123; @Override public void run() &#123; int sum = 0; for (int i=1; i&lt;=10; i++) &#123; sum += i; &#125; LOGGER.info("sum=" + sum); &#125; &#125;&#125; 上面为示例代码，执行结果如下 13:40:15:944 INFO [Thread-1] sum=5513:40:15:944 INFO [main] done 如果去掉thread1.join()，那么执行结果如下 13:41:21:690 INFO [main] done13:41:21:690 INFO [Thread-1] sum=55 通常，Runnable接口需要调用join()方法，Callable接口就不需要了，直接调用FutureTask的get()方法就可以获取执行结果。FutureTask.get()方法起到和join()相同的效果，当前线程阻塞，直到子线程执行完成并返回执行结果，以下为示例。 public class ThreadJoin &#123; private final static Logger LOGGER = LoggerFactory.getLogger(ThreadJoin.class); public static void main(String[] args) throws Exception &#123; Task2 task2 = new Task2(); FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;&gt;(task2); Thread thread2 = new Thread(futureTask); thread2.start(); LOGGER.info(futureTask.get().toString()); &#125; public static class Task2 implements Callable&lt;Integer&gt; &#123; @Override public Integer call() throws Exception &#123; int sum = 0; for (int i=1; i&lt;=10; i++) &#123; sum += i; &#125; return sum; &#125; &#125;&#125; 以上代码开启一个子线程计算1到10的和，执行结果如下；FutureTask.get()方法是同步等待的，等待Task的call()方法执行完成才返回。 13:47:02:066 INFO [main] 55 中断线程有时我们可能由于某种原因中断子线程任务的执行，在其执行完成前退出。通常用两种方法：一是自己设置标志位，根据标志位退出；二是调用interrupt()方法。 标志位 先来看使用标志位退出的代码 public class ThreadStop &#123; private final static Logger LOGGER = LoggerFactory.getLogger(ThreadStop.class); public static void main(String[] args) &#123; Task task = new Task(); Thread thread = new Thread(task); thread.start(); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; task.stop(); &#125; public static class Task implements Runnable &#123; private boolean stop = false; @Override public void run() &#123; while (!stop) &#123; LOGGER.info("run"); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; LOGGER.info("stop"); &#125; public void stop() &#123; stop = true; &#125; &#125;&#125; 执行结果如下，在执行过程中不断判断标志位stop，当发现stop被置为true后退出。 14:02:51:483 INFO [Thread-1] run14:02:52:483 INFO [Thread-1] run14:02:53:496 INFO [Thread-1] stop 中断 通过标志位退出线程有自己的局限性，如果线程调用了阻塞方法（例如wait()），并且无法被唤醒，那么就无法通过判断标志位来实现退出了。这种情况下，我们可以调用Thread的interrupt()方法中断阻塞方法，实现退出。 public class ThreadStop &#123; private final static Logger LOGGER = LoggerFactory.getLogger(ThreadStop.class); public static void main(String[] args) &#123; Task task = new Task(); Thread thread = new Thread(task); thread.start(); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; thread.interrupt(); &#125; public static class Task implements Runnable &#123; @Override public void run() &#123; while (true) &#123; if (Thread.currentThread().isInterrupted()) &#123; LOGGER.info("interrupted"); break; &#125; LOGGER.info("run"); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; LOGGER.error("interrupted in sleep"); break; &#125; &#125; &#125; &#125;&#125; 执行结果如下，thread.interrupt()方法中断了阻塞的Thread.sleep()方法，抛出InterruptedException异常；线程捕获异常后退出，注意这里需要手动退出。 14:11:43:574 INFO [Thread-1] run14:11:44:580 ERROR [Thread-1] interrupted in sleep14:11:44:580 INFO [Thread-1] interrupted 线程属性线程名通过线程名可以区分每一个线程，输出线程名到日志中对于分析多线程问题是非常有帮助的。 设置线程名称 thread.setName("threadName"); 读取当前线程的线程名称，注意使用Thread.currentThread()获取当前线程对象的方法 Thread.currentThread().getName(); 当然，如果线程实现的方式是从Thread类继承，那么当然可以调用this.getName()方法获取到线程名；但是，更多的场景是实现了Runnable或者Callable接口，这个时候this指向的就不是Thread对象了，所以使用Thread.currentThread().getName();获取线程名是更通用的方法。 扩展一下，通过Thread的类的静态方法可以得到当前所有active的线程，有兴趣可以执行一下下面的代码看看输出结果 public class ThreadBasic &#123; public static void main(String[] args) &#123; int threadCount = Thread.activeCount(); Thread [] threadList = new Thread[threadCount]; // 枚举所有活动的线程 int n = Thread.enumerate(threadList); for (int i=0; i&lt;n; i++) &#123; System.out.println(threadList[i].getName()); &#125; &#125;&#125; 按照我们的理解，输出的应该是”main”，因为这时候只有一个主线程。通过命令行运行，或者在IDEA中debug确实是预期的结果。但是如果在IDEA中run的话，会多一个”Monitor Ctrl-Break”线程。 线程优先级创建一个线程以后，可以设置线程的优先级。线程优先级是从1到10的数字，数字越大优先级越高，常用的优先级有MIN_PRIORITY、MAX_PRIORITY和NORMAL_PRIORITY三种，其中默认值为NORMAL_PRIORITY public final static int MIN_PRIORITY = 1;public final static int NORM_PRIORITY = 5;public final static int MAX_PRIORITY = 10; 以下为示例代码 MyThread thread = new MyThread();thread.setPriority(Thread.MAX_PRIORITY);thread.start(); 理论上优先级高的线程先被执行，但不一定绝对这样，具体情况要看操作系统如何调度。总体上，优先级高的线程有更多的机会被执行。 守护线程通过设置daemon属性可以将一个线程设置为守护线程，默认值为false，也就是非守护线程，通常称为用户线程。 thread.setDaemon(true); 守护线程和用户线程的差别不大，主要区别在于主线程结束时：如果主线程结束时，已经没有活动的用户线程，那么守护线程自动退出。平时我们很少会用到守护线程，GC线程是典型的守护线程，当其他线程都已经退出了，只保留一个GC线程也没有什么意义了。 public class ThreadDaemon &#123; public static void main(String[] args) &#123; DaemonThread daemonThread = new DaemonThread(); daemonThread.start(); &#125; public static class DaemonThread extends Thread &#123; public DaemonThread() &#123; this.setName("DaemonThread"); this.setDaemon(true); &#125; @Override public void run() &#123; while (true) &#123; System.out.println(this.getName() + " - I'm alive."); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;&#125; 在上面的例子中，如果setDaemon(false)，当主线程结束退出后子线程会一直运行，输出“I’m alive.”；如果setDaemon(true)，当主线程结束退出后由于已经没有其他用户线程，子线程自动退出了。运行一下，你会发现甚至连一个“I’m alive.”都没有输出出来，这是因为调用完daemonThread.start()主线程就退出了，这个时候daemonThread还没有抢到时间片，等daemonThread抢到时间片的时候发现已经没有非守护线程了，就直接退出了。]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>并发</tag>
        <tag>线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RocketMQ(3) 开发]]></title>
    <url>%2F2018%2F04%2F23%2Frocketmq-dev%2F</url>
    <content type="text"><![CDATA[编码配置在pom.xml引入rocketmq-client模块和rocketmq-common模块，选择合适的版本，这里我用的是3.1.4版本 https://github.com/apache/rocketmq-externals/tree/master/rocketmq-spring-boot-starter &lt;!-- rocket mq --&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.rocketmq&lt;/groupId&gt; &lt;artifactId&gt;rocketmq-client&lt;/artifactId&gt; &lt;version&gt;3.1.4&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.rocketmq&lt;/groupId&gt; &lt;artifactId&gt;rocketmq-common&lt;/artifactId&gt; &lt;version&gt;3.1.4&lt;/version&gt;&lt;/dependency&gt; 发送消息 发送消息比较简单，首先创建消息生产者，指定组；然后启动生产者； 当需要发消息时调用生产者的send()方法即可，消息对象需要指定主题、标签、主键、消息体内容等信息；通过send()方法的返回值同步判断是否发送成功； 发送失败将会自动重试，重试次数和超时时间可以在创建生产者时进行设置。 package cn.waterlu.test.rocketmq; import com.alibaba.rocketmq.client.producer.DefaultMQProducer;import com.alibaba.rocketmq.client.producer.SendResult;import com.alibaba.rocketmq.common.message.Message;public class TestRocketMq &#123; @Test public void testProducer() &#123; // 生产者组的名称 String groupName = "group_producer"; // NameServer地址 String nameServer = "10.10.10.163:9876"; // 如果发送失败，重试次数 int retryTimes = 3; // 发送超时时间（毫秒） long timeout = 10000; // 创建Producer并进行配置 DefaultMQProducer producer = new DefaultMQProducer(groupName); producer.setNamesrvAddr(nameServer); producer.setRetryTimesWhenSendFailed(retryTimes); producer.setSendMsgTimeout(timeout); // 启动Producer，可复用 producer.start(); // 创建消息 // topic String 消息主题 // tag String 消息标签（可空） // key String 消息主键 // body byte [] 消息体 Message message = new Message(topic, tag, key, body); // 发送消息 SendResult sendResult = producer.send(message); SendStatus status = sendResult.getSendStatus(); // 判断发送是否成果 if (status.equals(SendStatus.SEND_OK)) &#123; logger.info("发送成功"); &#125; else &#123; logger.warn("发送失败"); &#125; &#125;&#125; 接收消息 消费消息与生产消息类似，需要首先创建消费者，设置参数，最后启动消费者消费消息； 消费者和生产者一样需要指定NamerServer地址和消费组名称； 消费者启动前需要指定订阅的主题和标签，进行消息过滤； 消费者需要注册收到消息后的处理方法； 消费者分为Pull和Push两种模式，其本质都是拉去消息； Push模式把轮询过程封装了，对用户来说，感觉消息是被推送过来的； Pull模式用户需要自己拉起消息。 package cn.waterlu.test.rocketmq;import com.alibaba.rocketmq.client.consumer.DefaultMQPushConsumer;import com.alibaba.rocketmq.client.consumer.ConsumeFromWhere;public class TestRocketMq &#123; @Test public void testConsumer() &#123; // 消费组的名字 String consumerGroupName = "group_consumer"; // NameServer地址 String nameServer = "10.10.10.163:9876"; // 创建消费者 DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(consumerGroupName); consumer.setNamesrvAddr(nameServer); // 三个选项，区别在新订阅组第一次启动时的行为不同，以后都是继续上一次的位置进行消费 // CONSUME_FROM_LAST_OFFSET 新订阅组第一次启动从队列的最后开始消费 // CONSUME_FROM_FIRST_OFFSET 新订阅组第一次启动从队列的头开始消费 // CONSUME_FROM_TIMESTAMP 新订阅组第一次启动从指定时间点开始消费 consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_LAST_OFFSET); // 指定订阅的主题和标签，主题和标签都是String // 多个标签中间通过"||"分隔，例如："pay||order||clear" consumer.subscribe(topic, tags); // 注册消息处理的回掉方法 consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; list, ConsumeConcurrentlyContext consumeConcurrentlyContext) &#123; // consumeMessageBatchMaxSize默认值为1，所以List里面只有一个元素 MessageExt messageExt = list.get(0); // 主题 String topic = messageExt.getTopic(); // 标签 String tag = messageExt.getTags(); // 消息ID，RocketMQ自动生成 String messageID = messageExt.getMsgId(); // 消息主键，业务自己指定 String messageKey = messageExt.getKeys(); // 消息内容 byte[] messageBody = messageExt.getBody(); // CONSUME_SUCCESS 表示消息消费成功 // RECONSUME_LATER 表示消息消费失败，RocketMQ过一段时间后会重新投递消息 return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; //return ConsumeConcurrentlyStatus.RECONSUME_LATER; &#125; &#125; // 启动消费组 consumer.start(); &#125;&#125;]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>mq</tag>
        <tag>rocketmq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RocketMQ(2) 部署与维护]]></title>
    <url>%2F2018%2F04%2F22%2Frocketmq-deploy%2F</url>
    <content type="text"><![CDATA[由于用到了事务消息功能，所以我使用的是3.1.4版本，这是一个非常老的版本，3.x最新稳定版本是3.5.8。 RocketMQ从4.0版本开始在Apache孵化，目前最新版本是4.2.0，不包含事务消息功能，预计4.3.0版本可能会增加事务消息功能。 RocketMQ官方版本V3.0.4~3.1.4基于文件系统实现了事务消息，已开源；V3.1.5~4.2.0基于数据库实现事务消息，未开源。 部署如下图所示，RocketMQ由NameServer和BrokerServer组成，其中NameServer用做注册中心，Broker启动后注册到NameServer，Producer和Consumer与NameServer通信，获取Broker的地址；Producer发送消息给Broker，Broker完成消息存储，并负责将消息投递给Consumer。 RocketMQ 3.1.4这里 有V3.1.4版本的源码，是作为V3.1.9版本的一个分支存在的。 打包 环境准备：安装rocketmq前需要先安装jdk，git和maven 编译打包 $ cd rocketmq-3.1.4$ mvn -Dmaven.test.skip=true clean package install assembly:assembly -U$ cd ./target/alibaba-rocketmq-3.1.4/alibaba-rocketmq$ ls -ldrwxrwxr-x 2 lu lu 4096 Jan 20 16:34 benchmarkdrwxrwxr-x 2 lu lu 4096 Jan 20 16:34 bindrwxrwxr-x 5 lu lu 4096 Jan 20 16:34 confdrwxrwxr-x 2 lu lu 4096 Jan 20 16:34 lib-rw-rw-r-- 1 lu lu 10275 Jan 20 16:34 LICENSE.txtdrwxrwxr-x 2 lu lu 4096 Jan 20 16:34 test 启动由于默认启动参数配置的内存比较大，所以开发环境我们一般会先调整一下内存参数，具体为修改apache-rocketmq/bin目录下的runserver.sh和runbroker.sh脚本，修改其中的JAVA_OPT，将Xms/Xmx/Xmn等内存参数调整到合适大小 首先，启动NameServer，NameServer默认服务端口为9876 $ cd target/alibaba-rocketmq-3.1.4/alibaba-rocketmq$ nohup sh bin/mqnamesrv &gt; /dev/null 2&gt;&amp;1 &amp; 然后，启动BrokerServer，其中-n参数为NameServer的地址和端口，Broker的服务端口为10911和10912，10911供Producer和Consumer通信使用，10912供Broker集群通信使用 $ cd target/alibaba-rocketmq-3.1.4/alibaba-rocketmq$ nohup sh bin/mqbroker -n localhost:9876 &gt; /dev/null 2&gt;&amp;1 &amp; Broker启动时将自己的地址和端口注册到NameServer上，但存在多网卡时，Broker有可能获取不到正确的IP地址，最后导致Producer和Consumer连接不到Broker上，出现类似下面这样的错误。 connect to &lt;172.17.0.1:10911&gt; failed 这种情况下，我们需要在Broker启动时指定IP地址，具体方法为配置一个启动参数文件broker.properties，内容如下（可以从conf/2m-noslave/broker-a.properties复制并修改）： brokerClusterName=DefaultClusterbrokerName=broker-abrokerId=0brokerIP1=192.168.75.159deleteWhen=04fileReservedTime=48brokerRole=ASYNC_MASTERflushDiskType=ASYNC_FLUSH 启动脚本如下，重点在于-c参数指定了配置文件，如果需要我们可以在broker.properties中做更多个性化配置 $ nohup sh bin/mqbroker -n localhost:9876 -c conf/broker.properties &gt; /dev/null 2&gt;&amp;1 &amp; 关闭关闭Broker服务 $ sh bin/mqshutdown broker 关闭NameServer服务 $ sh bin/mqshutdown namesrv 正常先关闭broker，再关闭namesrv RocketMQ 4.2.0这里 有详细指南，按照文档一步一步操作即可，和3.1.4版本区别不大。 首先，下载源代码 rocketmq-all-4.2.0-source-release.zip ，解压并编译打包 $ mvn -Prelease-all -DskipTests clean install -U$ cd /rocketmq-all-4.2.0/distribution/target/apache-rocketmq 注意：下面启动使用/distribution/target/apache-rocketmq/bin，而不是/distribution/bin 3.1.4版本叫alibaba-rocketmq，4.2.0版本叫apache-rocketmq 启动和关闭方法与3.1.4一样： 修改runserver.sh和runbroker.sh调整内存大小，修改/conf/broker.conf增加IP地址。 $ cd rocketmq-all-4.2.0/distribution/target/apache-rocketmq$ nohup sh bin/mqnamesrv &gt; /dev/null 2&gt;&amp;1 &amp;$ nohup sh bin/mqbroker -n localhost:9876 -c conf/broker.conf &gt;/dev/null 2&gt;&amp;1 &amp;$ sh bin/mqshutdown broker$ sh bin/mqshutdown namesrv 查看端口，如果9876/10909/10911/10912端口都已启动监听，说明启动成功。 $ netstat -tnpltcp6 0 0 :::10909 :::* LISTEN 112040/java tcp6 0 0 :::10911 :::* LISTEN 112040/java tcp6 0 0 :::10912 :::* LISTEN 112040/java tcp6 0 0 :::9876 :::* LISTEN 111889/java 10909：VIP端口 10911：Broker主要端口，发送和拉取消息都使用它 10912：集群通信端口 命令管理RocketMQ提供了bin/mqadmin命令行对消息队列进行管理，以下4.2.0版本为例，3.1.4版本基本一样。 -n设置NameServer地址和端口(从NameServer上获取Broker地址和端口) 查看主题列表，RocketMQ安装完成后自带了如下主题 $ bin/mqadmin topicList -n localhost:9876BenchmarkTestOFFSET_MOVED_EVENTbroker-aTBW102SELF_TEST_TOPICDefaultCluster 创建主题 参数 说明 -n NameServer地址和端口 -b Broker地址和端口(Topic创建在这个Broker上面) -c Cluster名称（Broker和Cluster二选一） -t Topic主题名称 -r 读队列数(默认8个) -w 写队列数(默认8个) 创建主题test $ bin/mqadmin updateTopic -n localhost:9876 -b localhost:10911 -t test -r 4 -w 4create topic to localhost:10911 success.TopicConfig [topicName=test, readQueueNums=4, writeQueueNums=4, perm=RW-, topicFilterType=SINGLE_TAG]$ bin/mqadmin topicList -n localhost:9876TBW102test 查看Topic信息 $ bin/mqadmin topicStatus -n localhost:9876 -t test 查看集群信息 $ bin/mqadmin clusterList -n localhost:9876#Cluster Name #Broker Name #BID #Addr #VersionDefaultCluster ubuntu 0 172.17.0.1:10911 V3_1_4 根据MessageID查询消息 $ bin/mqadmin queryMsgById -n localhost:9876 -i 根据消息Key查询消息 $ bin/mqadmin queryMsgByKey -n localhost:9876 -t test -k 控制台虽然通过命令行可以查看RocketMQ状态，但是使用起来很不方便。幸运的是RocketMQ提供了页面控制台，我们可以通过UI来操作，方便多了。 rocketmq-console项目封装了mqadmin指令，提供了web页面来展示rocketmq信息，所以通常我们都使用rocketmq-console来查看RocketMQ状态。 rocketmq-console属于rocketmq-externals 项目的一部分。 首先，获取源码 $ git clone https://github.com/apache/rocketmq-externals 然后，打包部署(rocketmq-console是spring boot项目) $ cd rocketmq-externals/rocketmq-console$ mvn clean package -Dmaven.test.skip=true 修改配置文件 rocketmq-console/src/main/resources/application.properties #if this value is empty,use env value rocketmq.config.namesrvAddr NAMESRV_ADDR | now, you can set it in ops page.default localhost:9876rocketmq.config.namesrvAddr=localhost:9876#if you use rocketmq version &lt; 3.5.8, rocketmq.config.isVIPChannel should be false.default truerocketmq.config.isVIPChannel=true 最后启动 $ nohup java -jar target/rocketmq-console-ng-1.0.0.jar &gt; /dev/null 2&gt;&amp;1 &amp; v3.1.4版本是没有提供控制台工具的，rocketmq-externals(包括rocketmq-console)是为rocketmq v4.0.0以上版本服务的。所以，理论上rocketmq-console和v3.1.4是不兼容的。不过，mqadmin的指令协议没有变化，所以基本使用是可以的。当然，升级到4.0.0以上版本就更没有问题了。 集群https://blog.csdn.net/xiaojie19871116/article/details/46982907 https://blog.csdn.net/jayjjb/article/details/70140667]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>mq</tag>
        <tag>rocketmq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RocketMQ(1) 介绍]]></title>
    <url>%2F2018%2F04%2F21%2Frocketmq-intro%2F</url>
    <content type="text"><![CDATA[简介RocketMQ是阿里巴巴开源的一款高性能、高吞吐率的分布式消息中间件。产品基于高可用分布式集群技术，提供消息发布订阅、消息轨迹查询、定时（延时）消息、资源统计、监控报警等功能，是阿里巴巴双11使用的核心产品。2016年阿里巴巴正式宣布将 RocketMQ 捐赠给 Apache 软件基金会。 RocketMQ的前身叫MetaQ，MetaQ从3.0版本开始更名为RocketMQ。 官网地址http://rocketmq.apache.org/， 目前最新版本为4.2.0。 基本概念以下内容来自阿里云对MQ项目的介绍。 应用场景 异步解耦，基于发布订阅模型，对分布式应用进行异步解耦，增加应用的水平扩展能力； 削峰填谷，大促等流量洪流突然来袭时，MQ 可以缓冲突发流量，避免下游订阅系统因突发流量崩溃； 日志监控，作为重要日志的监控通信管道，将应用日志监控对系统性能影响降到最低； 消息推送，为社交应用和物联网应用提供点对点推送，一对多广播式推送的能力； 金融报文，发送金融报文，实现金融准实时的报文传输，可靠安全； 电信信令，将电信信令封装成消息，传递到各个控制终端，实现准实时控制和信息传递。 上面是官方介绍，我来根据自己的理解解读一下： 异步解耦：对于实时性要求不高的操作，例如：用户注册送金币，将送金币的逻辑从用户注册的主逻辑中拆分处理，通过消息触发，这就是异步解耦。异步解耦可以提升主逻辑的响应速度，辅助逻辑稍有延迟。 削峰填谷：相当于排队，例如：突发大量用户抢购行为，不直接处理认购操作，而是将请求发送到MQ队列，再通过消费者消费掉。相当于把并发操作通过队列变成了串行操作，当然这里的串行不是一个一个执行，如果有M个消费者，类似于M个一起执行。或者说，就像银行柜员的操作，不管来多少人办理业务，就开3个窗口，大家拿号依次办理；不用队列就相当于人多了就得多雇柜员（峰），人少了就把柜员裁了（谷）。 日志监控：我理解就是ELK，一般用Kafka更多。 消息推送：我没用过，我感觉这个应该不实用，因为RocketMQ的consumer无论push还是pull模式都是主动拉去的。RabbitMQ做消息推送更合适，它提供了很多插件，比较方便。 金融报文和电信信令：没用过，不太理解，类似于事件驱动？ 消息类型定时消息和延时消息 定时消息：Producer 将消息发送到 MQ 服务端，但并不期望这条消息立马投递，而是推迟到在当前时间点之后的某一个时间投递到 Consumer 进行消费。 延时消息：Producer 将消息发送到 MQ 服务端，但并不期望这条消息立马投递，而是延迟一定时间后才投递到 Consumer 进行消费。 定时/延时消息适用于如下一些场景： 消息生产和消费有时间窗口要求：比如在电商交易中超时未支付关闭订单的场景，在订单创建时会发送一条 MQ 延时消息，这条消息将会在30分钟以后投递给消费者，消费者收到此消息后需要判断对应的订单是否已完成支付。如支付未完成，则关闭订单，如已完成支付则忽略。 通过消息触发一些定时任务：比如在某一固定时间点向用户发送提醒消息。 我们在提现操作中使用了延时消息，因为提现操作不能立即返回真正是否成功，需要后续主动查询提现结果。我们在提现请求成功后，过一段时间开始启动查询操作，用的就是延时消息。 顺序消息顺序消息是MQ提供的一种按照顺序进行发布和消费的消息类型。顺序消息由两个部分组成：顺序发布和顺序消费。顺序消息类型分为两种：全局顺序和分区顺序。 全局顺序消息 MQ全局顺序消息适用于以下场景：性能要求不高，所有的消息严格按照 FIFO 原则进行消息发布和消费的场景。 分区顺序消息 MQ 分区顺序消息适用于如下场景：性能要求高，以 sharding key 作为分区字段，在同一个区块中严格的按照 FIFO 原则进行消息发布和消费的场景。 举例说明：【例一】用户注册需要发送发验证码，以用户 ID 作为 sharding key， 那么同一个用户发送的消息都会按照先后顺序来发布和订阅。【例二】电商的订单创建，以订单 ID 作为 sharding key，那么同一个订单相关的创建订单消息、订单支付消息、订单退款消息、订单物流消息都会按照先后顺序来发布和订阅。 阿里巴巴集团内部电商系统均使用此种分区顺序消息，既保证业务的顺序，同时又能保证业务的高性能。 事务消息 事务消息：MQ 提供类似XA的分布事务功能，通过 MQ 事务消息能达到分布式事务的最终一致； 半消息：暂不能投递的消息，发送方已经将消息成功发送到了 MQ 服务端，但是服务端未收到生产者对该消息的二次确认，此时该消息被标记成“暂不能投递”状态，处于该种状态下的消息即半消息； 消息回查：由于网络闪断、生产者应用重启等原因，导致某条事务消息的二次确认丢失，MQ 服务端通过扫描发现某条消息长期处于“半消息”时，需要主动向消息生产者询问该消息的最终状态（Commit 或是 Rollback），该过程即消息回查。 如上图所示，事务消息的处理过程如下： 发送方向 MQ 服务端发送消息； MQ Server 将消息持久化成功之后，向发送方 ACK 确认消息已经发送成功，此时消息为半消息； 发送方开始执行本地事务逻辑； 发送方根据本地事务执行结果向 MQ Server 提交二次确认（Commit 或是 Rollback），MQ Server 收到 Commit 状态则将半消息标记为可投递，订阅方最终将收到该消息；MQ Server 收到 Rollback 状态则删除半消息，订阅方将不会接受该消息； 在断网或者是应用重启的特殊情况下，上述步骤4提交的二次确认最终未到达 MQ Server，经过固定时间后 MQ Server 将对该消息发起消息回查； 发送方收到消息回查后，需要检查对应消息的本地事务执行的最终结果； 发送方根据检查得到的本地事务的最终状态再次提交二次确认，MQ Server 仍按照步骤4对半消息进行操作。 事务消息完成本地事务后，可在返回如下三种状态： TransactionStatus.CommitTransaction 提交事务，允许订阅方消费该消息； TransactionStatus.RollbackTransaction 回滚事务，消息将被丢弃不允许消费； TransactionStatus.Unknow 暂时无法判断状态，期待固定时间以后 MQ Server 向发送方进行消息回查。 事务消息是我们选择RocketMQ作为消息队列的最重要原因，如果没有事务消息Kafka用的更多。 集群消费和广播消费集群消费 消息只被消费者组中的一个实例消费； 这是我们最常见的模式，集群消费可以很方便的横向拓展，提升处理能力。 广播消费 消费者组中的每一个实例都可以消费到消息。 消息过滤Tag，即消息标签、消息类型，用来区分某个 MQ 的 Topic 下的消息分类。MQ 允许消费者按照 Tag 对消息进行过滤，确保消费者最终只消费到他关心的消息类型。 以下图电商交易场景为例，从客户下单到收到商品这一过程会生产一系列消息，比如订单创建消息（order）、支付消息（pay）、物流消息（logistics）。这些消息会发送到 Topic 为 Trade_Topic 的队列中，被各个不同的系统所接收，比如支付系统、物流系统、交易成功率分析系统、实时计算系统等。其中，物流系统只需接收物流类型的消息（logistics），而实时计算系统需要接收所有和交易相关（order、pay、logistics）的消息。 说明：针对消息归类，您可以选择创建多个 Topic， 或者在同一个 Topic 下创建多个 Tag。但通常情况下，不同的 Topic 之间的消息没有必然的联系，而 Tag 则用来区分同一个 Topic 下相互关联的消息，比如全集和子集的关系，流程先后的关系。 消息重试 当消息不能送达时，MQ 默认允许每条消息最多重试 16 次，每次重试的间隔越来越长，从10 秒、30秒、1分钟，直到2小时； 如果消息重试 16 次后仍然失败，消息将不再投递； 也就是说，某条消息在一直消费失败的前提下，将会在接下来的 4 小时 46 分钟之内进行 16 次重试，超过这个时间范围消息将不再重试投递。 消费幂等发送时消息重复（消息 Message ID 不同） MQ Producer 发送消息场景下，消息已成功发送到服务端并完成持久化，此时网络闪断或者客户端宕机导致服务端应答给客户端失败。如果此时 MQ Producer 意识到消息发送失败并尝试再次发送消息，MQ 消费者后续会收到两条内容相同但是 Message ID 不同的消息。 投递时消息重复（消息 Message ID 相同） MQ Consumer 消费消息场景下，消息已投递到消费者并完成业务处理，当客户端给服务端反馈应答的时候网络闪断。为了保证消息至少被消费一次，MQ 服务端将在网络恢复后再次尝试投递之前已被处理过的消息，MQ 消费者后续会收到两条内容相同并且 Message ID 也相同的消息。 真正安全的幂等处理，不建议以 Message ID 作为处理依据。最好的方式是以业务唯一标识作为幂等处理的关键依据，而业务的唯一标识可以通过消息 Key 进行设置。 RocketMQ没有提供消息幂等实现，需要自己做。即使提供了，安全起见，我认为自己也要做幂等判断，尤其是敏感型消息。 消息发送方式 可靠同步发送，同步发送是指消息发送方发出数据后，会在收到接收方发回响应之后才发下一个数据包的通讯方式； 可靠异步发送，异步发送是指发送方发出数据后，不等接收方发回响应，接着发送下个数据包的通讯方式。MQ 的异步发送，需要用户实现异步发送回调接口（SendCallback），在执行消息的异步发送时，应用不需要等待服务器响应即可直接返回，通过回调接口接收服务器响应，并对服务器的响应结果进行处理； 单向（Oneway）发送，单向（Oneway）发送特点为只负责发送消息，不等待服务器回应且没有回调函数触发，即只发送请求不等待应答。此方式发送消息的过程耗时非常短，一般在微秒级别。]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>mq</tag>
        <tag>rocketmq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Hexo搭建自己的博客]]></title>
    <url>%2F2018%2F04%2F21%2Fhexo-intro%2F</url>
    <content type="text"><![CDATA[概述搭建个性化的博客网站，我们需要用到hexo和github。其中Hexo是一个快速、简洁且高效的博客框架，使用hexo我们可以快速编写、生成、预览和部署博客文章，最终我们的博客文章发布到github上。Github为个人博客提供了免费的发布平台，通过域名yourname.github.io可以访问到同名的github项目。 准备工作安装Git可以去这里下载Git的windows版本，正确安装后可以在Shell中查看到git版本 $ git --versiongit version 2.7.2.windows.1 安装Node.js去nodejs官网下载最新版本(node-v8.11.1-x64.msi)并安装，正确安装后可以查看到版本 $ node -vv8.11.1 安装Hexonode.js中带了包管理工具npm，后面的模块都可以通过npm来安装，-g表示全局安装 官网上的文档中只安装了hexo-cli，试了一下有问题，这里还是安装hexo(里面包含hexo-cli) $ npm install -g hexo$ hexo versionhexo: 3.7.1hexo-cli: 1.1.0 创建Github项目 注册github账户，并做好配置 创建以用户开头，以github.io结尾的项目，例如：我的用户名是waterlu，那么创建的项目名称为 waterlu.github.io 项目创建成功后访问 https://waterlu.github.io/ ，后面就是部署页面的操作了。 Hexo基本操作Hexo是静态化的博客框架，使用markdown格式编写文章，然后通过hexo generate指令生成静态的HTML页面，最后通过hexo depoly指令将HTML页面上传到GitHub上。 所有hexo操作都需要在hexo init的目录执行，也就是含有_config.yml和source的目录，在其他目录执行hexo generate等操作是无效的。 初始化 hexo init 指令创建新的博客 $ cd /c/lu/blog$ hexo init$ ls -l-rw-r--r-- 1 _config.ymldrwxr-xr-x 1 node_modules/-rw-r--r-- 1 package.jsondrwxr-xr-x 1 scaffolds/drwxr-xr-x 1 source/drwxr-xr-x 1 themes/ 配置_config.yml，配置个性化信息和部署地址 title: Waterlu&apos;s Blogdescription: 个人技术博客author: Water Ludeploy: type: git repo: git@github.com:waterlu/waterlu.github.io.git branch: master 生成网站$ hexo generate 本地预览 启动web服务 访问http://localhost:4000 $ hexo server 部署到Github 第一次部署前安装hexo-deployer-git 以后通过deploy部署（事先需要在_config.yml中配置github相关信息） $ npm install hexo-deployer-git --save$ hexo deploy 个性化定制主题我使用的主题是Maupassant，感觉比较简洁。 注意：npm install的两个模块不是全局安装的，每次hexo init创建新项目后都得执行(npm install -g才是全局安装)。 $ git clone https://github.com/tufu9441/maupassant-hexo.git themes/maupassant$ npm install hexo-renderer-pug --save$ npm install hexo-renderer-sass --save 修改根目录下的_config.yml，设置theme为maupassant theme: maupassant 创建about页面 $ hexo new page about 修改themes/maupassant目录下的_config.yml，去掉RSS页面 menu: - page: home directory: . icon: fa-home - page: archive directory: archives/ icon: fa-archive - page: about directory: about/ icon: fa-user # - page: rss # directory: atom.xml # icon: fa-rss 评论功能 TODO 站内搜索 安装hexo-generator-search $ npm install hexo-generator-search --save$ npm install hexo-generator-searchdb --save 修改根目录下的_config.yml，增加如下配置 search: path: search.xml field: post format: html limit: 10000 修改themes\maupassant下的_config.yml，打开self_search google_search: false ## Use Google search, true/false.baidu_search: false ## Use Baidu search, true/false.swiftype: ## Your swiftype_key, e.g. m7b11ZrsT8Me7gzApciTtinysou: ## Your tinysou_key, e.g. 4ac092ad8d749fdc6293self_search: true ## Use a jQuery-based local search engine, true/false. 访问统计 修改themes\maupassant下的_config.yml，打开不蒜子busuanzi: true ## If you want to use Busuanzi page views please set the value to true. 流程图和序列图Hexo默认不支持markdown的flow图和sequence图，需要安装插件 进入项目根目录安装插件 $ npm install --save hexo-filter-flowchart$ npm install --save hexo-filter-sequence 修改项目的_config.yml，增加配置 flowchart: # raphael: # optional, the source url of raphael.js # flowchart: # optional, the source url of flowchart.js options: # options used for `drawSVG`sequence: # webfont: # optional, the source url of webfontloader.js # snap: # optional, the source url of snap.svg.js # underscore: # optional, the source url of underscore.js # sequence: # optional, the source url of sequence-diagram.js # css: # optional, the url for css, such as hand drawn theme options: theme: css_class: Hexo日常操作写文章 [layout]默认为post，指的是文章的布局类型，在_config.yml中可以配置 如果[layout]=post，那么新文章将生成到source/_posts目录下 $ hexo new [layout] &lt;title&gt; 文章开头”—“之间的部分称为Front-matter，主要包括以下信息 参数 描述 layout 文章布局 title 文章标题 date 文章发布时间 updated 文章更新时间 tags 标签 categories 分类 发表文章$ hexo new post [title]$ hexo clean$ hexo generate$ hexo server$ hexo deploy 常见问题解析错误 当title.md文章中出现无法解析的markdown语法时，报错Template render error 因为需要把markdown转成html，所以必须解析正确 $ hexo gINFO Start processingFATAL Something's wrong. Maybe you can find the solution here: http://hexo.io/docs/troubleshooting.htmlTemplate render error: expected variable end]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>github</tag>
      </tags>
  </entry>
</search>
