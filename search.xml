<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[HashMap源码分析]]></title>
    <url>%2F2018%2F05%2F08%2Fjava-basic-hashmap%2F</url>
    <content type="text"><![CDATA[HashMap解析基本用法分析HashMap源码前，先看看怎么使用。 Map接口首先看一下Map接口，Map接口里面定义了常用的方法。 public interface Map&lt;K,V&gt; &#123; // 大小 int size(); // 是否包含key boolean containsKey(Object key); // 读 V get(Object key); // 写 V put(K key, V value); // 删除 V remove(Object key); // 返回所有key Set&lt;K&gt; keySet(); // 返回所有value Collection&lt;V&gt; values(); // 遍历 Set&lt;Map.Entry&lt;K, V&gt;&gt; entrySet(); // 内部类 interface Entry&lt;K,V&gt; &#123; // 遍历读取key K getKey(); // 遍历读取value V getValue(); &#125;&#125; Map遍历方法一，我认为最正统的写法 for(Map.Entry&lt;String, Object&gt; entry : map.entrySet()) &#123; String key = entry.getKey(); Object value = entry.getValue();&#125; 方法二，意思和上面的方法是一样的，看上去绕一些 Iterator it = map.entrySet().iterator();while (it.hasNext()) &#123; Map.Entry&lt;String, Object&gt; entry = (Map.Entry&lt;String, Object&gt;)it.next(); String key = entry.getKey(); Object value = entry.getValue();&#125; 方法三，先拿到key，再通过get()方法读取value，绕了一圈 for(String key : map.keySet()) &#123; Object value = map.get(key);&#125; 方法四，只能获取value，得不到key for(Object value : map.values()) &#123;&#125; 源码分析基于JDK1.8的源码进行分析。 数据结构先上源码 package java.util;public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt; &#123; // 默认容量16 static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16 // 默认加载因子3/4,当容量到达12时开始扩容 static final float DEFAULT_LOAD_FACTOR = 0.75f; transient int modCount; // 大小 transient int size; // 下一个需要扩容的阈值 int threshold; // 数据存储，是一个数组，数组的大小就是容量 transient Node&lt;K,V&gt;[] table; // 加载因子,默认3/4 final float loadFactor; // 红黑树转换 static final int TREEIFY_THRESHOLD = 8;&#125; table：数组，保存数据； threshold：阈值，当数组中的数据达到这个值以后，对数组进行扩容； HashMap采用了链地址法来解决冲突问题，简单说，就是数组加链表的结合。在每个数组元素上都一个链表结构，当数据被Hash后，得到数组下标，把数据放在对应下标元素的链表上。 如上图所示，HashMap的基本存储结构是一个数组，根据key的hash值取模可以定位到数组的某一个元素，如果有多个key定位到同一个元素，通过链表连接(p1-&gt;next=p2)。读取数据时先根据key的hash值定位到元素，然后再遍历链表查找。如果分布不均匀导致某一个链表很长，就会降低效率。或者说，HashMap的容量间接决定了它的效率：当容量大时，每个key容易落到不同的数组位置上，一次就能读取到；当容量小时，多个key容易发生哈希碰撞，就需要遍历链表，效率自然就降低了。当然，大容量就占用了空间，还是典型的空间换时间。 static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next; Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125;&#125; Node是真实存储键值对的数据结构：Node是HashMap的内部类，实现了Map.Entry接口，其中hash是key的原始哈希值，当扩容时需要用它重新计算数组下标位置，next指向下一个元素，默认为null，也就是说Node可以组成一个链表。 PUT流程先看一下我总结的PUT操作流程，再看源码 GET操作流程 PUT源码第一步，计算哈希值 public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125; static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; 首先需要计算key的哈希值 调用hashCode()方法获取对象的int型哈希值； &gt;&gt;&gt; 16 意思是无符号右移16位； ^ 意思是异或操作，两位相同为0，不同为1（异或可以实现两数交换）； 高16位与0做异或，高位值不变；低16位与高16位做异或，混合高16位和低16位信息（称为扰动）； 为什么要异或（或者为什么要扰动）？ 我们知道hashCode()方法的返回值是int，范围是很大的，如果直接以这个返回值作为数组下标显然内存是不够用的，所以会采用类似取模的办法； 我们知道默认的数组大小是16，那么就是对16取模，相当于hashCode()返回值中只有最后4位起了作用，其他位都没有起到作用；即使int数比较分散，但是最后四位可能碰撞严重；换句话说，精心设计了哈希算法，计算出了分散的32位整数，但实际上只有最后4位起作用，效果可能还不好； 所以在JDK1.7中是这么做的，进行了多次扰动；（让高位与最后四位进行异或运算） h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4); JDK1.8认为四次扰动不必要，一次就够了，所以拿高16位与低16位进行异或计算； 我理解：如果数组大小为16，那么实际上是[0,4)和[16,20)位上的值决定了数组下标位置，其他位的计算是没有用的；当然，数组大小是可以扩容的，如果扩容到64，那么起作用的就是[0,6)和[16,22)位了。 上图充分说明了哈希和取模的过程。 如果容量选择31这样的质数，hash冲突就会小很多，但是取模计算和扩容就复杂了。HashMap才用16这样的非质数容量，必然导致冲突比31这样的质数多，中庸之道就是通过异或运算进行扰动综合。 第二步，取模 if ((p = tab[i = (n - 1) &amp; hash]) == null) &#123; tab[i] = newNode(hash, key, value, null);&#125; i = (n - 1) &amp; hash，假设n=16，那么&amp;15就相当于&amp;00001111，也就是保留hash的后四位的意思。 p=tab[i]就是根据key的hash值最终计算出来数组下标位置。 如果这个位置上的元素是空的，直接创建Node对象放到这里即可。 当n为2的x次方时，&amp; (n-1)操作就起到了取模的作用，这就是为什么HashMap的容量总是2的x次方的原因。如果不是，那么%取模操作效率是很低的。 第三步，元素链表 if ((p = tab[i = (n - 1) &amp; hash]) == null) &#123; tab[i] = newNode(hash, key, value, null);&#125; else &#123; Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; // 如果当前元素hash值和key的hash值一样，直接返回e e = p; &#125; else if (p instanceof TreeNode) &#123; // 红黑树特殊处理 e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); &#125; else &#123; // 遍历链表 for (int binCount = 0; ; ++binCount) &#123; // 找到链表最后一个元素 if ((e = p.next) == null) &#123; // 新数据加入到链表末尾 p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st // 当元素个数达到8个时，转换为红黑树存储 treeifyBin(tab, hash); break; &#125; // 链表里某个元素hash值和key的hash值一样，直接返回e if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; // 如果元素已经存在（hash值存在），直接返回 if (e != null) &#123; // existing mapping for key V oldValue = e.value; // 返回的一定是旧值，是否替换为新值需要onlyIfAbsent=false，默认false替换 if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125;&#125; 定位到数组位置后，遍历链表查找key是否存在，如果key存在直接返回value，不存在把新元素加入到链表末尾。 如果key存在，返回值一定是旧的value，至于是否使用新value替换旧value可以设置，默认是替换的。 put()方法是有返回值的，如果返回null不是说put()操作失败了，说明key不存在；如果返回值不为空，说明key存在，没有写入新数据，直接返回了存在的value。 key可以是null的，定位到数组0位置，但key是唯一的，所以只能有一个null的key。 比较key的时候是根据hash值进行比较的，所以使用String做key感觉比使用Object做key更放心一些。 第四步，扩容 // 简化代码final Node&lt;K,V&gt;[] resize() &#123; // 旧数据 Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; // 扩容一倍 newCap = oldCap &lt;&lt; 1; &#125; else &#123; // 使用默认值初始化 newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr == 0) &#123; // 重新计算阈值=容量*因子 newThr = (float)newCap * loadFactor; &#125; threshold = newThr; // 扩容后的新数据 Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; // 数据迁移 if (oldTab != null) &#123; // 遍历旧数据 for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) &#123; // 只有一个元素，直接复制，根据key的原始哈希值重新计算数组下标 newTab[e.hash &amp; (newCap - 1)] = e; &#125; else if (e instanceof TreeNode) &#123; // 红黑树特殊处理 ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); &#125; else &#123; // preserve order // 链表情况 Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; // 遍历链表 next = e.next; if ((e.hash &amp; oldCap) == 0) &#123; // 位置不变 if (loTail == null) loHead = e; else // 顺序不变 loTail.next = e; loTail = e; &#125; else &#123; // 位置+oldCap if (hiTail == null) hiHead = e; else // 顺序不变 hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; // 低位链表 newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; // 高位链表 newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab; &#125; 扩容优化这部分代码是JDK1.8优化过的，需要解释一下。 Map&lt;String, Integer&gt; map = new HashMap(4);map.put("A", 90);map.put("E", 85);map.put("I", 80);map.put("M", 70); 我们通过上面的实际例子来说明。为了简单，初始化容量为4，默认因子0.75，阈值为3。当put(“M”)时容量超过阈值，启动扩容操作。 扩容从4增加到8，我们看一下数组下标计算的变化： hash(A)=01000001, hash(E)=01000101, hash(I)=01001001, hash(M)=01001101 容量为4的情况，截取最后两位，AEIM的最后两位都是01，对应的数组 01000001&amp;0011=01, 01000101&amp;0011=01, 01001001&amp;0011=01, 01001101&amp;0011=01 容量为8的情况，截取最后三位，AI的最后三位是001，EM的最后三位是101 01000001&amp;0111=001, 01000101&amp;0111=101, 01001001&amp;0111=001, 01001101&amp;0111=101 以上，可以看出：扩容以后，由于只是多截取了一位，所以数组下标或者不变，或者增加4（旧容量）。 因此，扩容时就不需要重新计算链表中每一个元素的新位置，要么不变，要么增加旧容量，所以才有了上面的算法：设立两个指针，loHead指向位置不变的，hiHead指向增加4的。了解了原理以后，我们再来看代码。 if ((e.hash &amp; oldCap) == 0) 注意，oldCap第一位是1，其他位都是0，所以&amp; oldCap相当于判断hash值中新增加的哪一位的值。例如：继续上面的例子oldCap=100，hash(A)=01000001，01000001&amp;100=0，其实就是在判断hash(A)的倒数第三位的值。我们知道原来只截取后两位，倒数第三位就新增的截取位。如果这一位等于0，数组下标就不变，如果这一位等于1，数组下标就加4。 所以，当(e.hash &amp; oldCap) == 0时，将元素添加到loHead链表中，== 1时，将元素添加到hiHead链表中。 这样，遍历完旧数据后，就根据倒数第三位的值把就数据分为两份：loHead和hiHead，最后把它们放到数组中。 newTab[j] = loHead;newTab[j + oldCap] = hiHead; 红黑树注意到put()代码里面有对TreeNode的特殊处理，这是JDK1.8新增加的红黑树。当链表很长时，遍历链表必然降低效率，所以当链表中元素个数超过8个时，不再使用链表，而改为使用红黑树存储，这样在get()时可以提高效率。 死循环HashMap是线程不安全的，下面来具体分析一下多线程put()操作引起的get()方法死循环问题。 这个问题也可以描述成HashMap引发的CPU 100%问题，查看堆栈程序都Hang在HashMap.get()这个方法上，因为get()出现死循环，所以一直占用CPU。 首先，死循环的原因一定是链表出了问题，出现了循环链表。如果多线程并发put()操作出了问题，导致出现了循环列表，那么当get()查询到这个链表时，就会进入死循环出不来。 原理清楚了，下面看看具体的实例。 注意，例子是基于JDK1.7的，因为JDK1.7及以下才有这个问题。 void resize(int newCapacity) &#123; Entry[] oldTable = table; int oldCapacity = oldTable.length; // 创建一个新的Hash表 Entry[] newTable = new Entry[newCapacity]; // 数据迁移 transfer(newTable); table = newTable;&#125;void transfer(Entry[] newTable) &#123; int newCapacity = newTable.length; // 遍历旧数据 for (Entry&lt;K,V&gt; e : table) &#123; while(null != e) &#123; Entry&lt;K,V&gt; next = e.next; // 重新计算新容量下的数组下标 int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; &#125; &#125;&#125; JDK1.8保持了链表的顺序不变，所以不会出现循环链表的情况了，也就不会出现死循环了。虽然不会出现死循环了，但是还有可能出现其他问题，所以仍然不是线程安全的，在多线程环境下不建议使用。 首先来看单线程的情况： 旧数据容量2，key的哈希值是3、7、5，都存储在table[1]，新数据容量4，table[1]=5，table[3]=3、7； 数据迁移算法：遍历全部旧数据，将其从旧链表中摘下，插入到新链表的最前面。 接下来考虑多线程的情况，假设两个线程A和B，A线程执行到next = e.next; 时被挂起，B线程一直执行完成，那么当前状态如下：粉色表示线程A、天蓝色表示线程B。 接下来线程A继续执行，当前e=3,next=7。将3插入到table[3]开头，然后，e=next=7。 下一个循环，e=7，next=3，将7插入到table[3]开头，然后e=next=3。 下一个循环，e=3，next=null，将3插入到table[3]开头，e=next=null。循环结束，最后的结果如下，形成了循环链表。 此时，如果线程A调用get(11)就会进入无限循环，问题重现。 Debug默认debug时是不能调试JDK源码的，具体体现就是单步执行和加断点失败，为了调试JDK源码需要修改配置： Setting –&gt; Build,Execution,Deployment –&gt; Debugger –&gt; Stepping 把Do not step into the classes中的java.* 和javax.* 取消勾选 参考JDK 源码中 HashMap 的 hash 方法原理是什么？ Java集合：HashMap源码剖析 Java8系列之重新认识HashMap 疫苗：Java HashMap的死循环 漫画：什么是HashMap？ 漫画：高并发下的HashMap s=>start: 开始 hash=>operation: 计算key的哈希值 table=>condition: 数组是否为空? init=>operation: 初始化数组(16) mod=>operation: 去模计算数组下标 node=>condition: 下标位置元素是否为空? newNode=>operation: 创建Node对象放入数组 nodeLink=>operation: 遍历链表到末尾 newLinkNode=>operation: 创建Node对象加入链表末尾 addSize=>operation: 增加容量 size=>condition: 容量达到阈值？ resize=>operation: 扩容 e=>end: 结束 s->hash->table table(yes)->init->mod table(no)->mod mod->node node(yes)->newNode node(no)->nodeLink->newLinkNode newNode->addSize newLinkNode->addSize addSize->size size(yes)->resize size(no)->e resize->e{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12,"theme":"simple"} var code = document.getElementById("flowchart-0-code").value; var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-0-options").value)); var diagram = flowchart.parse(code); diagram.drawSVG("flowchart-0", options);]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>Hashmap</tag>
        <tag>哈希冲突</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库原理]]></title>
    <url>%2F2018%2F05%2F07%2Fdatabase-theory%2F</url>
    <content type="text"><![CDATA[数据库原理基础知识时间复杂度时间频度用以描述一个算法处理一定量数据需要花多长时间。这里的时间不是常规意义上的时分秒，那依赖于硬件环境，没有意义；这里的时间指的是运算次数，运算次数的多少决定了时间多少的相对值，运算次数多的相对执行时间就长。 数据量不同，运算次数就不同，所以比较绝对运算次数也是没有意义的；实际上比较的是当数据量增加时，运算次数增加的趋势，这就是时间复杂度；好的算法不会随着数据量的增加和翻倍增加运算次数。 下图列出了常见的时间复杂度，展示了当数据量增加时，运算次数增加的趋势。 从低到高解释一下上述算法时间复杂度，以需要处理2000条数据为例： O(1)：只需要执行一次运算； O(log(n))：需要执行7次运算； O(n)：需要执行2000次运算； O(n*log(n))：需要执行14,000次运算； O(n^2)：需要执行4,000,000次运算； O(n!)：溢出了。 以查找为例，查找不同数据的情况所需的运算次数是不一样的；当我们讨论一个算法的时间复杂度时，都以平均情况为例进行讨论。 常见排序和查找方法的时间复杂度 算法 平均时间复杂度 最坏时间复杂度 冒泡排序 O(n^2) O(n^2) 快速排序 O(n^2) O(n*log(n)) 二叉树排序 O(n^2) O(n*log(n)) 堆排序 O(n*log(n)) O(n*log(n)) 顺序查找 O(n) 二分查找 O(log(n)) 二叉排序树查找 O(log(n)) 哈希表法 O(1) 合并排序排序树二叉查找树是带有特殊属性的二叉树，每个节点的关键字必须： 比保存在左子树的任何键值都要大 比保存在右子树的任何键值都要小 B+树哈希表数据库数据库是由多种互相交互的组件构成的。 客户端管理器客户端管理器是处理客户端通信的。 查询管理器事务管理器一个ACID事务是一个工作单元，它要保证4个属性： 原子性（Atomicity）: 事务『要么全部完成，要么全部取消』，即使它持续运行10个小时。如果事务崩溃，状态回到事务之前（事务回滚）。 隔离性（Isolation）: 如果2个事务 A 和 B 同时运行，事务 A 和 B 最终的结果是相同的，不管 A 是结束于 B 之前/之后/运行期间。 持久性（Durability）: 一旦事务提交（也就是成功执行）,不管发生什么（崩溃或者出错），数据要保存在数据库中。 一致性（Consistency）: 只有合法的数据（依照关系约束和函数约束）能写入数据库，一致性与原子性和隔离性有关。 经典的例子是从账户A到账户B的汇款。假设有2个事务： 事务1（T1）从账户A取出100美元给账户B 事务2（T2）从账户A取出50美元给账户B 我们回来看看ACID属性： 原子性确保不管 T1 期间发生什么（服务器崩溃、网络中断…），你不能出现账户A 取走了100美元但没有给账户B 的现象（这就是数据不一致状态）。 隔离性确保如果 T1 和 T2 同时发生，最终A将减少150美元，B将得到150美元，而不是其他结果，比如因为 T2 部分抹除了 T1 的行为，A减少150美元而B只得到50美元（这也是不一致状态）。 持久性确保如果 T1 刚刚提交，数据库就发生崩溃，T1 不会消失得无影无踪。 一致性确保钱不会在系统内生成或灭失。 原子性和一致性太像了？ SQL一般定义4个隔离级别： 串行化(Serializable，SQLite默认模式）：最高级别的隔离。两个同时发生的事务100%隔离，每个事务有自己的『世界』。 可重复读（Repeatable read，MySQL默认模式）：每个事务有自己的『世界』，除了一种情况。如果一个事务成功执行并且添加了新数据，这些数据对其他正在执行的事务是可见的。但是如果事务成功修改了一条数据，修改结果对正在运行的事务不可见。所以，事务之间只是在新数据方面突破了隔离，对已存在的数据仍旧隔离。举个例子，如果事务A运行”SELECT count(1) from TABLE_X” ，然后事务B在 TABLE_X 加入一条新数据并提交，当事务A再运行一次 count(1)结果不会是一样的。这叫幻读（phantom read）。 读取已提交（Read committed，Oracle、PostgreSQL、SQL Server默认模式）：可重复读+新的隔离突破。如果事务A读取了数据D，然后数据D被事务B修改（或删除）并提交，事务A再次读取数据D时数据的变化（或删除）是可见的。这叫不可重复读（non-repeatable read）。 读取未提交（Read uncommitted）：最低级别的隔离，是读取已提交+新的隔离突破。如果事务A读取了数据D，然后数据D被事务B修改（但并未提交，事务B仍在运行中），事务A再次读取数据D时，数据修改是可见的。如果事务B回滚，那么事务A第二次读取的数据D是无意义的，因为那是事务B所做的从未发生的修改（已经回滚了嘛）。这叫脏读（dirty read）。 TODO 结合事务 参考 如果有人问你数据库的原理，叫他看这篇文章]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从短地址说起]]></title>
    <url>%2F2018%2F05%2F07%2Fweb-short-url%2F</url>
    <content type="text"><![CDATA[短地址短地址（也叫Short URL）就是为了让一个很长的网站链接缩短为一个短的链接，短地址最初的出现是因为微博内有字数限制，现在短地址的应用领域越来越广泛。 小型业务中，我们通常使用免费的第三方服务来实现短地址转换。如果需要自己实现，该怎么做呢，本文给出方案和思考。单纯就短地址服务来说，的确不需要自己来实现，但仔细思考一下其实现原理和细节，对于我们理解哈希、分片等概念都有帮助。 需求业务上有发营销短信的需求，短信内容中带有APP下载地址。由于短信字数有限制（100个左右），很可能一个链接地址长度就超过了总字数限制，所以要使用短地址。 例如：下面为客户端1.5.1安卓版本的下载地址，仅链接地址就超过了100个字符。 http://imtt.dd.qq.com/16891/EB45FB72BADD5F2C0EBF02C906AAFCD6.apk?fsname=com.zjinv.kingold_1.5.1_15.apk&amp;csr=1bbd 进一步，还可以根据短地址生成二维码。 托管实现实际工作中，我们可以通过短地址服务平台来实现。这些平台提供了将长地址转换为短地址的功能。 新浪: http://sina.lt/ sina.lt/t.cn/ 百度: http://dwz.cn/ dwz.cn 例如：通过新浪提供的服务，我们把一篇博客的长地址转换为短地址，然后使用即可，新浪帮我们完成页面跳转。 长地址：https://my.oschina.net/didispace/blog/1807876 短地址：http://t.cn/Rukpf81 自己实现以上是通过第三方服务实现短链接，下面来看看如何自己实现。 哈希首先，容易想到调用String类的hashCode()方法，将一个字符串转换为一个int值，然后再将10进制的int值转换为16进制字符串就实现了短地址。下面为例子代码： public class HashExample &#123; public static void main(String[] args) &#123; String url = "https://my.oschina.net/didispace/blog/1807876"; int hashCode = url.hashCode(); String code = String.format("%x", hashCode); System.out.println("http://t.cn/" + code); &#125;&#125; 输出如下 http://t.cn/70fcf5cf 我们已经实现了长地址到短地址的映射（当然，还需要存储起来供查询）。但是，这种做法是有问题的。因为有可能产生冲突，也就是说两个不一样的url地址，计算出来的hash值一样，导致它们的短地址一样。 我们把两个对象生成的hash值一样的情况成为哈希冲突，哈希冲突需要做专门的处理，请参考HashMap的做法。 hashCode()下面我们先来看看hashCode()方法是如何实现的。 通常意义上，hashCode()是Object类的方法，返回的是对象在JVM堆上的内存地址，不同对象的堆内存地址不同，hash值就不同。也就是说，在一个JVM内我们能够保证不同对象的hashCode()不同，但是不同JVM之间就不能保证了。 public class Object &#123; public native int hashCode(); &#125; 但是，String类重载了Object类的hashCode()方法，没有使用内存地址，自定义了自己的实现，代码如下： public final class String&#123; public int hashCode() &#123; int h = hash; if (h == 0 &amp;&amp; value.length &gt; 0) &#123; char val[] = value; for (int i = 0; i &lt; value.length; i++) &#123; h = 31 * h + val[i]; &#125; hash = h; &#125; return h; &#125;&#125; 算法如下，从第一个字符开始，第i字符转换为int，然后乘以31的n-i次方，然后加和，计算哈希值。 hashCode=s[0]*31^(n-1)+s[1]*31(n-2)+s[2]*31^(n-3)+......+31*s[n-1]+s[n] ASCII码表如下，这里可以查看到每个字符对应的int值 字符 10进制 16进制 字符 10进制 16进制 A 65 0x41 a 97 0x61 B 66 0x42 b 98 0x62 Z 90 0x5A z 122 0x7A 0 48 0x30 . 46 0x2E 1 49 0x31 / 47 0x2F 9 57 0x39 : 58 0x3A 字符串”ab”的hashCode 97*31+98=3105 字符串”ABC”的hashCode 65*31*31+66*31+67=64578 这种算法有可能出现两个字符串的哈希值一样的情况，例如：”hierarch”和”crinolines”的哈希值一样，”buzzards” 和 “righto”和哈希值也相同。 为什么是31为什么乘以31的n次方，不是2，不是32，不是101呢？ 31是一个不大不小的质数，是作为 hashCode 乘子的优选质数之一。另外一些相近的质数，比如37、41、43等等，也都是不错的选择。选择质数作为因子是数学理论，可以保证： 冲突率尽量低； 分布率尽量广，计算出来的hash值分散广泛，自然冲突就少，本质和冲突率低是一样的。 31可以被 JVM 优化，方便计算，31 * i = (i &lt;&lt; 5) - i。 一定不能选取2的整数幂，例如：2，4，16，32，64等，因为乘以2的整数幂，相当于左移；左移时丢弃高位，地位补零，相当于丢失了信息，特别容易发生冲突。 自增既然哈希可能有冲突，不能使用，那么我们来看看另外一种思路，使用数据库自增ID的方法。 建一张表，主键是bigint自增ID，内容是长地址即可。短地址只需要将10进制bigint转换成62进制即可。 为什么62进制？A-Z(26)+a-z(26)+0-9(10)=62。 每收到一个地址转换请求，就往数据库表里面增加一条记录，建立对应关系。访问时将62进制短地址转换为ID就可以根据主键快速查询到长地址。 使用这个方法，每收到一个请求就往数据库中添加一条新的记录，长地址是可以重复的。多个短地址都指向同一个长地址，操作不会出错，但是占用的多余的存款空间。 改进下面看看如何改进，保证每个长地址对应唯一的短地址： 方案一：首先，最容易想到：每次插入前先查询一次数据库表，如果长地址存在，直接返回主键，如果长地址不存再添加；当数据库量大时，这么操作效率太低，首先排除。 方案二：再进一步，查询数据库太慢，我们可以把长地址和短地址的对应关系冗余存储到redis中，插入数据库前先查询redis；这种方法减小了数据库压力，但是redis中使用hash表存储所有对应关系，占用空间也很大； 方案三：继续优化，既然redis的问题是占用空间太大，那么我们是否可以不保存所有的对应关系，只保留最近的对应关系；使用LRU算法可以在保证一定命中率的前提下减少存储空间占用。（可以这么做的前提是我们认为有些地址热度较高，经常会被引用到）。 前面都只考虑了单机的情况，如果并发量巨大，一台数据库服务器处理不过来，那么就需要继续优化了： 方案一：数据库分片，例如：分4个db，每个起始值+1（1，2，3，4），步长4。 方案二：使用snowflake等分布式ID生成器生成ID。 重定向最后，还有一个页面重定向的问题，我们来看看操作过程： 用户访问短地址http://t.cn/Rukpf81 t.cn服务器收到请求，将Rukpf81 转换为主键3038198013989 查询到长地址https://my.oschina.net/didispace/blog/1807876 t.cn服务器返回HTTP 302，在HTTP的Location中设置长地址 浏览器重定向请求到长地址 注意：HTTP 301和302重定向的区别： 301永久重定向，SEO用新页面替换旧页面 302临时重定向，SEO认为是新旧是两个页面 进制转换62进制转10进制的源码： 也可以设置因子factor=1，从最后一位开始计算，每次factor = factor*62； 代码算法参考了String类的hashCode()实现，因为每次都有value 62，所以第一位实际上做了n-1次 62操作，与乘以62的n-1次方结果是一样的。 public final char[] array = "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ" .toCharArray();private long _62_to_10(String code) &#123; long value = 0; for (int i=0; i&lt;code.length(); i++) &#123; value = value * 62 + _62_2_10(code.charAt(i)); &#125; return value;&#125;private int _62_2_10(char c) &#123; for (int i=0; i&lt;array.length; i++) &#123; if (c == array[i]) &#123; return i; &#125; &#125; return 0;&#125; 计算结果 Rukpf81=3038198013989 10进制转62进制的源码： 每一次计算出来的余数是当前最低位的值，商用于下一次计算； 最后做字符串反转。 static String _10_to_62(long value) &#123; StringBuffer buffer = new StringBuffer(); while(value &gt; 0) &#123; int v = (int)(value % 62); buffer.append(array[v]); value = value / 62; &#125; return buffer.reverse().toString();&#125; 注意：int v = (int)(value % 62); 不能写成int v = (int)value % 62; ，精度截断后计算结果就错了。]]></content>
      <categories>
        <category>WEB</category>
      </categories>
      <tags>
        <tag>WEB</tag>
        <tag>短地址</tag>
        <tag>哈希</tag>
        <tag>hashCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL索引]]></title>
    <url>%2F2018%2F05%2F04%2Fmysql-index%2F</url>
    <content type="text"><![CDATA[MySQL索引索引和事务是MySQL最重要的两个概念，而Innodb存储引擎的索引结构又是事务的基础，可谓重中之重。本文从二叉搜索树说起，直到B+树，详细解释MySQL索引的数据结构，试图从底层探究索引原理。 数据结构基础从查找说起，数据库查询就是查找的一种，不同的存储结构（数据结构）决定了查找的方法和效率。先从数据结构的角度看看为什么选用B树作为索引的数据结构。 二叉树二叉树：每个节点最多有两个子节点。 节点的度：一个节点拥有的子树的个数。 满二叉树：除叶子节点外，其他节点都有两个子节点。满二叉树的最大特点是每一层次的结点数都达到最大值。 完全二叉树：只有最底层不满，最底层从左侧开始没有空的。 二分查找树也叫二叉搜索树（BST树），首先是二叉树，其次每个节点上的值是有规律的： 左子树上所有结点的值均小于它的根结点的值； 右子树上所有结点的值均大于它的根结点的值。 查找的时候，从根节点开始比较，小于根的值就从左子树中递归查找，大于根的值就从右子树中递归查找。 添加节点也是一样，从根节点开始，递归找到合适的节点位置并添加。 删除节点麻烦一些，如果删除叶子节点比较简单，直接删除即可；如果删除非叶子节点，需要对数进行调整。 先序遍历二分查找树输出的结果就是排序结果。 下图为一颗二分查找树的例子。 AVL树高度平衡二叉树，也叫平衡二叉树，在AVL树中任何节点的两个子树的高度最大差为一，这里不展开。 红黑树前面提到的都是基础知识，在实战中使用的不多，常见的是由它们逐步引出的红黑树，JDK1.8中TreeMap和HashMap都用到了红黑树(Red Black Tree)。 从二叉树的发展来看，红黑树是一颗相对平衡的二叉树；二叉树–&gt;二叉搜索树–&gt;平衡搜索二叉树–&gt; 红黑树；红黑树具有如下特点： 节点要么是黑色，要么是红色； 根和叶子节点都是黑色的； 不能有连续两个红色的节点； 从任一节点到它所能到达得叶子节点的所有简单路径都包含相同数目的黑色节点。 下图为一颗红黑树的例子，本文重点为了引出B+树，红黑树不展开。 为什么要引入红黑树？ 二分查找树时间复杂度是O(log(n))，不是效率就已经够高了吗，直接使用不行吗？为什么还要发展到红黑树呢？因为二分查找树的运行时间取决于树的形状，树的高度越高，查询效率越低。试想最极端的情况，所有节点都只有右子树，那么查找最大的树需要遍历所有节点，相当于顺序查找。所以有了平衡的概念，越平衡的二分查找树效率越高。 想一下，二分查找树的高度就是最大的查询次数，所以树越高，效率越低。AVL树是高度平衡二叉树，红黑树是相对平衡二叉树，都是为了减小树的高度，提供查找效率。 以上可知，引入红黑树就是为了平衡。平衡的方法有三种：变色、左旋、右旋。 B树(B-tree)B通常认为是Balance的简称，B树不是二叉树。一棵m阶B树(balanced tree of order m)是一棵平衡的m路搜索树。一颗M阶B树是一颗平衡的M路搜索树，它或者是空树，或者满足下列条件： 根结点至少有两个孩子； 每个中间节点都包含k-1个元素和k个孩子，其中 M/2 &lt;= k &lt;= M；(向上取整) 每个叶子节点都包含k-1个元素，其中 M/2 &lt;= k &lt;= M；(向上取整) 每个节点中的元素从小到大升序排列；节点当中k-1个元素正好是k个孩子包含的元素的值域划分； 所有的叶子节点都在同一层。 B树在插入时可能需要调整节点进行自平衡，删除也是一样；添加和删除节点后，可能导致不满足B+树条件，这个时候就需要调整，这个调整的过程称为自平衡。 我认为，二分查找树可以看作2阶的B树：每个节点都只有1个键值，2个子节点，左边子节点键值小于父节点键值，右边子节点键值大于父节点键值。以此类推，3阶的情况如下：每个节点有1-2个键值，1个键值的情况同上；如果有2个键值，那么有3个子节点。第N个子节点的键值位于父节点[N-1,N]键值之间。 以5阶B树为例，每个节点最多有4个元素，5个孩子。假设元素值为 (10, 20, 30, 40)，那么5个子节点的元素值范围是c0 &lt;10，10 &lt; c1 &lt; 20，20 &lt; c2 &lt;30，30 &lt; c3 &lt; 40，c4 &gt; 40 ，也就是分布于左右。 为什么引入B树？ 我认为，B树是红黑树的升级版，更合适外部排序。换句话说，如果排序和查找都在内存中完成，那么红黑树就够用了，是很优秀的方案；如果排序和查找涉及到外部数据，也就是在磁盘上的数据，那么红黑树就不能满足要求了，所以引入了B树。B树在自平衡等很多算法上和红黑树是一样的，但是B树中一个节点可以保存更多的键值，一是减少了磁盘I/O，二是大大减小了树的高度。 B+树B树有很多变种，B+树就是其中一种，MySQL使用B+树(实际上是B*树)作为索引的数据结构。 B+树与B树最重要的区别： B树所有节点都保存数据，B+树只有叶子节点保存数据； B*树基于B+树继续优化，增加顺序指针。 每个叶子节点增加一个指向相邻叶子节点的指针；这样可以提高区间查询的效率，例如：where age &gt;= 30 and age &lt; 50； MySQL索引基础索引分为聚簇索引和非聚簇索引两种，聚簇索引是按照数据存放的物理位置为顺序的，而非聚簇索引就不一样了；聚簇索引能提高多行检索的速度，而非聚簇索引对于单行的检索很快。 索引类型 按照索引数据和源数据是否分开存储，索引分为聚簇索引和非聚簇索引两种。 聚簇索引：索引数据和源数据存储在一起，或者说源数据就是按照主键作为索引组织的，Innodb存储引擎使用聚簇索引。 非聚簇索引：索引数据和源数据分开存储，MyISAM存储引擎使用非聚簇索引，数据文件有三个：.frm 文件存储表结构，.MYD 文件存储表数据，.MYI 文件存储索引数据。 按照使用类型，索引可以分为普通索引、唯一索引、全文索引和复合索引 普通索引 CREATE INDEX index_name ON table_name(column(length));ALTER TABLE table_name ADD INDEX index_name ON (column(length));DROP INDEX index_name ON table_name; 唯一索引 与普通索引类似，不同的是索引列的值必须唯一，但允许有空值（注意和主键不同）。 CREATE UNIQUE INDEX indexName ON table_name(column(length));ALTER TABLE table_name ADD UNIQUE indexName ON (column(length)); 全文索引 FULLTEXT索引只适用于 MyISAM，一般不用。 复合索引 顾名思义，复合索引是由2个或者更多字段组合而成的索引。普通索引和唯一索引都是单字段的。 CREATE INDEX index_name ON table_name(column1(length1), column2(length2));ALTER TABLE table_name ADD INDEX index_name (column1(length1), column2(length2)); 注意，复合索引遵循最左前缀原则，上面的SQL实际上建立了column1和column1+column2两个索引。 最左前缀原则，就是从最左侧开始组合，如果创建了column1、column2、column3复合索引，那么实际上已经有了如下三个索引，无需在单独在column1上建索引，但是column2和column3是没有索引的： column1 column1+column2 column1+column2+column3 安装数据结构，索引可以分为BTREE索引和HASH索引 BTREE索引，就是使用B+/B*树存储索引，前面说过。 HASH索引， MySQL索引原理MySQL索引使用改进的B+树来实现。 为什么用B+树存储索引为什么不使用二分查找树来实现索引呢？二分查找树效率也很高啊，时间复杂度O(log(n))。 如果索引全部在内存中，那么使用二分查找树是没有问题的。但实际情况中，索引文件可能很大，不可能全部加载到内存中，这就意味着对索引的访问涉及到磁盘I/O。也就是说，虽然二分查找树算法的比较次数少，但是需要去和磁盘上的索引数据进行比较，访问太慢，虽然次数少，但是时间长。 简单分析一下磁盘I/O，磁盘由磁片和磁头组成，磁片旋转 那么，B+树难道就不需要访问磁盘I/O了，内存同样放不下啊。实际操作中，我们每次加载磁盘一页的数据到内存中，MySQL索引B+树的每一个节点就保存一页数据，可以一次加载到内存中。这样，虽然比较次数多了，但是磁盘I/O次数少了，整体还是高效的。 二分查找树（二叉搜索树）本质上是二叉树，当数据量比较大时，树的高度一定非常高。B+树是多路搜索树，当阶数比较大时，树的高度可以很低。如果索引数据需要从磁盘加载，那么树的高度就决定了磁盘I/O的次数，也就决定了执行速度。 以查找数据10为例，二分查找树需要4次比较和4次磁盘I/O； MyISAM实现MyISAM引擎使用B+Tree作为索引结构，叶节点的data域存放的是数据记录的地址。MyISAM的索引方式也叫做“非聚簇索引”。 在MyISAM中，主索引和辅助索引（Secondary key）在结构上没有任何区别，只是主索引要求key是唯一的，而辅助索引的key可以重复。 InnoDB实现虽然InnoDB也使用B+Tree作为索引结构，但具体实现方式却与MyISAM截然不同。 第一个重大区别是InnoDB的数据文件本身就是索引文件。从上文知道，MyISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址。而在InnoDB中，表数据文件本身就是按B+Tree组织的一个索引结构，这棵树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。 因为InnoDB的数据文件本身要按主键聚集，所以InnoDB要求表必须有主键（MyISAM可以没有），如果没有显式指定，则MySQL系统会自动选择一个可以唯一标识数据记录的列作为主键，如果不存在这种列，则MySQL自动为InnoDB表生成一个隐含字段作为主键，这个字段长度为6个字节，类型为长整形。所以，表必须要有主键。 第二个与MyISAM索引的不同是InnoDB的辅助索引data域存储相应记录主键的值而不是地址。换句话说，InnoDB的所有辅助索引都引用主键作为data域。聚集索引这种实现方式使得按主键的搜索十分高效，但是辅助索引搜索需要检索两遍索引：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录。 知道了InnoDB的索引实现后，就很容易明白为什么不建议使用过长的字段作为主键，因为所有辅助索引都引用主索引，过长的主索引会令辅助索引变得过大。 MySQL索引使用高效使用索引的首要条件是知道什么样的查询会使用到索引，这个问题和B+Tree中的“最左前缀原理”有关，下面通过例子说明最左前缀原理。 复合索引索引失效索引命中 &lt;，&lt;=，=，&gt;，&gt;=，BETWEEN，IN, like &#39;xx%&#39; 索引不能命中 &lt;&gt;，not in ，!=，like &#39;%xx&#39; 1.索引不存储null值 更准确的说，单列索引不存储null值，复合索引不存储全为null的值。索引不能存储Null，所以对这列采用is null条件时，因为索引上根本 没Null值，不能利用到索引，只能全表扫描。 为什么索引列不能存Null值？ 将索引列值进行建树，其中必然涉及到诸多的比较操作。Null值的特殊性就在于参与的运算大多取值为null。 这样的话，null值实际上是不能参与进建索引的过程。也就是说，null值不会像其他取值一样出现在索引树的叶子节点上。 2.不适合键值较少的列（重复数据较多的列） 假如索引列TYPE有5个键值，如果有1万条数据，那么 WHERE TYPE = 1将访问表中的2000个数据块。 再加上访问索引块，一共要访问大于200个的数据块。 如果全表扫描，假设10条数据一个数据块，那么只需访问1000个数据块，既然全表扫描访问的数据块 少一些，肯定就不会利用索引了。 3.前导模糊查询不能利用索引(like ‘%XX’或者like ‘%XX%’) 假如有这样一列code的值为’AAA’,’AAB’,’BAA’,’BAB’ ,如果where code like ‘%AB’条件，由于前面是 模糊的，所以不能利用索引的顺序，必须一个个去找，看是否满足条件。这样会导致全索引扫描或者全表扫 描。如果是这样的条件where code like ‘A % ‘，就可以查找CODE中A开头的CODE的位置，当碰到B开头的 数据时，就可以停止查找了，因为后面的数据一定不满足要求。这样就可以利用索引了。 4.索引失效的几种情况 1.如果条件中有or，即使其中有条件带索引也不会使用(这也是为什么尽量少用or的原因) 要想使用or，又想让索引生效，只能将or条件中的每个列都加上索引 2.对于多列索引，不是使用的第一部分，则不会使用索引 3.like查询以%开头 4.如果列类型是字符串，那一定要在条件中将数据使用引号引用起来,否则不使用索引 5.如果mysql估计使用全表扫描要比使用索引快,则不使用索引 5.MySQL主要提供2种方式的索引：B-Tree索引，Hash索引 B树索引具有范围查找和前缀查找的能力，对于有N节点的B树，检索一条记录的复杂度为O(LogN)。相当于二分查找。 哈希索引只能做等于查找，但是无论多大的Hash表，查找复杂度都是O(1)。 显然，如果值的差异性大，并且以等值查找（=、 &lt;、&gt;、in）为主，Hash索引是更高效的选择，它有O(1)的查找复杂度。 如果值的差异性相对较差，并且以范围查找为主，B树是更好的选择，它支持范围查找。 Innodb插入优化InnoDB使用聚集索引，数据记录本身被存于主索引（一颗B+Tree）的叶子节点上。这就要求同一个叶子节点内（大小为一个内存页或磁盘页）的各条数据记录按主键顺序存放，因此每当有一条新的记录插入时，MySQL会根据其主键将其插入适当的节点和位置，如果页面达到装载因子（InnoDB默认为15/16），则开辟一个新的页（节点）。 如果表使用自增主键，那么每次插入新的记录，记录就会顺序添加到当前索引节点的后续位置，当一页写满，就会自动开辟一个新的页。这样就会形成一个紧凑的索引结构，近似顺序填满。由于每次插入时也不需要移动已有数据，因此效率很高，也不会增加很多开销在维护索引上。 如果使用非自增主键（如果身份证号或学号等），由于每次插入主键的值近似于随机，因此每次新纪录都要被插到现有索引页得中间某个位置：此时MySQL不得不为了将新记录插到合适位置而移动数据，甚至目标页面可能已经被回写到磁盘上而从缓存中清掉，此时又要从磁盘上读回来，这增加了很多开销，同时频繁的移动、分页操作造成了大量的碎片，得到了不够紧凑的索引结构，后续不得不通过OPTIMIZE TABLE来重建表并优化填充页面。 只要可以，请尽量在InnoDB上采用自增字段做主键。 参考 数据结构中各种树 探索B树/B+树与MySQL数据库索引的关系 mysql索引的实现原理 平衡二叉树、B树、B+树、B*树 浅析——B树，B+树，B*树以及分析MySQL的两种引擎 mysql索引总结 由浅入深探究 MySQL索引结构原理、性能分析与优化 http://www.sohu.com/a/201923614_466939]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>索引</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux性能调优工具]]></title>
    <url>%2F2018%2F05%2F03%2Fperformance-linux%2F</url>
    <content type="text"><![CDATA[Linux性能调优CPU占用过高首先，通过top -c指令查看进程的cpu占用情况，找到cpu占用高的进程pid； 然后，通过top -Hp [pid]指令查看进程内线程运行情况，找出cpu占用高的线程pid； root@iZ2ze4k1o3ish3waeplqi8Z:~# top -Hp 14933PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 14965 root 20 0 2449044 493880 15588 S 0.3 24.1 0:05.92 java 14982 root 20 0 2449044 493880 15588 S 0.3 24.1 0:02.76 java 14984 root 20 0 2449044 493880 15588 S 0.3 24.1 0:18.18 java 14985 root 20 0 2449044 493880 15588 S 0.3 24.1 0:02.45 java 14999 root 20 0 2449044 493880 15588 S 0.3 24.1 0:13.40 java 假设第一个线程14965占用cpu最多，将[pid]=14965转换成16进制0x3a75 root@iZ2ze4k1o3ish3waeplqi8Z:~# printf "%x\n" 149653a75 最后，打印进程堆栈，过滤线程pid，查看线程栈，找出执行任务： root@iZ2ze4k1o3ish3waeplqi8Z:~# jstack 14933 | grep '0x3a75' -C5 --color"nioEventLoopGroup-2-1" #27 prio=10 os_prio=0 tid=0x00007fe5b890b800 nid=0x3a75 runnable [0x00007fe587802000] java.lang.Thread.State: RUNNABLE at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method) at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269) at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93) at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86) 本例为虚拟例子，所以当前执行的任务是poll()。 端口占用netstat -lap | grep 8051 lsof -i :8051 root@iZ2ze4k1o3ish3waeplqi8Z:~# netstat -lap | grep 8051tcp 0 0 *:8051 *:* LISTEN 14933/java tcp 0 0 172.17.134.10:8051 172.17.134.96:55014 ESTABLISHED 14933/java tcp 0 0 172.17.134.10:8051 172.17.134.96:51712 ESTABLISHED 14933/java tcp 0 0 172.17.134.10:8051 172.17.134.9:56656 FIN_WAIT2 - tcp 0 0 172.17.134.10:8051 172.17.134.9:56652 ESTABLISHED 14933/java tcp 0 0 172.17.134.10:8051 172.17.134.11:44974 ESTABLISHED 14933/java root@iZ2ze4k1o3ish3waeplqi8Z:~# lsof -i:8051COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEjava 14933 root 35u IPv4 43755096 0t0 TCP 172.17.134.10:8051-&gt;172.17.134.9:56652 (ESTABLISHED)java 14933 root 36u IPv4 43719121 0t0 TCP *:8051 (LISTEN)java 14933 root 48u IPv4 43719551 0t0 TCP 172.17.134.10:8051-&gt;172.17.134.96:51712 (ESTABLISHED)java 14933 root 59u IPv4 43751694 0t0 TCP 172.17.134.10:8051-&gt;172.17.134.96:55014 (ESTABLISHED) jmap -heap 14933jmap -histo:live 14933 | morell /proc/14933/fd/ll /proc/14933/task/ll /proc/14933/task | wc -l]]></content>
  </entry>
  <entry>
    <title><![CDATA[分布式锁]]></title>
    <url>%2F2018%2F05%2F03%2Fdistributed-system-lock%2F</url>
    <content type="text"><![CDATA[https://github.com/redisson/redisson http://redis.cn/topics/distlock.html https://blog.csdn.net/forezp/article/details/68957681 https://blog.csdn.net/forezp/article/details/70305336]]></content>
  </entry>
  <entry>
    <title><![CDATA[分布式ID生成器]]></title>
    <url>%2F2018%2F05%2F03%2Fdistributed-system-unique-id%2F</url>
    <content type="text"><![CDATA[分布式ID在分布式情况下，尤其是分库分表情况下，如何生成表的主键是一个问题。 我们对于表的主键有两个要求： 一是唯一性，这是基础，也是最重要的要求，ID必须唯一； 二是顺序性，如果表ID是有序的，越来越大的，那么ID可以起到时间排序的作用； 在单库情况下，我们通常使用自增ID作为表的主键。 分库情况下，为保证ID的唯一，就需要手工设置各个库的auto_increment值以及步长，例如：我们把user表分到4个库中，db1从1开始，db2从2开始，db3从3开始，db4从4开始，步长都是4；这样，db1上生成的ID是[1,5,9,13,……]，db2上生成的ID是[2,6,10,14,…..]。这样做问题不大，如果非要挑毛病，那么在一个db上ID是严格按照顺序创建的，但是跨db的ID顺序不能严格保证。例如，[5,6,7,8]因为在不同的db上，不一定是按照这个顺序创建的。 还有一种比较简单的办法就是直接使用UUID。UUID可以保证唯一性，并且不依赖于库。但是，UUID的问题是随机，没有顺序性，并且占用的存储空间比较大。 UUID的好处： 应用本地生成，保证唯一，数据库无感知。 UUID的坏处： 无法保证趋势递增； 32位字符串太长，占用存款空间大，占用索引存储空间大； B+树写操作时，过多的随机写操作，效率低（自增ID是顺序写）； 作为主键查询效率没有bigint高； 高并发情况下，不能100%保证一定唯一。 Snowflake算法Snowflake是Twitter生成64位自增ID的算法。 最高位不用，是0；接下来的41位是时间戳；接下来的10为是主机ID；最后12位是序列号。实际使用过程中，各组的位数可以根据实际情况进行调整。 SnowFlake的优势是本地生成，不依赖于其他任何第三方。我的理解：SnowFlake生成的自增ID有三部分组成：一、时间戳：为节省空间，可以不使用绝对时间，使用相对时间即可；例如：以2000年1月1日为时间基点，时间戳存储的是距离时间基点的毫秒数（实际上所谓绝对时间也是从1970年1月1日开始的）。二、进程标识：不同进程可能在相同时间生成ID，为了保证他们生成的ID不同，需要在ID中增加进程标志；进程标志可以是IP+Port，也可以自定义然后直接从配置文件中读取；三、进程内自增序号：解决同一个进程内并发的问题，使用AtomicInteger自增即可。 计算机元年就是1970年1月1日0时，加上时区因素，就是北京时间1970年1月1日8时。0毫秒就表示这个时间。 根据实际情况，我们也可以在上述三部分的基础上增加新的内容，例如业务类型。为保证ID具有顺序特性，通常时间戳都是放在最前面的；为了做分布式hash，通常自增序号都是放在最后面的；所以业务类型字段可以放在中间，进程标志的前后都可以。 回想一下，我们的order_bill_code其实也是类似的思路，业务类型+时间戳+自增序号(随机序号)，殊途同归。 参考Twitter-Snowflake，64位自增ID算法详解 详解Twitter开源分布式自增ID算法snowflake]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>SnowFlake</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库水平拆分]]></title>
    <url>%2F2018%2F05%2F03%2Fdatabase-sharding%2F</url>
    <content type="text"><![CDATA[数据库拆分垂直拆分数据库垂直拆分就是要把表按模块划分到不同数据库中。微服务架构中每个服务拥有自己独立的数据库，就是典型的垂直拆分。通俗说，就是根据业务类型，把一个数据库中的多张表拆分到多个数据库中，这样不同数据库的数据量和压力不同，可以有针对性的进行优化。 水平拆分垂直拆分只是把一张表拆分到另一个数据库实例中，并不会把一张表拆分为多张表。当单表的数据量增加到千万量级以上时，就需要拆表了，成为数据库水平拆分，也叫做数据库分片或者Sharding。 通常，我们认为MySQL数据库单表数据量在百万级，经过索引优化后查询效率是没有问题的。但是当数据量超过千万时，就需要考虑拆分了，如果超过五千万就肯定要拆表了。 数据库分片数据库垂直拆分相对简单一些，分片就复杂多了，本文主要讨论数据库分片遇到的各种问题和解决方案。 一般我们根据表的主键和数据类型的不同来进行表的拆分，下面分别以用户表、帖子表和订单表为例，介绍如何进行拆分表拆分的三种方法。 用户表用户表是典型的1对1例子，也就是说表的主键是user_id，1个用户只有1条记录。 背景用户表保存用户姓名、手机号码、登录名、登录密码等基本信息，主键是user_id。在业务初期，单库单表就能满足需求，但随着数据量越来越大，需要对数据库进行水平切分，常见的方法有范围法和取模法。 方案一、范围法： 将user_id设计为long型，根据user_id值的范围不同进行拆分。例如：1~1000万存储到db1中，1000万~2000万存储到db2中。 好处： 简单，读写时根据user_id可以迅速定位数据在哪个db上； 扩容简单，对历史数据无影响；每增加1000万用户，增加一个db即可。 坏处： user_id必须是整数，且自增； 数据量不均匀，前面的db满了才会新增db，新增db数据量小； 访问量不均匀，一般新注册用户活跃度高，新db的负载比旧db负载高。 二、哈希法： 对user_id取模，除以总共的db个数，根据mod值分配db。如果user_id是字符串，可以先计算出哈希值，然后再根据哈希值取模。例如：5个数据库，user_id以1/6结尾的存储到db1中，以2/7结尾的存储到db2中，依次类推（是不是可以简称为限行算法？）。 好处： 简单，最多计算user_id的哈希值就可以确定db位置； 数据均匀，哈希值均匀分布可以保证数据均匀分布到各个db上； 访问量均匀，理由同上； 坏处： 扩容复杂，扩容以后可能引起数据迁移，如何平滑进行数据迁移是一个问题。 每次2倍扩容：概率上有一半的数据不用迁移。例如：开始2个数据库，1/3/5/7/9在db1上，2/4/6/8/10在db2上；扩容2倍到4个数据库，1/5/9还在db1上，2/6/10还在db2上，60%的数据不用迁移，需要做的是把3/7移动到db3上，4/8移动到db4上。 一致性哈希：一致性哈希算法可以保证增加和减少数据库数量时，尽量少的数据需要迁移。不过一致性哈希一般基数需要大一些效果才好，至少32或64起步吧，也就是说上来就开64个数据库，相当于单表数据量在10亿量级。所以，2倍扩容应该更常见。 问题根据user_id分表以后带来的问题： 用户登录操作，需要根据登录名读取登录密码，现在有多张用户表，怎么办？都读取一遍？ 同样，还有根据用户手机号码查询用户信息的需求？ 此外，管理后台还有各种各样复杂、变态的查询需求，各种组合的，怎么办？ 解决先把查询需求分为前端需求和后台需求两种，使用不同的解决方案。 前端需求：通过登录名和手机号码查询用户，采用建立非主键属性到主键映射关系的方案。 后台需求：各种各样的复杂需求，采用前后端分离方案。 前端需求根据手机号码查询 以根据user_phone查询user表为例。 建一张user_phone_id表，主键是user_phone，内容字段是user_id。查询时先通过user_phone查询user_phone_id表找到user_id，然后再根据user_id找到用户信息。user_phone_id表可以不分片。 考虑性能，也可以把user_phone_id表的信息缓存在redis中，如果redis缓存不命中，再查数据库。 user_phone和user_id的对应关系一旦建立很少改变，适合做缓存。 根据登录名查询 假设查询字段是user_login_name，当然可以使用和user_phone相同的方法。如果user_login_name字段不是用户输入的，是系统自动生成的，那么我们有更简便的方法。 缓存的出发点是空间换时间，预先把对应关系保存起来。另外一种思路就是设计一个函数f(x)，保证f(user_login_name)=user_id，这样我们就不用查数据库了，直接结算就可以得到user_id。实际上我们不需要f(x)=user_id，因为我们不关心user_id具体是什么，我们只关系user_id在哪个db上，或者更专业点，在哪个数据库分片上。所以，我们只需要设计f(user_login_name)=db_sharding即可。这就简单了，我们创建用户记录时，根据user_id计算出db_sharding的值，然后放到user_login_name中就可以了。 如上图所示，最后三个字节保存的是user_id在那个db上（一共8个分片）。当根据登录名查询时，截取后三位就知道应该去哪个数据库查询了。 这种做法，需要考虑如果出现数据迁移怎么办，最好确定分片后就不变了。 后端需求上面都是单条数据的查询，那批量查询怎么办？回想一下，前端用户只能查询自己的数据，只有运营后台才可以批量查询用户数据，后端需要采用不同的策略。 水平切分的目的是为了提高访问速度，后台查询条件复杂，对响应时间要求不高，所以不用分库，从前端通过MQ同步数据即可。MQ同步数据机制建立以后，也可以同步到Hive等其他存储结构中。 帖子中心1对多。 订单中心以order表为例 order_id user_id product_id 首先，区分前端访问和后台访问。前端访问指用户的访问，用户下单后需要查询订单，查询条件比较简单，一般只能查询自己的订单，但是响应速度要求要快。后台访问指运营人员对订单的查询，一般查询条件比较复杂，但实时性要求低一些。 如图所示，order-center提供前端服务，order-center对应的数据库进行了水平切分；order-back提供后台服务，这里显示的存储方案是ES或者Hive，其实也可以是MySQL，总之后台服务的存储数据结构不依赖于前端，可以根据实际业务需求进行选择。如果选择了MySQL，后台存储可以选择不分库，因为后台需求往往逻辑比较复杂，但是对响应性要求不高。 前后端数据同步可以通过开源的中间件来实现，更多的时候像图中一样，通过MQ来同步。MQ异步同步意味着数据是有延迟的。MQ要保证数据送到的可靠性和幂等性。 不只是订单服务，后台可以把所有前端服务产生的数据都汇总到一个库中，可以是原始数据直接进入，也可以是经过order-back处理后的数据进入。（看上去有点像数据仓库了。） 接下来看，前端的数据库存储如何做水平拆分。 这里有一个前提，前端用户查询的都是自己的订单，不能查询别人的订单。这样，我们就可以根据user_id来分库。例如：如果分为4个库，那么最简单的办法对user_id % 4，来确定订单数据落在那个schema上面。实际操作中，我们是通过主键order_id来做水平切分的，所以要保证order_id和user_id的切分一致。所以在生成订单时，可以让order_id的最后两位和user_id 的最后两位一致，或者最简单order_id=timestamp+user_id，这样取模就肯定和user_id一致了。 https://mp.weixin.qq.com/s/PCzRAZa9n4aJwHOX-kAhtA https://blog.csdn.net/admin1973/article/details/74923283 https://blog.csdn.net/jiangzhexi/article/details/76794801 https://blog.csdn.net/admin1973/article/details/77713716]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Database</tag>
        <tag>MySQL</tag>
        <tag>Sharding</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL使用规范]]></title>
    <url>%2F2018%2F05%2F03%2Fmysql-rules%2F</url>
    <content type="text"><![CDATA[58MySQL规范 表存储引擎必须使用InnoDB 表字符集默认使用utf8，必要时使用utf8mb4（4个字节的utf8，能存储表情符号） 禁止使用存储过程、视图、触发器（扩展性差） 禁止在数据库中存储大文件，例如图片，大文件存储到分布式文件系统，数据库中保存访问地址 库名、表名、列名必须用小写，”_”分隔（MyBatis生成工具可自动转换为驼峰） 库名、表名、列名长度不要超过32个字符 表必须有主键，推荐使用unsigned整数为主键 禁止使用外键（外键影响性能，有可能造成死锁） 将大字段、访问频度低的字段拆分到单独的表中存储，分离冷热数据 根据业务区分使用tinyint/int/bigint分别占1/4/8字节 根据业务区分使用char/varchar（char查询性能高，varchar减少存储空间） 根据业务区分使用datetime/timestamp（我都使用datetime） 必须把字段定义为NOT NULL并设置默认值（NULL列使索引更复杂） 使用int unsigned存储IP4，不要使用char(15) 使用varchar(20)存储手机号码，不要使用整数（考虑+86，varchar支持模糊查询） 使用tinyint，不要使用enum 唯一索引使用uniq_命名 非唯一索引使用idx_命名 单表索引建议控制在5个以内（太多索引影响写性能，异常复杂的查询需求，可以选择ES等存储方式） 组合索引字段数不建议超过5个 不建议在频繁更新的字段上建立索引 除非必要不做join查询，join字段必须建立索引 禁止使用select *，只获取必要字段（表结构变更时，对程序无影响） insert必须指定字段（表结构变更时，对程序无影响） 隐式类型转换会使索引失效 禁止在where条件中使用函数或表达式（索引失效） 禁止以%开头的模糊查询（索引失效） 同一个字段OR使用IN ​ 赶集MySQL规范 控制列的数量，字段数控制在20个以内 避免使用NULL字段 不在数据库里存图片 不在索引列做运算 SQL语句尽可能简单 事务时间尽可能短 limit越大效率越低 ​ 阿里巴巴MySQL规范 互联网业务，能让服务层干的事情，不要交到数据库层。 删除无主键的表，如果是row模式的主从架构，从库会挂住。 TODO 如何实施数据库垂直拆分？ MySQL索引 MySQL索引失效 MySQL事务隔离级别]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Database</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Singleton]]></title>
    <url>%2F2018%2F05%2F02%2Fdesign-pattern-singleton%2F</url>
    <content type="text"><![CDATA[Singleton单例Singleton是最常见的设计模式，如何实现单例呢？如果实现线程安全的单例呢？ 单线程单例最常见的单例写法 声明一个静态实例 构造函数声明为私有，确保不能通过构造函数创建对象 getInstance()时进行null判断 public class OneThreadSingleton &#123; private static OneThreadSingleton instance = null; private OneThreadSingleton() &#123; &#125; public static OneThreadSingleton getInstance() &#123; if (null == instance) &#123; instance = new OneThreadSingleton(); &#125; return instance; &#125;&#125; 以上代码在单线程环境下进行测试，测试代码如下 public class SingletonExample &#123; public static void main(String[] args) &#123; for (int i=0; i&lt;10; i++) &#123; OneThreadSingleton singleton = OneThreadSingleton.getInstance(); System.out.println(singleton); &#125; &#125;&#125; 返回结果如下，都是一个实例，说明单例成功 cn.waterlu.java.design.OneThreadSingleton@6f75e721cn.waterlu.java.design.OneThreadSingleton@6f75e721cn.waterlu.java.design.OneThreadSingleton@6f75e721cn.waterlu.java.design.OneThreadSingleton@6f75e721cn.waterlu.java.design.OneThreadSingleton@6f75e721cn.waterlu.java.design.OneThreadSingleton@6f75e721cn.waterlu.java.design.OneThreadSingleton@6f75e721cn.waterlu.java.design.OneThreadSingleton@6f75e721cn.waterlu.java.design.OneThreadSingleton@6f75e721cn.waterlu.java.design.OneThreadSingleton@6f75e721 但是以上代码在多线程环境下是有问题的，多线程测试代码如下 public class SingletonExample &#123; public static void main(String[] args) &#123; List&lt;Task&gt; taskList = new ArrayList&lt;&gt;(); for (int i=0; i&lt;10; i++) &#123; Task task = new Task(); taskList.add(task); &#125; for (Task task : taskList) &#123; task.start(); &#125; &#125; public static class Task extends Thread &#123; @Override public void run() &#123; OneThreadSingleton singleton = OneThreadSingleton.getInstance(); System.out.println(singleton); &#125; &#125;&#125; 返回结果如下，存在不一样的情况，单例失败 注意，结果是随机的，需要多运行几次才能出现返回不一样实例的情况 错误原因在于并发进行(null==instance)判断是不准确的，可能存在多个线程判断时instance都是null的情况 cn.waterlu.java.design.OneThreadSingleton@65d2066bcn.waterlu.java.design.OneThreadSingleton@dbefcacn.waterlu.java.design.OneThreadSingleton@6464d21cn.waterlu.java.design.OneThreadSingleton@65d2066bcn.waterlu.java.design.OneThreadSingleton@65d2066bcn.waterlu.java.design.OneThreadSingleton@65d2066bcn.waterlu.java.design.OneThreadSingleton@65d2066bcn.waterlu.java.design.OneThreadSingleton@65d2066bcn.waterlu.java.design.OneThreadSingleton@65d2066bcn.waterlu.java.design.OneThreadSingleton@65d2066b 同步单例以上经典的单例代码在多线程情况是有问题的，也就是非线程安全的，如果如何写出线程安全的单例呢？ 以下代码是最容易想到的，给getInstance()方法增加synchronized关键字，这样就能保证线程安全了 首先肯定这种写法是对的，没有问题，可以实现线程安全的单例模式 这种写法虽然简单，但存在效率问题：每一次进入synchronized代码块都是需要加锁的，加锁和释放锁肯定是有开销的；绝大多数情况下，instance不等于null，加锁只在instance等于null时起作用，典型的悲观锁 既然这样，把synchronized放到if()判断里面不就行了，这就引出了另外一种实现 public class SynchronizedSingleton &#123; private static SynchronizedSingleton instance = null; private SynchronizedSingleton() &#123; &#125; public synchronized static SynchronizedSingleton getInstance() &#123; if (null == instance) &#123; instance = new SynchronizedSingleton(); &#125; return instance; &#125;&#125; 双重检查单例继续上面的思路，代码如下： synchronized代码块只在instance等于null时起作用，大多数情况下直接return instance即可 注意，这里有两个if (null == instance)判断，所以也被称为双重检查，那么为什么要做第二遍检查呢 因为synchronized虽然起到了互斥的作用，但是代码还是会执行的；假设，两个线程同时通过第一层null判断，抢到锁的线程执行了new操作；第一个线程释放锁以后第二个线程从阻塞状态唤醒执行，此时如果没有第二次判断，那么它还是会创建一个新的对象。 public class DoubleCheckSingleton &#123; private static DoubleCheckSingleton instance = null; private DoubleCheckSingleton() &#123; &#125; public static DoubleCheckSingleton getInstance() &#123; if (null == instance) &#123; synchronized (DoubleCheckSingleton.class) &#123; if (null == instance) &#123; instance = new DoubleCheckSingleton(); &#125; &#125; &#125; return instance; &#125;&#125; 静态单例其实还有更简单的单例实现方法，代码如下 代码非常简单，也是线程安全的，因为多线程只发生了读操作，当然是安全的 当然，这么做也有缺点，那就是没有延迟加载，俗称lazy load 即使StaticSingleton类没有被使用，它也创建对象并占用了内存空间；上面的例子都是延迟加载的，在第一次被使用时创建的对象 备注：我真心觉得这么写就挺好，又简单又高效，耗费那点内存空间真不算什么。 public class StaticSingleton &#123; private final static StaticSingleton instance = new StaticSingleton(); private StaticSingleton() &#123; &#125; public static StaticSingleton getInstance() &#123; return instance; &#125;&#125; 内部静态类单例 在前面代码的基础上进行改造，把创建对象操作放到内部类中实现，以完成延迟加载 头一次看到这种代码可能会感到奇怪，一步一步分析过来就了解了 public class Singleton &#123; private Singleton() &#123; &#125; private static class SingletonInner &#123; private static Singleton instance = new Singleton(); &#125; public static Singleton getInstance() &#123; return SingletonInner.instance; &#125;&#125; 这么多单例的实现方式，个人觉得这就和茴香豆的茴字有几种写法差不多，没啥意义。关键理解其中的思考方法，还有些意义。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>单例</tag>
        <tag>线程安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程高级篇(2) 线程实现]]></title>
    <url>%2F2018%2F04%2F29%2Fthread-advance-implementation%2F</url>
    <content type="text"><![CDATA[线程实现Java线程的实现有三种策略： 内核实现，Java线程相关方法声明为native，所有操作直接调用操作系统内核的API，此时的Java线程与操作系统内核线程一一对应； 用户实现，Java线程对操作系统是透明的，自己实现线程调度； 混合实现，综合上面两种实现的折中方案。 Java线程在JDK1.2之前采用用户实现策略，之后替换为内核实现。也就是说，一个Java线程就对应操作系统一个实际的线程（轻量级进程）。 Java线程使用抢占式的调度策略，由操作系统来分配执行时间。由于各个操作系统的线程优先级粒度不一样，所以Java线程优先级设置很难与操作系统线程优先级一一对应，所以就不那么靠谱。 上图中，KLT是Kernel Thread的缩小，表示这是一个操作系统内核线程；LWP是Light Weight Process的缩写，表示轻量级进程。应用程序一般不直接使用内核线程，而是使用轻量级进程作为接口；P表示一个Java进程。 所以，上图的含义为：一个Java进程中可以创建多个线程，每个线程调用LWP接口，实际对应着一个内核线程，内核线程由操作系统调度。 Linux 2.6以后有了一种新的pthread线程库–NPTL(Native POSIX Threading Library)，hotspot虚拟机就是使用NPTL来实现多线程的。]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>并发</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程中级篇(3) Java内存模型]]></title>
    <url>%2F2018%2F04%2F28%2Fthread-java-memory-model%2F</url>
    <content type="text"><![CDATA[内存模型什么是内存模型？首先，不要和JVM运行时数据区混淆了。JVM运行时数据区描述的是堆、栈等内存空间的组成，而内存模型是和多线程息息相关的，解决的是可见性和线程安全问题。 上图描述了Java内存模型， http://tutorials.jenkov.com/java-concurrency/ https://blog.csdn.net/suifeng3051 https://www.jianshu.com/u/f8e9b1c246f1 重排序： 编译器重排序 处理器重排序 volatile解决的是多线程之间读的可见性问题，如果只有一个线程写共享变量，多个线程读取共享变量，那么volatile可以保证读线程能够即使读取到共享变量的最新值，也就是说，一旦写线程修改了共享变量的值，那么读线程可以立即读取到最新的值，没有脏读。 但是，volatile不是用来解决多线程一起写的。只有在一种情况下，使用volatile多线程写共享变量不会出问题，那就是共享变量的新值与旧值没有关联，或者说新值是直接设置的，不需要通过旧值计算得到，这个时候即使有多线程写，volatile共享变量也是正确的。 实际情况中，这样的场景并不常见，多数场景新值都是依赖于旧值的。 volatile可以保证一旦写了，其他线程可以立即读取到；但是如果写之前其他线程做了读取操作，然后再一起写，这样就出问题了。 从内存语义的角度来说，volatile的写-读与锁的释放-获取有相同的内存效果 当写一个volatile变量时，JMM会把该线程对应的本地内存中的共享变量值刷新到主内存 当读一个volatile变量时，JMM会把该线程对应的本地内存中的值置为无效，从主内存中读取共享变量 Load1 LoadLoad Load2 确保Load1在Load2之前加载（从主内存读取到工作内存） Store1 StoreStore Store2 确保Store1在Store2之前存储（从工作内存回写到主内存） Load1 LoadStore Store2 先加载Load1，然后在存储Store2 Store1 StoreLoad Load2 最重要，刷新工作内存中所有共享变量到主内存，然后再读取 为实现volatile的内存语义，编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。 在每一个volatile写操作前面插入StoreStore，后面插入StoreLoad 在每一个volatile https://sourceforge.net/projects/fcml/files/fcml-1.1.1/hsdis-1.1.1-win32-amd64.zip/download java -XX:+UnlockDiagnosticVMOptions -XX:+PrintAssembly -Xcomp VolatileExample$Task &gt; VolatileExample$Task.asm -Xcomp -XX:+UnlockDiagnosticVMOptions -XX:+PrintAssembly -XX:CompileCommand=compileonly,*LazySingleton.getInstance -Xcomp -XX:+UnlockDiagnosticVMOptions -XX:+PrintAssembly -XX:CompileCommand=compileonly Object wait(), notify(), notifyAll() 必须先获得锁，然后才可以调用wait()和notify()方法 Spurious Wakeup 虚假唤醒，没有notify()，wait()就被唤醒。为避免这个问题，使用while()进行判断，不要使用if()进行判断。 注意：使用Object.wait()方法时，这个Object可以是任何对象，但不要使用字符串常量和全局对象。因为字符串常量内部会指向同一个对象。 原本是两个对象，两个锁。但是实际上引用指向一个对象。可能引发问题。如果使用notifyAll()还没有什么大问题，如果使用notify()就有问题了。 Synchronized 语句块是可以重入的(reentrance) 一旦一个共享变量（类的成员变量、 类的静态成员变量） 被 volatile 修饰之后， 那么就具备了两层语义： 保证了不同线程对这个变量进行读取时的可见性， 即一个线程修改了某个变量的值， 这新值对其他线程来说是立即可见的。 (volatile 解决了线程间共享变量的可见性问题)。 禁止进行指令重排序， 阻止编译器对代码的优化。 内存可见性 第一： 使用 volatile 关键字会强制将修改的值立即写入主存； 第二： 使用 volatile 关键字的话， 当线程 2 进行修改时， 会导致线程 1 的工作内存中缓存变量 stop 的缓存行无效（反映到硬件层的话， 就是 CPU 的 L1或者 L2 缓存中对应的缓存行无效） ； 第三： 由于线程 1 的工作内存中缓存变量 stop 的缓存行无效， 所以线程 1再次读取变量 stop 的值时会去主存读取。 那么， 在线程 2 修改 stop 值时（当然这里包括 2 个操作， 修改线程 2 工作内存中的值， 然后将修改后的值写入内存） ， 会使得线程 1 的工作内存中缓存变量 stop 的缓存行无效， 然后线程 1 读取时， 发现自己的缓存行无效， 它会等待缓存行对应的主存地址被更新之后， 然后去对应的主存读取最新的值。 禁止重排序volatile 关键字禁止指令重排序有两层意思： 当程序执行到 volatile 变量的读操作或者写操作时， 在其前面的操作的更改肯定全部已经进行， 且结果已经对后面的操作可见； 在其后面的操作肯定还没有进行 在进行指令优化时， 不能把 volatile 变量前面的语句放在其后面执行，也不能把 volatile 变量后面的语句放到其前面执行。 为了实现 volatile 的内存语义， 加入 volatile 关键字时， 编译器在生成字节码时，会在指令序列中插入内存屏障， 会多出一个 lock 前缀指令。 内存屏障是一组处理器指令， 解决禁止指令重排序和内存可见性的问题。 编译器和 CPU 可以在保证输出结果一样的情况下对指令重排序， 使性能得到优化。 处理器在进行重排序时是会考虑指令之间的数据依赖性。 内存屏障， 有 2 个作用： 1.先于这个内存屏障的指令必须先执行， 后于这个内存屏障的指令必须后执行。 2.使得内存可见性。 所以， 如果你的字段是 volatile， 在读指令前插入读屏障， 可以让高速缓存中的数据失效， 重新从主内存加载数据。 在写指令之后插入写屏障， 能让写入缓存的最新数据写回到主内存。 lock 前缀指令在多核处理器下会引发了两件事情： 1.将当前处理器中这个变量所在缓存行的数据会写回到系统内存。 这个写回内存的操作会引起在其他 CPU 里缓存了该内存地址的数据无效。 但是就算写回到内存， 如果其他处理器缓存的值还是旧的， 再执行计算操作就会有问题， 所以在多处理器下， 为了保证各个处理器的缓存是一致的， 就会实现缓存一致性协议， 每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了， 当处理器发现自己缓存行对应的内存地址被修改， 就会将当前处理器的缓存行设置成无效状态， 当处理器要对这个数据进行修改操作的时候， 会强制重新从系统内存里把数据读到处理器缓存里 2.它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置， 也不会把前面的指令排到内存屏障的后面； 即在执行到内存屏障这句指令时， 在它前面的操作已经全部完成。 内存屏障可以被分为以下几种类型： LoadLoad 屏障： 对于这样的语句 Load1; LoadLoad; Load2， 在 Load2 及后续读取操作要读取的数据被访问前， 保证 Load1 要读取的数据被读取完毕。 StoreStore 屏障： 对于这样的语句 Store1; StoreStore; Store2， 在 Store2 及后续写入操作执行前， 保证 Store1 的写入操作对其它处理器可见。 LoadStore 屏障： 对于这样的语句 Load1; LoadStore; Store2， 在 Store2 及后续写入操作被刷出前， 保证 Load1 要读取的数据被读取完毕。 StoreLoad 屏障： 对于这样的语句 Store1; StoreLoad; Load2， 在 Load2 及后续所有读取操作执行前， 保证 Store1 的写入对所有处理器可见。 它的开销是四种屏障中最大的。 在大多数处理器的实现中， 这个屏障是个万能屏障， 兼具其它三种内存屏障的功能。]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>并发</tag>
        <tag>线程</tag>
        <tag>内存模型</tag>
        <tag>内存可见性</tag>
        <tag>指令重排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程中级篇(2) 线程中断]]></title>
    <url>%2F2018%2F04%2F28%2Fthread-interrupt%2F</url>
    <content type="text"><![CDATA[我们在基础篇的线程介绍里面已经提到过如何中断线程，本文将详细展开，描述其中的细节，让大家对线程中断有一个更深刻的理解。 线程中断停止线程虽然在Thread中提供了stop()方法，但是已经声明为@Deprecated不再使用了。所以，其实Java并没有给我们提供一种简单和方便的优雅停止线程的方法。 @Deprecatedpublic final void stop() &#123;&#125; Java没有提供，那只能我们自己来实现了，比较容易想到的是加一个标志位stop=false，在线程执行过程中不断判断这个标志位，当标志为被置为true时，正常退出线程。 注意，这个标志位是典型的volatile关键字的应用场景：所有线程共享这个标志位，每个线程在自己的工作内存中有一个备份，当外部修改主内存中的标志位后，各个线程需要立即读取到变化，完成线程退出。 public class Task implements Runnable &#123; private volatile boolean stop = false; @Override public void run() &#123; while (!stop) &#123; // do something &#125; &#125; public void stop() &#123; this.stop = true; &#125;&#125; Task task = new Task();new Thread(task).start();task.stop(); 中断线程以上代码可以实现线程的正常停止，没有问题。但是有一种情况无法处理，那就是如果在while()语句块出现了I/O或者同步相关的阻塞操作，那么就无法判断stop的值了，上面停止线程的方法就失效了。怎么办呢？这个时候就需要中断线程了。 首先，这些阻塞方法是可以被中断的，一旦被中断将抛出InterruptedException异常；从下面的方法声明中可以看到，join()、sleep()和wait()都声明抛出InterruptedException异常，也就是说这些阻塞方法会检查线程的中断状态，如果发现被中断就抛出异常，变相提供了一种退出机制。 public class Thread &#123; public final void join() throws InterruptedException &#123;&#125; public static native void sleep(long millis) throws InterruptedException;&#125; public class Object &#123; public final native void wait(long timeout) throws InterruptedException; &#125; Thread类提供了方法来查询和设置中断状态。 public class Thread &#123; public boolean isInterrupted() &#123;&#125; public void interrupt() &#123;&#125;&#125; 当调用了一个线程的interrupt()方法后，当前线程的状态被置为中断状态，但是线程不会自动停止，需要我们来进行处理，停止线程的代码可以修改为： public class MyThread extends Thread &#123; @Override public void run() &#123; while (!isInterrupted()) &#123; // do something &#125; &#125;&#125; MyThread thread = new MyThread();thread.start();thread.interrupt(); 这里将while(!stop)修改为while (!isInterrupted())，停止方法由调用自定义的stop()方法改为调用Thread类实例对象的interrupt()方法。 实战中，我们不会在线程执行过程中每执行一步就判断一次isInterrupted()，所以更加贴近现实场景的情况是中断阻塞操作。前面讲过，这时会抛出异常，我们捕获异常并退出程序即可。 public class MyThread extends Thread &#123; @Override public void run() &#123; while (!isInterrupted()) &#123; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; break; &#125; &#125; &#125;&#125; 我们以sleep()阻塞为例，wait()和join()也是一样的；当外部调用myThread.interrupt()时，发现MyThread正处于sleep的阻塞状态，会让sleep()抛出InterruptedException异常，我们捕获异常退出即可。 注意，如果外部调用interrupt()方法时，线程处于非阻塞状态，那么状态被设置为interrupted；如果线程处于阻塞状态，那么抛出异常，但是线程状态不会被修改。所以，我们可以在捕获异常后自行设置中断状态，统一退出，看上去是更优雅的做法，代码如下。 public class MyThread extends Thread &#123; @Override public void run() &#123; while (!isInterrupted()) &#123; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; Thread.currentThread().interrupt(); &#125; &#125; &#125;&#125; Thread.currentThread().interrupt()手工设置中断状态，然后通过isInterrupted()判断退出。 实战原来停止或者中断一个线程如此麻烦，那实战中如何使用呢？ 其实，实战反而简单。因为实战中我们通常只实现Runnable接口，并把任务提交给Executor去处理。虽然我们自己没有创建Thread对象，但最后线程池里面保存的肯定是Thread对象，也就是说Executor帮我们创建了Thread对象，它实现了一种中断机制来保证任务可以被中断或取消。 下面通过例子代码看看如何使用。 TODO FutureTask的取消]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>并发</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程基础篇(4) 线程同步]]></title>
    <url>%2F2018%2F04%2F28%2Fthread-basic-signal%2F</url>
    <content type="text"><![CDATA[线程同步我们已经了解如何创建一个线程，以及如何交给线程池去调度，接下来看看线程之间同步的问题。之所以引入线程同步的原因是临界资源和竞争条件，我们先不讨论，放到后面去了解，这里先来看如何实现线程同步。 synchronized关键字synchronized用来标识同步语句块，同步语句块同一时间只能有一个线程执行，其他线程都必须等这个线程执行完成，起到了同步锁的作用。并发操作添加synchronized后意味着变成了串行操作，一次只能执行一个。 四种同步方法synchronized可以用在以下四个位置进行同步 类的成员方法上 静态方法上 类成员方法内部的语句块上 静态方法内部的语句块上 synchronized语义可以理解为对一个对象的锁定，同一时刻只有一个线程可以操作这个对象，其他线程被锁定。或者说，synchronized语句意味着synchronized代码块与一个对象进行了关联，需要先锁定这个对象，然后才能执行synchronized代码块，当然这个对象只能被锁定一次，当退出synchronized代码块时可以解锁这个对象。 下面依次来看一下synchronized关键字放置在不同位置的效果 类成员方法 public class Math() &#123; public synchronized void add(int value)&#123; this.count += value; &#125;&#125; 上述代码意味着，synchronized语句块（this.count += value;）的执行，必须先要获得Math类实例对象的锁，然后才可以执行。当两个线程同时执行一个Math对象的add()方法，后执行的线程加锁失败，必须等到先执行的线程操作完成，退出synchronized语句块解锁后才能开始执行。 注意，锁定的是对象，不是类，如果两个线程创建了两个Math对象，那么是可以同时调用它们的add()方法的。 静态方法 public class Math() &#123; public static synchronized void add(int value)&#123; Math.count += value; &#125;&#125; 可以认为静态方法同步锁的是类对象（区分类对象和实例对象），所以两个线程对静态同步方法的调用一定是互斥的。 方法内部语句块 public class Math &#123; public void add(int value)&#123; synchronized(this) &#123; this.count += value; &#125; &#125;&#125; 其效果和第一种把synchronized加到类成员方法上面是一样的。其实，这样写更明显，可以认为是第一种的翻译。 静态方法内部语句块 public class Math &#123; public void add(int value)&#123; synchronized(Math.this) &#123; this.count += value; &#125; &#125;&#125; 同上，这种写法和第三种是一样的，效果也一样。 思考一下：如果一个类有两个方法，一个静态，一个非静态，都加上synchronized关键字，可以同时执行吗？答案是可以。因为一个锁定的是实例对象this，另外一个锁定的是类对象Math.this，不是一个对象，所以可以同时执行。 Object对象 synchronized关键字不一定非要修饰this，也可以自己指定任何一个Object对象实例，如下也可行： public class Math &#123; private Object lock = new Object(); public void add3(int value)&#123; synchronized(lock) &#123; this.count += value; &#125; &#125;&#125; 选用哪种方法有这么多种同步方法，实战中我们应该选择哪一种呢。个人建议选择“方法内部语句块”的同步方法，这样同步对象非常明确，不容易引起混淆。此外，同步语句块的颗粒度也可以小于同步方法，减小同步语句块通常也是提升性能的方法之一。 字符串常量再来多思考一层，像下面这样写行不行呢？ public class Math &#123; private String lock = "lock"; public void add(int value)&#123; synchronized(lock) &#123; this.count += value; &#125; &#125;&#125; 说行也对，应该不会报错；说不行也对，因为这样有隐患，强烈不建议这么用。详细说一下，如果只有一个类这么用是不会出错的，但是如果有两个类这么用就出问题了。 public class Math &#123; private String lock = "lock"; public void add(int value)&#123; synchronized(lock) &#123; this.count += value; &#125; &#125;&#125;public class Work &#123; private String lock = "lock"; public void work(int value)&#123; synchronized(lock) &#123; //doSomething &#125; &#125;&#125; 如上，完全不相干的两个类，add()方法和work()的调用将会互斥，因为两个方法都将试图锁定相同的字符串实例。这里多说一下，理论上讲，虽然字符串内容一样，但是Math和Work两个类中的lock应该是不同的对象；但是，为了效率，Java提供了常量池的概念，导致两个类中的lock对象都是常量池中”lock”的引用，所以就一样了。 正常情况，String也是一个普通的类，那么lock作为String类的实例对象，应该在堆上分配空间，并且 “lock” 应该保存在堆空间上。如果是这样的话，两个类中的lock对象就不一样了。例如：把String lock = “lock”换成 Object lock = new Object()就没有问题了。但是实际情况是，创建String对象时，字符串内容没有保存到堆空间上，而是在方法区开辟了一块空间来保存，这块空间也被成为常量池。常量池是有去重逻辑的，当创建第二个lock对象时，发现常量池中已经存在就不会再创建了，直接返回已有常量字符串。 wait/nofity/notifyAll有了synchronized以后，其实我们已经可以进行线程通信了。例如：我们可以创建一个线程共享对象MySignal，一个线程在完成工作后，修改hasDataToProcess标志，另外一个线程轮询这个标志位，当第一个线程任务完成后第二个线程开始自己的任务。 public class MySignal&#123; protected boolean hasDataToProcess = false; public synchronized boolean hasDataToProcess()&#123; return this.hasDataToProcess; &#125; public synchronized void setHasDataToProcess(boolean hasData)&#123; this.hasDataToProcess = hasData; &#125;&#125; 以上模型有一个明显的问题，就是第二个线程需要一直查询，占用CPU时间，所以更常用的线程间通信机制是wait和notify，调用wait()方法后当前线程进入阻塞，让出CPU时间片。 调用wait()方法将使当前线程进入等待状态，直到有其他线程调用了notify()方法后唤醒。wait()有点像sleep()，但是也有很大的区别。 首先，一定要注意sleep()是Thread类的静态方法，wait()是Object类的成员方法，这非常重要。虽然wait和notify是用来实现线程通信的，但是它们并不是Thread类的方法。其实这也非常好理解，假设实现方案是调用Thread类的wait()方法进入等待状态，那么如何把它唤醒呢，肯定还得调用这个Thread类对象的notify()方法来唤醒；那么我们知道肯定需要在其他线程中完成某一项工作后唤醒这个线程，那就意味着另外一个线程得拥有这个线程的类实例对象，这明显是不合适的。退一步，两个线程之间共享对象就合理多了。 其次，wait()和notify()方法必须在synchronized代码块内执行，也就是说，首先你得拥有这个对象的锁，然后才可以调用wait()和notify()方法。解析一下，通常的逻辑如下：一个线程获得Object对象锁进入synchronized代码块开始自己的工作，需要时调用wait()方法进入等待；这个时候另外一个线程获得Object对象锁进入synchronized代码块，执行自己的任务，任务完成后调用notify()方法，唤醒正在等待的线程。其实，以上就是生产者-消费者基本的处理逻辑。 最后，调用一个对象的notify()方法后，将唤醒一个在这个对象上wait()的线程，如果有多个现线正在wait()，那么由操作系统来决定唤醒哪一个，可以认为是随机的；如果调用的是notifyAll()方法，那么这个对象上wait()的全部线程都将被唤醒。 需要注意，notify()唤醒只是意味着wait()线程进入runnable状态，也就是可以执行的状态，至于什么时间能够被执行，还是看操作系统调度。换句话说，notify()的确可以唤醒线程，但是被唤醒线程什么时间能够被执行是没有保障的，运气不好的话，如果CPU一直在忙，那么被唤醒线程也可能很久都得不到执行。 下面来看一个例子，这里只展示基本用法，通过生产者和消费者的例子可以看的更清楚 public class MonitorObject&#123;&#125;public class MyWaitNotify&#123; MonitorObject myMonitorObject = new MonitorObject(); public void doWait()&#123; synchronized(myMonitorObject)&#123; try&#123; myMonitorObject.wait(); &#125; catch(InterruptedException e)&#123;...&#125; &#125; &#125; public void doNotify()&#123; synchronized(myMonitorObject)&#123; myMonitorObject.notify(); &#125; &#125;&#125; 丢失问题这里同样存在使用常量字符串做为同步对象的问题。 public class WaitNotify extends Thread &#123; private String myMonitorObject = "lock"; boolean wasSignalled = false; @Override public void run() &#123; doWait(); &#125; public void doWait()&#123; System.out.println("notify doWait start"); synchronized(myMonitorObject)&#123; while(!wasSignalled)&#123; try&#123; myMonitorObject.wait(); &#125; catch(InterruptedException e)&#123; &#125; &#125; wasSignalled = false; &#125; System.out.println("notify doWait done"); &#125; public void doNotify()&#123; synchronized(myMonitorObject)&#123; wasSignalled = true; myMonitorObject.notify(); &#125; &#125;&#125; public class WaitNotify2 extends Thread &#123; private String myMonitorObject = "lock"; boolean wasSignalled = false; @Override public void run() &#123; doWait(); &#125; public void doWait()&#123; System.out.println("notify2 doWait start"); synchronized(myMonitorObject)&#123; while(!wasSignalled)&#123; try&#123; myMonitorObject.wait(); &#125; catch(InterruptedException e)&#123; &#125; &#125; wasSignalled = false; &#125; System.out.println("notify2 doWait done"); &#125; public void doNotify()&#123; synchronized(myMonitorObject)&#123; wasSignalled = true; myMonitorObject.notify(); &#125; &#125;&#125; public class ThreadSignal &#123; public static void main(String[] args) throws InterruptedException &#123; WaitNotify notify = new WaitNotify(); WaitNotify2 notify2 = new WaitNotify2(); notify.start(); notify2.start(); Thread.sleep(1000); System.out.println("send signal"); notify.doNotify(); &#125;&#125; 由于WaitNotify和WaitNotify2实际上使用的是一个锁对象，所以实际上现在myMonitorObject对象上有两个wait()，当我们调用notify.doNotify()时，会随机选择一个来唤醒。如果唤醒的是WaitNotify，那么没有问题；如果唤醒的是WaitNotify2，那么就出问题了。 生产者和消费者实例通过经典的生产者和消费者的例子，可以看到Thread类和Object类如何配合，以及线程的生命周期和状态变化。 需求 两个线程，一个线程作为生产者生产商品，一个线程作为消费者消费商品； 商品有库存，当库存满时生产者暂停生产，当库存空时消费者暂停消费。 实现主线程 创建库存列表，启动生产者线程和消费者线程 public class ProducerAndConsumer &#123; public static void main(String[] args) &#123; LinkedList&lt;String&gt; storeList = new LinkedList&lt;&gt;(); // 生产者和消费者共享库存列表 Producer producer = new Producer(storeList); Consumer consumer = new Consumer(storeList); producer.start(); consumer.start(); &#125;&#125; 生产-消费逻辑 开始库存是空的，先生产一个数据 此后如果可以抢到synchronized锁，可以继续生产数据，直到库存满 库存满了以后主动让出时间片，进入waiting状态，等待消费者notify() 如果生产完第一个数据后没有抢到synchronized锁，那么进入blocked状态，等待消费者退出synchronized代码块；当消费者完成一次消费操作退出synchronized代码块后，生产者线程进入runnable状态，等待CPU调度；抢到CPU时间片后可以继续生产 如果生产者线程一直没有抢到CPU时间片，那么消费者一直消费（一次消费一个），直到库存空 库存空以后消费者交出时间片，生产者获得时间片，继续生产数据 生产数据后通过notify()方法唤醒消费者线程 生产者notify()方法只能保证消费者线程进入runnable状态，但不一定能抢到时间片执行 大家都是runnable状态时，谁能得到CPU时间片就看人品了，操作系统就可以这么任性 生产者线程public class Producer extends Thread &#123; // 库存最大容量 private final static int MAX = 10; // 计数器，方便观察 private AtomicInteger count = new AtomicInteger(1); // 库存 private LinkedList&lt;String&gt; storeList; public Producer(LinkedList&lt;String&gt; storeList) &#123; this.storeList = storeList; &#125; @Override public void run() &#123; // 获得时间片，进入running状态 while(true) &#123; // 必须在synchronized代码块内使用wait()和notify() // 如果storeList已经被其他线程锁定，进入blocked状态 // 如果storeList没有被其他线程锁定，继续running状态 synchronized (storeList) &#123; while(storeList.size() == MAX) &#123; System.out.println("库存满了"); try &#123; // 库存满了，不能再生产了 // 让出时间片，进入waiting状态 // 操作系统负责保存当前线程状态，当恢复时从这里继续执行 storeList.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; // storeList.size() &lt; MAX 时，直接生产一个新数据 // storeList.size() = MAX 时，消费者调用storeList.notify()时, // 进入runnable状态，获得时间片后继续执行，生产一个新数据 String data = String.format("%04d", count++); storeList.add(data); System.out.println("生产 " + data); // 让出时间片，进入waiting状态 try &#123; Thread.sleep(500); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; // Sleep 500毫秒后进入runnable状态，获得时间片后继续执行 // 通知消费者，如果消费者由于库存空了进入waiting状态，此时将被唤醒 storeList.notifyAll(); // 此后重新尝试进入synchronized代码块 &#125; &#125; &#125;&#125; 消费者线程public class Consumer extends Thread &#123; // 库存 private LinkedList&lt;String&gt; storeList; public Consumer(LinkedList&lt;String&gt; storeList) &#123; this.storeList = storeList; &#125; @Override public void run() &#123; // 获得时间片，进入running状态 while(true) &#123; // 如果storeList已经被其他线程锁定，进入blocked状态 // 如果storeList没有被其他线程锁定，继续running状态 synchronized (storeList) &#123; while(storeList.size() == 0) &#123; System.out.println("库存空了"); try &#123; // 库存空了，不能再消费了 // 让出时间片，进入waiting状态 storeList.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; // storeList.size() &gt; 0 时，直接消费一个数据 // storeList.size() = 0 时，生产者调用storeList.notify()时, // 进入runnable状态，获得时间片后继续执行，消费一个数据 String data = storeList.get(0); System.out.println("消费 " + data); storeList.remove(0); // 让出时间片，进入waiting状态 try &#123; Thread.sleep(500); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; // 通知生产者，如果生产者由于库存满了进入waiting状态，此时将被唤醒 storeList.notifyAll(); // 此后重新尝试进入synchronized代码块 &#125; &#125; &#125;&#125; 输出结果分析 下表列出了输出结果和对应的线程状态 日志输出 Producer PC Producer状态 Consumer PC Consumer状态 生产 0001 storeList.add(); running runnable 消费 0001 synchronized () blocked storeList.remove(); running 库存空了 synchronized () blocked storeList.wait(); waiting 生产 0002 storeList.add(); running storeList.wait(); waiting 生产 0003 storeList.add(); running storeList.wait(); waiting synchronized () blocked 消费 0002 synchronized () blocked storeList.remove(); running 消费 0003 synchronized () blocked storeList.remove(); running 库存空了 synchronized () blocked storeList.wait(); waiting 生产 0004 storeList.add(); running storeList.wait(); waiting …… 生产 0013 storeList.add(); running synchronized () blocked 库存满了 storeList.wait(); waiting synchronized () blocked 消费 0004 storeList.wait(); waiting storeList.remove(); running 消费 0005 synchronized () blocked storeList.remove(); running 消费 0006 synchronized () blocked storeList.remove(); running 生产 0014 storeList.add(); running synchronized () blocked 生产 0015 storeList.add(); running synchronized () blocked 注意：每生产或者消费一个数据以后都通过storeList.notify()来唤醒对手方的storeList.wait()，但是唤醒只能保证对手方线程进入runnable状态；这个时候继续执行当前线程(notify)，还是切换到等待线程(wait)是由操作系统来调度的，是随机的。此外，由于synchronized的存在，多CPU情况下生产者和消费者也不会长期同时处于running状态，短暂同时处于running状态后，后进入synchronized代码块的线程将进入blocked状态，等待前进入的线程退出synchronized代码块。]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>并发</tag>
        <tag>线程</tag>
        <tag>synchronized</tag>
        <tag>wait</tag>
        <tag>notify</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【置顶】Java多线程]]></title>
    <url>%2F2018%2F04%2F27%2Fthread-catalog%2F</url>
    <content type="text"><![CDATA[引言并发是Java开发领域中经常被提及的问题，也是比较复杂的问题。提到并发就不得不提到多线程和锁，可以认为JVM的线程模型和加锁机制是Java并发的基础。实际工作中，我们可能不会经常去操作线程池，使用wait/notify进行线程间通信，所以对多线程感受并不强烈。这是因为我们通常都是在框架的基础上进行开发，框架帮我做了这些事情，虽然我们没有感觉到，但是从服务启动那一刻开始，Java多线程机制一直在运转。 多线程少被提及的另一个原因，我认为与现代系统都是分布式系统有关，或者说是多进程的分布式系统有关，更多被提到的是多进程之间如何通信，如果处理高并发的问题。线程间通信局限在一个JVM进程之内，所以多线程的处理机制并不能解决多进程的问题(例如：synchronized可以在一个JVM进程内加锁实现线程互斥的目的，但是当我们分布式部署时，一个服务有多个进程实例，synchronized就起不到相应的作用了)。 既然在分布式系统中多线程机制已经不能解决问题了，那我们为什么还需要去了解Java多线程的原理和应用呢？ 首先，每个服务都是一个JVM进程，由多个线程组成，虽然框架帮我们封装了线程操作，把我们从复杂的多线程调度中解放处理，专注于业务逻辑；但是当出现问题或者需要调优时，了解底层的实现机制就显得必要；可以做一个这样的类比，平时我们也可以不关注JVM GC相关的内容，通常我们的Java应用可以很好的运行，但是当出现内存不足、内存泄漏等问题时，就需要我们了解GC的原理了。 其次，初期我们通常选用开源框架搭建业务服务；但是要明白框架或者中间件的出现通常是为了满足一个具体的需求而产生的，当任务完后进行抽象、剥离，开源后形成框架的；这就意味着所谓开源框架不是为你的业务需求而生的，很可能在某些方面不能满足、或者不能完美实现我们的需求；这个时候就需要我们在开源框架的基础上进行定制化修改（例如：阿里定制化MySQL），或者完全重新实现一个（例如：阿里借鉴Kafka原理实现RocketMQ），这个时候理解多线程机制就显得尤为重要了。 最后，多线程并发和多进程并发虽然有区别，但是也有很多类似之处；虽然具体的处理方法上可能差别较大，但是如果从思路和原理的角度来看，两者有非常多的相同点。例如，我们知道JDK1.5的并发包中提供了种类丰富的锁，那么我们在实现分布式锁的时候，就可以参考JDK中实现。还有，虽然多线程解决的是一个进程内的问题，但是和多进程一样都是并发操作引发的问题，即使解决方案不同，遇到的问题也是类似的。例如，多线程里面经常提到volatile，volatile解决的是什么问题呢？我们这里不讨论如何解决，只讨论问题是什么。我认为，本质上volatile解决的是由于缓存带来的与主内存不一致的问题。接下来开一下脑洞，多线程存在这个问题，多进程是否也有同样的问题呢？当然存在，如果我们把数据库看作主内存，那么在进程中缓存数据库中的数据就和线程的工作内存没有两样，当回写时就有可能出现问题。 当我们遇到问题时，类比是一种解决问题的思路。能够创新性的发明一种新的方法来解决问题的是大师，可遇而不求；能够找到类似问题的历史解决方案并设计出相应的解决方法， 通俗的说，如果你可以熟练使用Java多线程编程，那么你就至少是中级程序员了；如果还可以明白背后的原理，并引申有自己的思考，那么我认为你自称高级程序员不会有人质疑。 关于Java并发和多线程的资料有很多，网上一搜一大堆。接下来我会按照我的理解和思路进行一番串联。我发现很多书籍都是先讲原理，再讲应用，这和我们的实践是相悖的。通常，我们都是在不完全了解的情况下先使用，在使用过程中发现问题或者不清楚的地方再去看原理，这才是正常的思维。所以，我会先从应用开始：首先，我们要达到一个什么样的目的（目标）；接下来，我们要如何做才能实现目标（应用），最后才是为什么要这么做，其背后深层次的原因是什么（原理）。 有时候想，如果现在让我重新回到大学去学习计算机组成原理、操作系统原理、编译原理等，应该有不同理解。 大纲本文是一个大纲，或者目录，串联起整个思路，后面将逐一详细展开，敬请关注。 Q：为什么需要多线程？ A：在多处理器的硬件环境下，使用多线程可以提升程序运行的性能。 Q：怎么才能拥有一个线程？ A：new Thread()或者实现Runnable或Callable接口，我们就拥有了一个新的线程。run()方法将在新的线程中运行（非创建Thread类的线程），具体什么时间开始执行由操作系统决定。 Q：有了线程之后，如何管理？ A：为避免经常创建和销毁线程，产生不必要的开销，通常我们把任务交给线程池处理。ThreadPoolExecutor的构造参数决定了它的调度行为。 Q：线程从创建到销毁，有哪些状态？ A：一张线程状态迁移图描述了各个状态以及状态转换的触发条件。 Q：为了支持多线程，JVM需要做哪些事？ A：JMM就是JAVA对如何处理多线程的描述，JMM是一个跨平台的约定。 Q：多线程这么好吗？有没有什么问题？ A：多线程提升性能的同时，也带来了很多问题：内存可见性问题、指令重排序问题、临界资源和竞争条件问题、线程间通信的问题、线程饥饿问题、公平性问题、读写锁、死锁问题、虚假唤醒问题、嵌套死锁问题、重入死锁问题，等等。后面重头戏就是逐一描述和解决这些问题。 目录以下为各个章节的目录，应用相关的我称之为基础篇，原理相关的我称之为中级篇，其中可能有部分比较复杂的，我称之为高级篇。以下内容多为原创，图是从参考资料中截取的。 多线程基础篇 以代码为例，展示最基本的应用场景和使用方法。简单说，就是怎么使用。 多线程基础篇(1) 线程 多线程基础篇(2) 线程池 多线程基础篇(3) ThreadPoolExecutor 多线程基础篇(4) 线程同步 多线程(4) Java内存模型 线程 为什么需要多线程，多线程能够解决什么问题？多线程又带来哪些问题？如何拥有新的一个线程？ 线程池 线程如何调度？如何创建线程池？线程池有哪些参数，能够控制哪些行为？ 线程同步 synchronized、wait/notify、 生产者/消费者问题 非常经典的生产者消费者问题 Java并行包 ReentrantLock、AtomicInteger、ReadWriteLock ThreadLocal 每个线程有自己的值 多线程中级篇 探求内部实现原理和复杂一些的用法。简单说，就是内部基本原理。 线程状态 线程有几种状态？各个状态之间如何变化？一张完整的线程状态迁移图。 线程中断 当启动线程后，如果取消和关闭线程。 Java内存模型 JMM对于理解Java多线程非常重要，一定要吃透。 深入volatile 内存可见性与指令重排序问题。 深入synchronized 临界资源和竞争条件问题 深入wait/notify 线程间通信的问题、虚假唤醒问题 死锁 死锁问题、嵌套死锁问题、重入死锁问题 线程调度公平性 线程饥饿，公平锁 ReentrantLock源码解析 从源码基本解析 AtomicInteger源码解析 多线程高级篇 复杂原理，或者操作系统级别的实现原理。简单说，就是如果从头自己实现，需要怎么做。 线程模型 实现多线程有哪些常见的模型？Java采用的是哪一种模型？并发和并行的区别？ 线程实现 线程底层是如何实现的？一个JAVA线程对应操作系统的什么？ 内存屏障 volatile的实现语义 为什么要有多线程，多线程解决哪些问题？ 现代计算机拥有多个处理器，每个处理器又拥有多个核心；多线程的目的就是为了提升性能，让多个任务可以同时运行。如果只有一个线程，那么只会用到一个处理器的一个核心，CPU资源将被浪费。 多线程带来好处的同时，也带来成本和开销。 实现多线程有很多中模型，Java采用的是哪一种？（高级） 并发和并行的区别？ 多线程和多进程的区别？ 如何拥有一个线程？怎么把多线程创建出来？ 引入多线程以后，带来了哪些问题？ 临界资源 竞争条件 哪些资源是临界资源，可能在多线程执行过程中出现问题（内存、栈、堆） 多线程以后怎么办？Java内存模型。 基础篇-使用 Thread/ThreadPool/ReentrantLock/BlockingQueue/volatile/ThreadLocal/AtomicInteger/ wait/notify/synchronized 中级篇-原理 JMM/指令重排序/内存屏障/线程饥饿/CAS 高级篇-分析 并行包源码，自己实现，字节码分析，汇编码分析 http://ifeve.com/non-blocking-algorithms/ 什么是线程，为什么要多线程 如何创建线程 如何调度多线程 多线程带来了哪些问题 只有共享才有问题，不共享就没问题 哪些变量共享？ ThreadLocal，每个线程不一样，不共享 一个一个解决多线程带来的问题 缓存 指令重排序 死锁 嵌套锁死 重入锁死 虚假唤醒（自旋锁） 饥饿 ​ volatile，一个写，多个读 synchronized，多个写（锁，解锁） wait/notify，多线程之间的通信 以上已经实现了锁的功能，后面都是如何解决问题和提交效率了 线程饥饿 重入 读 &gt;&gt; 写 Lock显式锁 显示意味着可以控制更多 ReentreLock，可重入锁（解决了饥饿问题？） 读操作也需要锁吗？如果一个写，多个读用volatile就好，不用锁。如果只是读很多，写比较少呢？ 读写锁出现了 java.util.concurrent包源码分析，JDK1.5以后并行包提供了一切，直接用就行了，最好理解源码和原理 CAS乐观锁(AtomicInteger使用CAS实现) ConcurrentLinkedQueue ​ 多个线程读，不需要锁； 一个线程写，多个线程读，volatile； 多个线程写，synchronized 读多写少， 参考资料http://www.cnblogs.com/skywang12345/p/3479949.html https://blog.csdn.net/huzhigenlaohu/article/details/51627201]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>并发</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程中级篇(1) 线程状态]]></title>
    <url>%2F2018%2F04%2F25%2Fthread-status%2F</url>
    <content type="text"><![CDATA[线程状态一个新线程启动后，从开始运行一直到最后任务执行完成销毁这个线程，在整个线程生命周期中有哪几个状态，各个状态之间如何流转，本文将给出详细解释。 线程状态迁移下面的这个线程状态迁移图是比较经典的，画的很详细，理解了这幅图就理解了线程状态变化。 线程的几个状态 [new]：初始状态，新建一个线程对象后的状态； [runnable]：就绪状态，调用了start()方法后，线程等待CPU资源准备执行的状态； [running]：运行状态，得到了CPU时间片，执行run()方法或者call()方法； [dead]：销毁状态，线程任务执行结束或者强制退出后的状态； [blocked]：阻塞状态，被动失去CPU时间片，等待进入runnable状态； [waiting]：等待状态，主动失去CPU时间片，等待进入runnable状态； waiting状态和blocked状态的区别在于一个是主动交出时间片，另外一个是被动交出时间片；当然前提是已经获得了时间片开始执行；从runnable状态到running状态是不受程序控制的，完全靠操作系统来调度，虽然我们可以设置线程的优先级，但是不一定达到预期。 状态变化过程 [new]：MyThread thread = new MyThread(); [new]-&gt;[runnable]：thread.start(); [runnable]-&gt;[running]：操作系统调度，runnable状态意味着任务已经做好执行的准备，但什么时间真正执行（获得时间片）需要由操作系统来控制，任务本身无法控制； [running]-&gt;[dead]：线程执行完成； [running]-&gt;[runnable]： Thread.yield(); 调用yield()方法将失去时间片，但是可以立刻进入runnable状态，运气好的话可以立刻又获得时间片进入running状态；yield()给其他任务以执行的机会； [running]-&gt;[waiting]： thread.join();调用join()方法将失去时间片，进入waiting状态，等到thread线程执行完毕后进入runnable状态； object.wait(); 调用 wait()方法将失去时间片，进入waiting状态，得到其他线程执行object.notify()方法是进入runnable状态； Thread.sleep(); 调用sleep()方法将失去时间片，进入waiting状态，sleep结束后进入runnable状态； [running]-&gt;[blocked]：进入synchronized(object){}语句块前检查object锁，如果object已经被锁定，那么当前线程进入blocked状态，当object锁被释放后，当前线程进入runnable状态； [waiting]-&gt;[runnable]： thread.join(); 引发的，其他线程执行完成后进入runnable状态； object.wait(); 引发的，其他线程调用object.notify()或者object.notifyAll()后进入runnable状态； [blocked]-&gt;[runnable]：其他线程退出synchronized{}语句块以后进入runnable状态； 我们再通过表格的形式来看一下线程状态变化过程 方法调用 线程旧状态 线程新状态 备注 new Thread(); new thread.start(); new runnable Thread.yield(); running runnable thread.join(); running waiting Thread.sleep(); running waiting object.wait(); running waiting synchronized(object){} running blocked thread.interrupt(); running dead 子线程执行完成 waiting runnable 外部线程 Sleep()时间到 waiting runnable object.notify()或notifyAll(); waiting runnable 外部线程 退出synchronized代码块 blocked runnable 外部线程 个人理解，waiting状态和blocked状态的区别并不大，粗一点的话可以不区分它们。 相关方法Thread类和Object类相关方法 注意：区分Thread类和Object类的方法，区分静态方法和普通方法。 package java.lang;public class Thread implements Runnable &#123; public static native Thread currentThread(); public static native void yield(); public static native void sleep(long millis) throws InterruptedException; public synchronized void start() &#123; start0(); &#125; public void interrupt() &#123; interrupt0(); &#125; public final void setPriority(int newPriority) &#123; setPriority0(priority = newPriority); &#125; private native void start0(); private native void interrupt0(); private native void setPriority0(int newPriority);&#125; package java.lang;public class Object &#123; public final native void notify(); public final native void notifyAll(); public final native void wait(long timeout) throws InterruptedException;&#125; 以上可以看出，所有的关键方法都是native的，基于系统底层实现的。]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>并发</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程基础篇(3) ThreadPoolExecutor]]></title>
    <url>%2F2018%2F04%2F24%2Fthread-basic-threadpoolexecutor%2F</url>
    <content type="text"><![CDATA[原理理解了ThreadPoolExecutor类的各个参数和内部原理也就理解了线程池机制。 构造参数public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123;&#125; 先来看ThreadPoolExecutor类的参数 参数名称 含义 详解 corePoolSize 核心线程数 当前线程数小于corePoolSize时，会一直创建新线程 maximumPoolSize 最大线程数 最多可以创建maximumPoolSize个线程，超过进入饱和策略 keepAliveTime 空闲时间 当超过corePoolSize时，回收线程时使用 unit 时间单位 配合keepAliveTime一起使用 workQueue 排队策略 最重要，排队策略决定了线程池的处理流程 threadFactory 工厂 创建线程时进行自定义操作 handler 饱和策略 配合workQueue使用，处理线程池满的情况 处理流程 基本逻辑 当线程池里面的线程数小于corePoolSize时，不管当前线程池中的线程是否空闲，都创建新的线程来执行任务，并加入到线程池中；这样随着任务的增加，线程池的线程数会达到corePoolSize个； 达到corePoolSize后，当新任务到来时，会选择空闲的线程来执行； 如果没有空闲线程，进入排队策略，不同的排队策略有不同逻辑； 当核心线程空闲时，会从排队队列中取出任务来执行； 当核心线程没有空闲，并且排队队列满时，创建新线程执行任务，最大不超过maximumPoolSize个； 当达到maximumPoolSize个线程，且都在忙，新任务到来时进入饱和策略，不同的饱和策略有不同逻辑；如果没有配置饱和策略，抛出RejectedExecutionException异常； 当线程数超过corePoolSize后，启动回收逻辑，空闲时间超过keepAliveTime的线程将被回收；回收时不区分核心线程和非核心线程，减少到corePoolSize个后不再回收。 排队策略不同，处理流程也不同，下面分别介绍常见三种排队策略的处理流程：SynchronousQueue、ArrayBlockingQueue和LinkedBlockingQueue。 SynchronousQueue简单说就是没有排队队列，或者队列长度为0，所以通常使用SynchronousQueue作为排队策略时，为避免出现线程执行被拒绝的情况，maximumPoolSize的值会被设置的很大。 ArrayBlockingQueue有界排队队列，必须设置队列长度；当线程数达到corePoolSize时，开始排队；当排队队列满时增加非核心线程直到maximumPoolSize。 LinkedBlockingQueueLinkedBlockingQueue如果不指定队列大小，那么就是无界队列；除非系统资源耗尽，将无限增加队列长度，因此无界队列不存在队列满的情况，也就没有非核心线程、饱和逻辑和线程回收逻辑；也就是说当设置workQueue为LinkedBlockingQueue时，keepAliveTime、unit和handler三个参数失效。 LinkedBlockingQueue也可以设置队列大小，就成了有界队列，和ArrayBlockingQueue的处理逻辑一样。 代码示例背景每个任务开始时输出“run”，结束时输出“exit”，不做具体逻辑，只是sleep1秒钟。 public static class Task implements Runnable &#123; @Override public void run() &#123; LOGGER.info("run"); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; LOGGER.info("exit"); &#125;&#125; 主线程 核心线程数2个，最大线程数4个，保活时间3秒 依次启动6个任务，每启动一个任务后都输出线程池大小 启动任务错误时输出异常信息 6个任务都启动完成后sleep 5秒，退出前再次输出线程池大小 public class ThreadExecutor &#123; private final static Logger LOGGER = LoggerFactory.getLogger(ThreadExecutor.class); public static void main(String[] args) &#123; int coreSize = 2; int maxSize = 4; long time = 3; TimeUnit unit = TimeUnit.SECONDS; ThreadPoolExecutor executor = new ThreadPoolExecutor(coreSize, maxSize, time, unit, queue, handler); for (int i=0; i&lt;6; i++) &#123; Task task = new Task(); try &#123; executor.submit(task); &#125; catch (Exception e) &#123; LOGGER.error(e.getClass().getSimpleName()); &#125; LOGGER.info("poolSize=" + executor.getPoolSize()); &#125; try &#123; Thread.sleep(5000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; LOGGER.info("poolSize=" + executor.getPoolSize()); LOGGER.info("exit"); &#125;&#125; 下面看看不同的workQueue和handler配置下的输出结果 测试结果无界队列LinkedBlockingQueue&lt;Runnable&gt; queue = new LinkedBlockingQueue&lt;&gt;(); 10:57:33:055 [pool-2-thread-1] run10:57:33:055 [main] poolSize=110:57:33:055 [main] poolSize=210:57:33:055 [main] poolSize=210:57:33:055 [pool-2-thread-2] run10:57:33:055 [main] poolSize=210:57:33:055 [main] poolSize=210:57:33:055 [main] poolSize=210:57:34:068 [pool-2-thread-2] exit10:57:34:068 [pool-2-thread-1] exit10:57:34:068 [pool-2-thread-1] run10:57:34:068 [pool-2-thread-2] run10:57:35:081 [pool-2-thread-1] exit10:57:35:081 [pool-2-thread-2] exit10:57:35:081 [pool-2-thread-1] run10:57:35:081 [pool-2-thread-2] run10:57:36:082 [pool-2-thread-1] exit10:57:36:082 [pool-2-thread-2] exit10:57:38:056 [main] poolSize=210:57:38:056 [main] exit 从日志中可以看出 当线程池达到核心线程数2后，一直保持在核心线程数不变 pool-2-thread-1和pool-2-thread-2顺序从队列中取出任务依次执行 有界队列ArrayBlockingQueue&lt;Runnable&gt; queue = new ArrayBlockingQueue&lt;&gt;(2);// LinkedBlockingQueue&lt;Runnable&gt; queue = new LinkedBlockingQueue&lt;&gt;(2); 11:01:23:147 [main] poolSize=111:01:23:147 [pool-2-thread-1] run11:01:23:147 [main] poolSize=211:01:23:147 [main] poolSize=211:01:23:147 [pool-2-thread-2] run11:01:23:147 [main] poolSize=211:01:23:147 [main] poolSize=311:01:23:147 [main] poolSize=411:01:23:147 [pool-2-thread-3] run11:01:23:147 [pool-2-thread-4] run11:01:24:147 [pool-2-thread-1] exit11:01:24:147 [pool-2-thread-1] run11:01:24:147 [pool-2-thread-2] exit11:01:24:147 [pool-2-thread-2] run11:01:24:147 [pool-2-thread-3] exit11:01:24:147 [pool-2-thread-4] exit11:01:25:158 [pool-2-thread-2] exit11:01:25:158 [pool-2-thread-1] exit11:01:28:154 [main] poolSize=211:01:28:154 [main] exit 从日志中可以看出 当队列（2个）满以后，增加了非核心线程pool-2-thread-3和pool-2-thread-4 核心线程pool-2-thread-1和pool-2-thread-2执行完第一个任务后，又从队列中取出第二个任务执行 主线程退出前线程池大小又回到了核心线程数，说明空闲线程已经被释放 同步移交+AbortSynchronousQueue&lt;Runnable&gt; queue = new SynchronousQueue&lt;&gt;();RejectedExecutionHandler handler = new ThreadPoolExecutor.AbortPolicy(); 11:07:26:130 INFO [main] poolSize=111:07:26:130 INFO [pool-2-thread-1] run11:07:26:132 INFO [main] poolSize=211:07:26:132 INFO [main] poolSize=311:07:26:132 INFO [pool-2-thread-2] run11:07:26:133 INFO [main] poolSize=411:07:26:133 ERROR [main] RejectedExecutionException11:07:26:133 INFO [main] poolSize=411:07:26:134 ERROR [main] RejectedExecutionException11:07:26:134 INFO [main] poolSize=411:07:26:135 INFO [pool-2-thread-3] run11:07:26:135 INFO [pool-2-thread-4] run11:07:27:143 INFO [pool-2-thread-3] exit11:07:27:143 INFO [pool-2-thread-2] exit11:07:27:143 INFO [pool-2-thread-4] exit11:07:27:143 INFO [pool-2-thread-1] exit11:07:31:150 INFO [main] poolSize=211:07:31:150 INFO [main] exit 从日志中可以看出 当线程数到达最大线程数4个以后，再提交的任务抛出了RejectedExecutionException异常 所以与前面的结果不同，这次只执行了4个任务 最后空闲线程被回收，线程数保持在2个 AbortPolicy是默认的饱和策略 以下已空队列为例，更换饱和策略 同步移交+DiscardSynchronousQueue&lt;Runnable&gt; queue = new SynchronousQueue&lt;&gt;();RejectedExecutionHandler handler = new ThreadPoolExecutor.DiscardPolicy(); 11:12:20:113 INFO [pool-2-thread-1] run11:12:20:113 INFO [main] poolSize=111:12:20:113 INFO [main] poolSize=211:12:20:113 INFO [pool-2-thread-2] run11:12:20:113 INFO [main] poolSize=311:12:20:113 INFO [main] poolSize=411:12:20:113 INFO [pool-2-thread-3] run11:12:20:113 INFO [main] poolSize=411:12:20:113 INFO [main] poolSize=411:12:20:113 INFO [pool-2-thread-4] run11:12:21:128 INFO [pool-2-thread-4] exit11:12:21:128 INFO [pool-2-thread-2] exit11:12:21:128 INFO [pool-2-thread-3] exit11:12:21:128 INFO [pool-2-thread-1] exit11:12:25:119 INFO [main] poolSize=211:12:25:119 INFO [main] exit 对比上面的日志可以发现 同样也是只执行了4个任务 区别在于没有抛出异常，也就是说Discard策略直接拒绝，来异常都不给，没啥用 同步移交+CallerRunSynchronousQueue&lt;Runnable&gt; queue = new SynchronousQueue&lt;&gt;();RejectedExecutionHandler handler = new ThreadPoolExecutor.CallerRunsPolicy(); 11:18:11:432 INFO [pool-2-thread-1] run11:18:11:432 INFO [main] poolSize=111:18:11:434 INFO [main] poolSize=211:18:11:434 INFO [pool-2-thread-2] run11:18:11:434 INFO [main] poolSize=311:18:11:435 INFO [main] poolSize=411:18:11:435 INFO [main] run11:18:11:435 INFO [pool-2-thread-3] run11:18:11:435 INFO [pool-2-thread-4] run11:18:12:447 INFO [pool-2-thread-4] exit11:18:12:447 INFO [main] exit11:18:12:447 INFO [pool-2-thread-3] exit11:18:12:447 INFO [pool-2-thread-2] exit11:18:12:447 INFO [pool-2-thread-1] exit11:18:12:447 INFO [main] poolSize=411:18:12:447 INFO [main] run11:18:13:448 INFO [main] exit11:18:13:448 INFO [main] poolSize=411:18:18:454 INFO [main] poolSize=211:18:18:454 INFO [main] exit 从日志中可以看出 当线程数到达最大线程数4个以后，第5个任务开始在main线程中执行 CallerRunsPolic保证了线程不会被丢弃，但交给主线程运行没有起到线程池的作用，应该也不常用 实战Executorspackage java.util.concurrent;public class Executors &#123; public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;())); &#125; public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()); &#125; public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;()); &#125; &#125; Executors类提供了常用线程池的创建方法，不过不建议使用Executors来创建线程池，因为这会隐藏最终创建ThreadPoolExecutor类的参数，还是建议手工构造ThreadPoolExecutor，显示指定参数。下面详细看看三个预定义的线程池： SingleThread，顾名思义，线程池的核心和最大线程数都是1，无界排队策略；也就是说这个线程池中只有1个线程，其他并发线程排队等待，线程池一个一个来处理，简单，但是效率比较低； FixedThread，线程池的核心线程数与最大线程数保持一致，无界排队策略；也就是说这个线程池中没有非核心线程，最多可以同时处理N个任务，其他任务排队等待；SingleThread可以看作N=1的FixedThread； CachedThread，核心线程数0，最大线程数无穷大，无排队队列，保活时间60秒；也就是说这个线程池中的线程数是动态变化的，当有新任务时就创建新线程来处理（当前线程都在忙），处理完成后1分钟回收线程；如果没有任务，线程数就是0，如果任务非常多，线程数无限增加，直到耗尽系统资源。 以上可以看出，Executors默认提供的几种线程池比较极端，实战中需要自定义ThreadPoolExecutor。 核心线程数虽然排队策略看上去比较复杂，但我认为ThreadPoolExecutor最重要的参数是核心线程数；因为考虑到不拒绝任何任务，我们可以使用LinkedBlockingQueue实现无界队列，这样其他参数基本就都失效了，而核心线程数即使当前没有任务也要保留，就变得异常重要的。 确定核心线程数，一般的思路是根据任务性质来判断的。如果是计算密集型任务，那么通常核心线程数设置为CPU个数+1，通过Runtime.getRuntime().availableProcessors();可以读取CPU个数。如果是I/O密集型任务，那么中断会多一些，核心线程数也可以多一些，一般可以设置为CPU个数的2倍。 Apache MINA 的核心线程数设置为CPU个数+1s=>start: 开始 e=>end: 结束 condCore=>condition: 小于核心线程数? condMax=>condition: 小于最大线程数? addCore=>operation: 增加核心线程 addNormal=>operation: 增加非核心线程 full=>operation: 饱和逻辑处理 s->condCore condCore(yes, right)->addCore condCore(no)->condMax condMax(yes, right)->addNormal condMax(no)->full addNormal->e addCore->e full->e{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12,"theme":"simple"} var code = document.getElementById("flowchart-0-code").value; var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-0-options").value)); var diagram = flowchart.parse(code); diagram.drawSVG("flowchart-0", options);s=>start: 开始 e=>end: 结束 condCore=>condition: 小于核心线程数? condQueue=>condition: 队列未满? condMax=>condition: 小于最大线程数? addCore=>operation: 增加核心线程 addNormal=>operation: 增加非核心线程 addQueue=>operation: 排队等待执行 full=>operation: 饱和逻辑处理 s->condCore condCore(yes, right)->addCore condCore(no)->condQueue condQueue(yes, right)->addQueue condQueue(no)->condMax condMax(yes, right)->addNormal condMax(no)->full addQueue->e addNormal->e addCore->e full->e{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12,"theme":"simple"} var code = document.getElementById("flowchart-1-code").value; var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-1-options").value)); var diagram = flowchart.parse(code); diagram.drawSVG("flowchart-1", options);s=>start: 开始 e=>end: 结束 condCore=>condition: 小于核心线程数? addCore=>operation: 增加核心线程 addQueue=>operation: 排队等待执行 s->condCore condCore(yes)->addCore condCore(no)->addQueue addQueue->e addCore->e{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12,"theme":"simple"} var code = document.getElementById("flowchart-2-code").value; var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-2-options").value)); var diagram = flowchart.parse(code); diagram.drawSVG("flowchart-2", options);]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>并发</tag>
        <tag>线程</tag>
        <tag>线程池</tag>
        <tag>排队策略</tag>
        <tag>饱和策略</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程基础篇(2) 线程池]]></title>
    <url>%2F2018%2F04%2F24%2Fthread-basic-threadpool%2F</url>
    <content type="text"><![CDATA[任务调度任务是一组逻辑工作单元，线程则是任务异步执行的机制。前面说过，实战中我们不会直接调用Thread类的start()方法来启动线程，那么线程应该如何启动呢？ Executor使用Executor.execute(task);来替代new Thread(task).start(); package java.util.concurrent;public interface Executor &#123; void execute(Runnable command);&#125; Executor将任务提交给线程池来处理，线程池的处理是异步的，任务会交给新的线程来执行，本地线程可以继续做其他事情。 ExecutorServiceExecutor只有一个没有返回值的接口execute()，为了更好的控制线程的行为，并行包中为我们提供了功能更强大的ExecutorService，实际使用过程中，更多使用的是ExecutorService的接口。 package java.util.concurrent;public interface ExecutorService extends Executor &#123; &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task); Future&lt;?&gt; submit(Runnable task); &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result); void shutdown(); List&lt;Runnable&gt; shutdownNow();&#125; 下面详细看一下ExecutorService的几个接口 submit提交任务有三个接口，区别在于任务类实现了哪个接口，以及是否需要读取返回结果 Callable：下面的例子用来计算1+2+…+N的和，任务完成后返回计算结果 public class Task implements Callable&lt;Integer&gt; &#123; private int count = 0; public Task(int count) &#123; this.count = count; &#125; @Override public Integer call() throws Exception &#123; int sum = 0; for (int i=1; i&lt;=count; i++) &#123; sum += i; &#125; LOGGER.info("done"); return sum; &#125;&#125; 再来看看任务调度，通过future.get()可以获取返回的计算结果55。future.get()是一个阻塞方法，如果task线程执行需要很长时间，那么main线程将会停在这里一直到task线程处理完成。 ExecutorService executor = Executors.newSingleThreadExecutor();Task task = new Task(10);Future&lt;Integer&gt; future = executor.submit(task);Integer result = future.get();LOGGER.info("result=" + result); 这里和new Thread().start()没有本质的区别，都达到相同的效果，区别在于这里使用了线程池。 Runnable：完成相同的功能，由于run()方法没有返回值，我们在构造Task对象时增加了Data参数 public class Task implements Runnable &#123; private final Data data; private int count = 0; public Task(int count, Data data) &#123; this.count = count; this.data = data; &#125; @Override public void run() &#123; int sum = 0; for (int i=1; i&lt;=count; i++) &#123; sum += i; &#125; data.setResult(sum); &#125;&#125;public static class Data &#123; private Integer result; public Integer getResult() &#123; return result; &#125; public void setResult(Integer result) &#123; this.result = result; &#125; &#125; 再来看看任务调度，通过future.get()可以获得Data对象，然后从Data对象中获取计算结果55。 这里调用的是submit(Runnable task, T result)方法，如果调用submit(Runnable task)方法是无法获取到计算结果的，future.get()返回null，只能表明计算任务已经完成。 ExecutorService executor = Executors.newSingleThreadExecutor();Data data = new Data();Task task = new Task(10, data);Future&lt;Data&gt; future = executor.submit(task, data);Integer result = future.get().getResult();LOGGER.info("result=" + result); 这里重点演示submit()的用法，线程池使用了最简单的SingleThreadExecutor shutdownshutdown()方法在关闭ExecutorService之前等待提交的任务执行完成，shutdownNow()方法阻止开启新的任务并且尝试停止当前正在执行的线程。 下面通过例子验证一下 定义任务：没有实际逻辑，只是sleep 1秒钟，任务开始和结束后输出日志 public class Task implements Runnable &#123; @Override public void run() &#123; LOGGER.info("run"); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; LOGGER.error(e.getMessage()); &#125; LOGGER.info("done"); &#125;&#125; 主线程：一共5个任务，为方便观察每提交一个任务后等待100毫秒；当提交完成3个任务后，分别调用shutdown()和shutdownNow()关闭线程池，然后观察日志输出 ExecutorService executor = new ThreadPoolExecutor(5, 10, 10, TimeUnit.SECONDS, new LinkedBlockingDeque&lt;&gt;(5), new ThreadPoolExecutor.AbortPolicy());for (int i=0; i&lt;5; i++) &#123; Task task = new Task(); try &#123; executor.submit(task); &#125; catch (Exception e) &#123; LOGGER.error(e.getMessage()); &#125; Thread.sleep(100); if (i == 2) &#123; executorService.shutdown(); //executorService.shutdownNow(); &#125;&#125;LOGGER.info("done"); shutdown结果 17:34:01:347 INFO [pool-2-thread-1] run17:34:01:456 INFO [pool-2-thread-2] run17:34:01:566 INFO [pool-2-thread-3] run17:34:01:675 ERROR [main] Task rejected from ThreadPoolExecutor@36b4cef0[Shutting down]17:34:01:784 ERROR [main] Task rejected from ThreadPoolExecutor@36b4cef0[Shutting down]17:34:01:894 INFO [main] done17:34:02:347 INFO [pool-2-thread-1] done17:34:02:456 INFO [pool-2-thread-2] done17:34:02:566 INFO [pool-2-thread-3] done 从日志中可以看出，shutdown()后再submit()任务时抛出了异常，提示正在“Shutting down”；正确启动了三个任务，这三个任务在shutdown()后继续执行，正常结束。 shutdownNow结果 17:37:00:663 INFO [pool-2-thread-1] run17:37:00:756 INFO [pool-2-thread-2] run17:37:00:866 INFO [pool-2-thread-3] run17:37:00:975 ERROR [pool-2-thread-3] sleep interrupted17:37:00:975 ERROR [pool-2-thread-2] sleep interrupted17:37:00:975 ERROR [pool-2-thread-1] sleep interrupted17:37:00:975 INFO [pool-2-thread-3] done17:37:00:975 INFO [pool-2-thread-1] done17:37:00:975 INFO [pool-2-thread-2] done17:37:00:975 ERROR [main] Task rejected from ThreadPoolExecutor@36b4cef0[Terminated]17:37:01:085 ERROR [main] Task rejected from ThreadPoolExecutor@36b4cef0[Terminated]17:37:01:194 INFO [main] done 首先，shutdownNow()后再submit()的任务也抛出了异常，但提示信息有差别；另外，虽然也输出了”donw”的信息，但是正确启动的三个任务并没有正常结束（时间不到1秒），日志显示中断了sleep操作，导致线程提前结束。 综上，我们应该使用shutdown()来关闭线程池。这也是web服务可以优雅关闭的基础，当tomcat接收到网络请求后，会提交给线程池进行处理，如果我们通知tomcat关闭服务，那么只需调用线程池的shutdown()方法，这样新的网络请求就没有线程来处理了（需要处理异常），而且正在工作的线程可以正常完成自己的工作后结束。 ThreadPoolExecutor平时我们最常用到的是ThreadPoolExecutor类，它实现了ExecutorService接口。 package java.util.concurrent;public class ThreadPoolExecutor extends AbstractExecutorService &#123;&#125; package java.util.concurrent;public abstract class AbstractExecutorService implements ExecutorService &#123;&#125; 我们知道，Executor接口含有execute()方法，ExecutorService接口含有submit()方法，这样就有两种方法提交任务给线程池ThreadPoolExecutor执行。当我们不关注任务的返回结果时，可以通过execute()方法提交任务；当我们需要拿到任务的返回结果时，就必须通过submit()方法提交任务了。 除了get()方法可以得到返回结果以外，Future类还提供了其他方法来查询线程的执行状态，所以当我们关系任务的执行状态时，也应该使用submit()，个人建议可以都使用submit()来提交任务。另外，submit()最后还是执行的execute()，只不过执行前做了Future的准备工作。 public abstract class AbstractExecutorService implements ExecutorService &#123; public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) &#123; if (task == null) throw new NullPointerException(); RunnableFuture&lt;T&gt; ftask = newTaskFor(task); execute(ftask); return ftask; &#125; protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Callable&lt;T&gt; callable) &#123; return new FutureTask&lt;T&gt;(callable); &#125; &#125;public interface RunnableFuture&lt;V&gt; extends Runnable, Future&lt;V&gt; &#123; void run();&#125;public class FutureTask&lt;V&gt; implements RunnableFuture&lt;V&gt; &#123; public V get() throws InterruptedException, ExecutionException &#123; int s = state; if (s &lt;= COMPLETING) s = awaitDone(false, 0L); return report(s); &#125; &#125; TODO: Future原理]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>并发</tag>
        <tag>线程</tag>
        <tag>线程池</tag>
        <tag>任务调度</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程基础篇(1) 线程]]></title>
    <url>%2F2018%2F04%2F24%2Fthread-basic-thread%2F</url>
    <content type="text"><![CDATA[进程与线程提到线程大家就会想起进程，先来看看进程和线程的联系和区别。 什么是进程？ 通俗的讲，进程就是操作系统中运行的程序，当你的程序代码被操作系统加载到内存中运行的时候，它就成为了一个进程。以Linux系统为例，每个进程有自己的进程号(pid)，有独立的地址空间。每个进程有独立的地址空间意味着，一个进程不能够访问到另外一个进程的内存空间，内存地址空间是进程私有的。 进程间可以通过共享内存通信，共享内存空间并非进程私有的。 什么是线程? 线程理解起来比进程要抽象一些。线程与操作系统的任务调用相关，可以简单认为线程是操作系统任务调度的基本单位。现在的大部分操作系统采用的都是时间片和抢占式的任务调用机制，当多个任务共享CPU资源时，一个任务执行一段时间后被挂起(这个任务执行的这段时间就称为时间片)，切换到另外一个任务开始执行。通常任务调度的单位不是进程，而是线程，也就是说，线程是进程可以独立交给CPU执行的一个任务。线程有自己的栈和程序计数器。 这样，一个进程可以包含多个线程，每个线程作为一个任务交给操作系统调用。实际上，Java进程至少要包含一个线程，如果我们没有显示的创建线程，main()方法是在[main]线程中执行的。对于Java进程来说，每个线程有自己的栈空间，多个线程共享进程的堆空间。 JAVA线程创建线程通常有三种创建线程的方法：继承Thread类，实现Runnable接口和实现Callable接口。继承Thread类和实现Runnable接口都需要实现run()方法，实现Callable接口需要实现call()方法。以下为示例代码。 可以认为run()方法和main()方法类似，都是程序的入口。main()是Java进程主线程的程序入口，run()是一个新线程的程序入口。 Thread类 public class Task extends Thread &#123; @Override public void run() &#123; int sum = 0; for (int i=1; i&lt;=10; i++) &#123; sum += i; &#125; System.out.println("sum=" + sum); &#125;&#125; Runnable接口 注意，run()方法没有返回值，且不抛出异常 public class Task implements Runnable &#123; @Override public void run() &#123; int sum = 0; for (int i=1; i&lt;=10; i++) &#123; sum += i; &#125; System.out.println("sum=" + sum); &#125;&#125; Callable接口 注意，call()方法有返回值，而且可以抛出异常，这是Callable和Runnable最重要的区别 public class Task implements Callable&lt;Integer&gt; &#123; @Override public Integer call() throws Exception &#123; int sum = 0; for (int i=1; i&lt;=10; i++) &#123; sum += i; &#125; return sum; &#125;&#125; 启动线程继承Thread类的，直接调用start()方法就可以启动线程； public class Task extends Thread &#123;&#125;Task task = new Task();task.start(); 实现Runnable接口的，需要new Thread(task).start()启动线程； public class Task implements Runnable &#123;&#125;Task task = new Task();new Thread(task).start(); 注意：虽然方法名字叫做start()，但是这个方法并不能保证线程立即开始执行，start()操作只能保证线程进入runnable状态，具体什么时间能够被执行由操作系统控制。 也可以使用匿名内部类 Thread task = new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println("run"); &#125;&#125;);task.start(); 实现Callable接口的，需要new Thread(new FutureTask&lt;&gt;(task)).start()启动线程。 FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;&gt;(new Callable&lt;Integer&gt;() &#123; @Override public Integer call() throws Exception &#123; int sum = 0; for (int i=1; i&lt;=10; i++) &#123; sum += i; &#125; return sum; &#125;&#125;);new Thread(futureTask).start(); 注意：虽然直接调用run()方法看上去也可以有正确的结果，但是这是在当前线程内执行的，没有启动一个新的线程来执行。 实战中，我们通常不会直接使用new Thread().start()来启动线程，而是交给Executor去处理。因为每次new一个新的线程显然是低效的，放到线程池里执行是更好的选择。同样原因，实际编码中很少使用继承Thread类的办法来创建线程，因为Executor只接收接口。并且由于Java不支持多重继承，实现Runnable接口是比继承Thread类更好的设计。 等待线程有时我们需要在主线程中等待新线程执行完成，并获得执行结果，这个时候可以使用join()方法。调用join()方法后当前线程被挂起，直到join线程执行完成后再被唤醒。 public class ThreadJoin &#123; private final static Logger LOGGER = LoggerFactory.getLogger(ThreadJoin.class); public static void main(String[] args) throws Exception &#123; Task1 task1 = new Task1(); Thread thread1 = new Thread(task1); thread1.start(); thread1.join(); LOGGER.info("done"); &#125; public static class Task1 implements Runnable &#123; @Override public void run() &#123; int sum = 0; for (int i=1; i&lt;=10; i++) &#123; sum += i; &#125; LOGGER.info("sum=" + sum); &#125; &#125;&#125; 上面为示例代码，执行结果如下 13:40:15:944 INFO [Thread-1] sum=5513:40:15:944 INFO [main] done 如果去掉thread1.join()，那么执行结果如下 13:41:21:690 INFO [main] done13:41:21:690 INFO [Thread-1] sum=55 通常，Runnable接口需要调用join()方法，Callable接口就不需要了，直接调用FutureTask的get()方法就可以获取执行结果。FutureTask.get()方法起到和join()相同的效果，当前线程阻塞，直到子线程执行完成并返回执行结果，以下为示例。 public class ThreadJoin &#123; private final static Logger LOGGER = LoggerFactory.getLogger(ThreadJoin.class); public static void main(String[] args) throws Exception &#123; Task2 task2 = new Task2(); FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;&gt;(task2); Thread thread2 = new Thread(futureTask); thread2.start(); LOGGER.info(futureTask.get().toString()); &#125; public static class Task2 implements Callable&lt;Integer&gt; &#123; @Override public Integer call() throws Exception &#123; int sum = 0; for (int i=1; i&lt;=10; i++) &#123; sum += i; &#125; return sum; &#125; &#125;&#125; 以上代码开启一个子线程计算1到10的和，执行结果如下；FutureTask.get()方法是同步等待的，等待Task的call()方法执行完成才返回。 13:47:02:066 INFO [main] 55 中断线程有时我们可能由于某种原因中断子线程任务的执行，在其执行完成前退出。通常用两种方法：一是自己设置标志位，根据标志位退出；二是调用interrupt()方法。 标志位 先来看使用标志位退出的代码 public class ThreadStop &#123; private final static Logger LOGGER = LoggerFactory.getLogger(ThreadStop.class); public static void main(String[] args) &#123; Task task = new Task(); Thread thread = new Thread(task); thread.start(); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; task.stop(); &#125; public static class Task implements Runnable &#123; private boolean stop = false; @Override public void run() &#123; while (!stop) &#123; LOGGER.info("run"); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; LOGGER.info("stop"); &#125; public void stop() &#123; stop = true; &#125; &#125;&#125; 执行结果如下，在执行过程中不断判断标志位stop，当发现stop被置为true后退出。 14:02:51:483 INFO [Thread-1] run14:02:52:483 INFO [Thread-1] run14:02:53:496 INFO [Thread-1] stop 中断 通过标志位退出线程有自己的局限性，如果线程调用了阻塞方法（例如wait()），并且无法被唤醒，那么就无法通过判断标志位来实现退出了。这种情况下，我们可以调用Thread的interrupt()方法中断阻塞方法，实现退出。 public class ThreadStop &#123; private final static Logger LOGGER = LoggerFactory.getLogger(ThreadStop.class); public static void main(String[] args) &#123; Task task = new Task(); Thread thread = new Thread(task); thread.start(); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; thread.interrupt(); &#125; public static class Task implements Runnable &#123; @Override public void run() &#123; while (true) &#123; if (Thread.currentThread().isInterrupted()) &#123; LOGGER.info("interrupted"); break; &#125; LOGGER.info("run"); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; LOGGER.error("interrupted in sleep"); break; &#125; &#125; &#125; &#125;&#125; 执行结果如下，thread.interrupt()方法中断了阻塞的Thread.sleep()方法，抛出InterruptedException异常；线程捕获异常后退出，注意这里需要手动退出。 14:11:43:574 INFO [Thread-1] run14:11:44:580 ERROR [Thread-1] interrupted in sleep14:11:44:580 INFO [Thread-1] interrupted 线程属性线程名通过线程名可以区分每一个线程，输出线程名到日志中对于分析多线程问题是非常有帮助的。 设置线程名称 thread.setName("threadName"); 读取当前线程的线程名称，注意使用Thread.currentThread()获取当前线程对象的方法 Thread.currentThread().getName(); 当然，如果线程实现的方式是从Thread类继承，那么当然可以调用this.getName()方法获取到线程名；但是，更多的场景是实现了Runnable或者Callable接口，这个时候this指向的就不是Thread对象了，所以使用Thread.currentThread().getName();获取线程名是更通用的方法。 扩展一下，通过Thread的类的静态方法可以得到当前所有active的线程，有兴趣可以执行一下下面的代码看看输出结果 public class ThreadBasic &#123; public static void main(String[] args) &#123; int threadCount = Thread.activeCount(); Thread [] threadList = new Thread[threadCount]; // 枚举所有活动的线程 int n = Thread.enumerate(threadList); for (int i=0; i&lt;n; i++) &#123; System.out.println(threadList[i].getName()); &#125; &#125;&#125; 按照我们的理解，输出的应该是”main”，因为这时候只有一个主线程。通过命令行运行，或者在IDEA中debug确实是预期的结果。但是如果在IDEA中run的话，会多一个”Monitor Ctrl-Break”线程。 线程优先级创建一个线程以后，可以设置线程的优先级。线程优先级是从1到10的数字，数字越大优先级越高，常用的优先级有MIN_PRIORITY、MAX_PRIORITY和NORMAL_PRIORITY三种，其中默认值为NORMAL_PRIORITY public final static int MIN_PRIORITY = 1;public final static int NORM_PRIORITY = 5;public final static int MAX_PRIORITY = 10; 以下为示例代码 MyThread thread = new MyThread();thread.setPriority(Thread.MAX_PRIORITY);thread.start(); 理论上优先级高的线程先被执行，但不一定绝对这样，具体情况要看操作系统如何调度。总体上，优先级高的线程有更多的机会被执行。 守护线程通过设置daemon属性可以将一个线程设置为守护线程，默认值为false，也就是非守护线程，通常称为用户线程。 thread.setDaemon(true); 守护线程和用户线程的差别不大，主要区别在于主线程结束时：如果主线程结束时，已经没有活动的用户线程，那么守护线程自动退出。平时我们很少会用到守护线程，GC线程是典型的守护线程，当其他线程都已经退出了，只保留一个GC线程也没有什么意义了。 public class ThreadDaemon &#123; public static void main(String[] args) &#123; DaemonThread daemonThread = new DaemonThread(); daemonThread.start(); &#125; public static class DaemonThread extends Thread &#123; public DaemonThread() &#123; this.setName("DaemonThread"); this.setDaemon(true); &#125; @Override public void run() &#123; while (true) &#123; System.out.println(this.getName() + " - I'm alive."); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;&#125; 在上面的例子中，如果setDaemon(false)，当主线程结束退出后子线程会一直运行，输出“I’m alive.”；如果setDaemon(true)，当主线程结束退出后由于已经没有其他用户线程，子线程自动退出了。运行一下，你会发现甚至连一个“I’m alive.”都没有输出出来，这是因为调用完daemonThread.start()主线程就退出了，这个时候daemonThread还没有抢到时间片，等daemonThread抢到时间片的时候发现已经没有非守护线程了，就直接退出了。]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>并发</tag>
        <tag>线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RocketMQ(3) 开发]]></title>
    <url>%2F2018%2F04%2F23%2Frocketmq-dev%2F</url>
    <content type="text"><![CDATA[编码配置在pom.xml引入rocketmq-client模块和rocketmq-common模块，选择合适的版本，这里我用的是3.1.4版本 https://github.com/apache/rocketmq-externals/tree/master/rocketmq-spring-boot-starter &lt;!-- rocket mq --&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.rocketmq&lt;/groupId&gt; &lt;artifactId&gt;rocketmq-client&lt;/artifactId&gt; &lt;version&gt;3.1.4&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.rocketmq&lt;/groupId&gt; &lt;artifactId&gt;rocketmq-common&lt;/artifactId&gt; &lt;version&gt;3.1.4&lt;/version&gt;&lt;/dependency&gt; 发送消息 发送消息比较简单，首先创建消息生产者，指定组；然后启动生产者； 当需要发消息时调用生产者的send()方法即可，消息对象需要指定主题、标签、主键、消息体内容等信息；通过send()方法的返回值同步判断是否发送成功； 发送失败将会自动重试，重试次数和超时时间可以在创建生产者时进行设置。 package cn.waterlu.test.rocketmq; import com.alibaba.rocketmq.client.producer.DefaultMQProducer;import com.alibaba.rocketmq.client.producer.SendResult;import com.alibaba.rocketmq.common.message.Message;public class TestRocketMq &#123; @Test public void testProducer() &#123; // 生产者组的名称 String groupName = "group_producer"; // NameServer地址 String nameServer = "10.10.10.163:9876"; // 如果发送失败，重试次数 int retryTimes = 3; // 发送超时时间（毫秒） long timeout = 10000; // 创建Producer并进行配置 DefaultMQProducer producer = new DefaultMQProducer(groupName); producer.setNamesrvAddr(nameServer); producer.setRetryTimesWhenSendFailed(retryTimes); producer.setSendMsgTimeout(timeout); // 启动Producer，可复用 producer.start(); // 创建消息 // topic String 消息主题 // tag String 消息标签（可空） // key String 消息主键 // body byte [] 消息体 Message message = new Message(topic, tag, key, body); // 发送消息 SendResult sendResult = producer.send(message); SendStatus status = sendResult.getSendStatus(); // 判断发送是否成果 if (status.equals(SendStatus.SEND_OK)) &#123; logger.info("发送成功"); &#125; else &#123; logger.warn("发送失败"); &#125; &#125;&#125; 接收消息 消费消息与生产消息类似，需要首先创建消费者，设置参数，最后启动消费者消费消息； 消费者和生产者一样需要指定NamerServer地址和消费组名称； 消费者启动前需要指定订阅的主题和标签，进行消息过滤； 消费者需要注册收到消息后的处理方法； 消费者分为Pull和Push两种模式，其本质都是拉去消息； Push模式把轮询过程封装了，对用户来说，感觉消息是被推送过来的； Pull模式用户需要自己拉起消息。 package cn.waterlu.test.rocketmq;import com.alibaba.rocketmq.client.consumer.DefaultMQPushConsumer;import com.alibaba.rocketmq.client.consumer.ConsumeFromWhere;public class TestRocketMq &#123; @Test public void testConsumer() &#123; // 消费组的名字 String consumerGroupName = "group_consumer"; // NameServer地址 String nameServer = "10.10.10.163:9876"; // 创建消息者 DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(consumerGroupName); consumer.setNamesrvAddr(nameServer); // 三个选项，区别在新订阅组第一次启动时的行为不同，以后都是继续上一次的位置进行消费 // CONSUME_FROM_LAST_OFFSET 新订阅组第一次启动从队列的最后开始消费 // CONSUME_FROM_FIRST_OFFSET 新订阅组第一次启动从队列的头开始消费 // CONSUME_FROM_TIMESTAMP 新订阅组第一次启动从指定时间点开始消费 consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_LAST_OFFSET); // 指定订阅的主题和标签，主题和标签都是String // 多个标签中间通过"||"分隔，例如："pay||order||clear" consumer.subscribe(topic, tags); // 注册消息处理的回掉方法 consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; list, ConsumeConcurrentlyContext consumeConcurrentlyContext) &#123; // consumeMessageBatchMaxSize默认值为1，所以List里面只有一个元素 MessageExt messageExt = list.get(0); // 主题 String topic = messageExt.getTopic(); // 标签 String tag = messageExt.getTags(); // 消息ID，RocketMQ自动生成 String messageID = messageExt.getMsgId(); // 消息主键，业务自己指定 String messageKey = messageExt.getKeys(); // 消息内容 byte[] messageBody = messageExt.getBody(); // CONSUME_SUCCESS 表示消息消费成功 // RECONSUME_LATER 表示消息消费失败，RocketMQ过一段时间后会重新投递消息 return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; //return ConsumeConcurrentlyStatus.RECONSUME_LATER; &#125; &#125; // 启动消费组 consumer.start(); &#125;&#125;]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>mq</tag>
        <tag>rocketmq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RocketMQ(2) 部署与维护]]></title>
    <url>%2F2018%2F04%2F22%2Frocketmq-deploy%2F</url>
    <content type="text"><![CDATA[由于用到了事务消息功能，所以我使用的是3.1.4版本，这是一个非常老的版本，没有使用最新的版本。RocketMQ从4.0版本开始在Apche孵化，现在最新的版本是4.2.0，预计4.3.0版本可能会增加事务消息功能。3.x的最新稳定版本是3.5.8。 RocketMQ官方版本V3.0.4~3.1.4基于文件系统实现了事务消息，已开源；V3.1.5~4.2.0基于数据库实现事务消息，未开源。 部署这里 有V3.1.4版本的源码，是作为V3.1.9的一个fork的分支存在的，以下操作都以V3.1.4版本为例，最新版本可能会不一样。 打包 环境准备：安装rocketmq前需要先安装jdk，git和maven 编译打包 $ cd rocketmq-3.1.4$ mvn -Dmaven.test.skip=true clean package install assembly:assembly -U$ cd ./target/alibaba-rocketmq-3.1.4/alibaba-rocketmq$ ls -ldrwxrwxr-x 2 lu lu 4096 Jan 20 16:34 benchmarkdrwxrwxr-x 2 lu lu 4096 Jan 20 16:34 bindrwxrwxr-x 5 lu lu 4096 Jan 20 16:34 confdrwxrwxr-x 2 lu lu 4096 Jan 20 16:34 lib-rw-rw-r-- 1 lu lu 10275 Jan 20 16:34 LICENSE.txtdrwxrwxr-x 2 lu lu 4096 Jan 20 16:34 test 启动由于默认启动参数配置的内存比较大，我们一般会先调整一下内存参数，具体为修改apache-rocketmq/bin目录下的runserver.sh和runbroker.sh脚本，修改其中的JAVA_OPT，将Xms/Xmx/Xmn等内存参数调整到合适大小 如上图所示，RocketMQ由NameServer和BrokerServer组成，其中NameServer用做注册中心，Broker启动后注册到NameServer，Producer和Consumer与NameServer通信，获取Broker的地址；Producer发送消息给Broker，Broker完成消息存储，并负责将消息投递给Consumer。 首先，启动NameServer，NameServer的服务端口为9876 $ cd target/alibaba-rocketmq-3.1.4/alibaba-rocketmq$ nohup sh bin/mqnamesrv &gt; /dev/null 2&gt;&amp;1 &amp; 然后，启动BrokerServer，其中-n参数为NameServer的地址和端口，Broker的服务端口为10911和10912，10911供Producer和Consumer通信使用，10912供Broker集群通信使用 $ cd target/alibaba-rocketmq-3.1.4/alibaba-rocketmq$ nohup sh bin/mqbroker -n localhost:9876 &gt; /dev/null 2&gt;&amp;1 &amp; Broker启动时将自己的地址和端口注册到NameServer上，但存在多网卡时，Broker有可能获取不到正确的IP地址，最后导致Producer和Consumer连接不到Broker上，出现类似下面这样的错误。 connect to &lt;172.17.0.1:10911&gt; failed 这种情况下，我们需要在Broker启动时指定IP地址，具体方法为配置一个启动参数文件broker.properties，内容如下（可以从conf/2m-noslave/broker-a.properties复制并修改）： brokerClusterName=DefaultClusterbrokerName=broker-abrokerId=0brokerIP=10.10.10.100deleteWhen=04fileReservedTime=48brokerRole=ASYNC_MASTERflushDiskType=ASYNC_FLUSH 启动脚本如下，重点在于-c参数指定了配置文件，当前如果需要我们可以在broker.properties中做更多的个性化配置 $ nohup sh bin/mqbroker -n localhost:9876 -c conf/broker.properties &gt; /dev/null 2&gt;&amp;1 &amp; 关闭关闭Broker服务 $ sh bin/mqshutdown broker 关闭NameServer服务 $ sh bin/mqshutdown namesrv 命令管理RocketMQ提供了bin/mqadmin命令行对消息队列进行管理。 -n设置NameServer地址和端口(从NameServer上获取Broker地址和端口) 查看主题列表 $ bin/mqadmin topicList -n localhost:9876TBW102 创建主题 参数 说明 -n NameServer地址和端口 -b Broker地址和端口(Topic创建在这个Broker上面) -c Cluster名称（Broker和Cluster二选一） -t Topic主题名称 -r 读队列数(默认8个) -w 写队列数(默认8个) 创建主题test $ bin/mqadmin updateTopic -n localhost:9876 -b localhost:10911 -t test -r 4 -w 4create topic to localhost:10911 success.TopicConfig [topicName=test, readQueueNums=4, writeQueueNums=4, perm=RW-, topicFilterType=SINGLE_TAG]$ bin/mqadmin topicList -n localhost:9876TBW102test 查看Topic信息 $ bin/mqadmin topicStats -n localhost:9876 -t test 查看集群信息 $ bin/mqadmin clusterList -n localhost:9876#Cluster Name #Broker Name #BID #Addr #VersionDefaultCluster ubuntu 0 172.17.0.1:10911 V3_1_4 根据MessageID查询消息 $ bin/mqadmin queryMsgById -n localhost:9876 -i 根据消息Key查询消息 $ bin/mqadmin queryMsgByKey -n localhost:9876 -t test -k 控制台虽然可以通过命令行查看RocketMQ状态，但是使用起来很不方便。 rocketmq-console项目封装了mqadmin指令，提供了web页面来展示rocketmq信息，所以通常我们都使用rocketmq-console来查看RocketMQ状态。 rocketmq-console属于rocketmq-externals 项目的一部分。 首先，获取源码 $ git clone https://github.com/apache/rocketmq-externals 然后，打包部署(rocketmq-console是spring boot项目) $ cd rocketmq-externals/rocketmq-console$ mvn clean package -Dmaven.test.skip=true$ java -jar rocketmq-console-ng-1.0.0.jar --server.port=12581 --rocketmq.config.namesrvAddr=10.89.0.64:9876 v3.1.4版本是没有提供控制台工具的，rocketmq-externals(包括rocketmq-console)是为rocketmq v4.0.0以上版本服务的。所以，理论上rocketmq-console和v3.1.4是不兼容的。不过，mqadmin的指令协议没有变化，所以基本使用是可以的。当然，升级到4.0.0以上版本就更没有问题了。]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>mq</tag>
        <tag>rocketmq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RocketMQ(1) 概述]]></title>
    <url>%2F2018%2F04%2F21%2Frocketmq-intro%2F</url>
    <content type="text"><![CDATA[简介RocketMQ是阿里巴巴开源的一款高性能、高吞吐率的分布式消息中间件。产品基于高可用分布式集群技术，提供消息发布订阅、消息轨迹查询、定时（延时）消息、资源统计、监控报警等功能，是阿里巴巴双11使用的核心产品。2016年阿里巴巴正式宣布将 RocketMQ 捐赠给 Apache 软件基金会。 RocketMQ的前身叫MetaQ，MetaQ从3.0版本开始更名为RocketMQ。 基本概念以下内容来自阿里云对MQ项目的介绍。 应用场景 异步解耦，基于发布订阅模型，对分布式应用进行异步解耦，增加应用的水平扩展能力； 削峰填谷，大促等流量洪流突然来袭时，MQ 可以缓冲突发流量，避免下游订阅系统因突发流量崩溃； 日志监控，作为重要日志的监控通信管道，将应用日志监控对系统性能影响降到最低； 消息推送，为社交应用和物联网应用提供点对点推送，一对多广播式推送的能力； 金融报文，发送金融报文，实现金融准实时的报文传输，可靠安全； 电信信令，将电信信令封装成消息，传递到各个控制终端，实现准实时控制和信息传递。 消息类型定时消息和延时消息 定时消息：Producer 将消息发送到 MQ 服务端，但并不期望这条消息立马投递，而是推迟到在当前时间点之后的某一个时间投递到 Consumer 进行消费。 延时消息：Producer 将消息发送到 MQ 服务端，但并不期望这条消息立马投递，而是延迟一定时间后才投递到 Consumer 进行消费。 定时/延时消息适用于如下一些场景： 消息生产和消费有时间窗口要求：比如在电商交易中超时未支付关闭订单的场景，在订单创建时会发送一条 MQ 延时消息，这条消息将会在30分钟以后投递给消费者，消费者收到此消息后需要判断对应的订单是否已完成支付。如支付未完成，则关闭订单，如已完成支付则忽略。 通过消息触发一些定时任务：比如在某一固定时间点向用户发送提醒消息。 顺序消息顺序消息是MQ提供的一种按照顺序进行发布和消费的消息类型。顺序消息由两个部分组成：顺序发布和顺序消费。顺序消息类型分为两种：全局顺序和分区顺序。 全局顺序消息 MQ全局顺序消息适用于以下场景：性能要求不高，所有的消息严格按照 FIFO 原则进行消息发布和消费的场景。 分区顺序消息 MQ 分区顺序消息适用于如下场景：性能要求高，以 sharding key 作为分区字段，在同一个区块中严格的按照 FIFO 原则进行消息发布和消费的场景。 举例说明：【例一】用户注册需要发送发验证码，以用户 ID 作为 sharding key， 那么同一个用户发送的消息都会按照先后顺序来发布和订阅。【例二】电商的订单创建，以订单 ID 作为 sharding key，那么同一个订单相关的创建订单消息、订单支付消息、订单退款消息、订单物流消息都会按照先后顺序来发布和订阅。 阿里巴巴集团内部电商系统均使用此种分区顺序消息，既保证业务的顺序，同时又能保证业务的高性能。 事务消息 事务消息：MQ 提供类似XA的分布事务功能，通过 MQ 事务消息能达到分布式事务的最终一致； 半消息：暂不能投递的消息，发送方已经将消息成功发送到了 MQ 服务端，但是服务端未收到生产者对该消息的二次确认，此时该消息被标记成“暂不能投递”状态，处于该种状态下的消息即半消息； 消息回查：由于网络闪断、生产者应用重启等原因，导致某条事务消息的二次确认丢失，MQ 服务端通过扫描发现某条消息长期处于“半消息”时，需要主动向消息生产者询问该消息的最终状态（Commit 或是 Rollback），该过程即消息回查。 如上图所示，事务消息的处理过程如下： 发送方向 MQ 服务端发送消息； MQ Server 将消息持久化成功之后，向发送方 ACK 确认消息已经发送成功，此时消息为半消息； 发送方开始执行本地事务逻辑； 发送方根据本地事务执行结果向 MQ Server 提交二次确认（Commit 或是 Rollback），MQ Server 收到 Commit 状态则将半消息标记为可投递，订阅方最终将收到该消息；MQ Server 收到 Rollback 状态则删除半消息，订阅方将不会接受该消息； 在断网或者是应用重启的特殊情况下，上述步骤4提交的二次确认最终未到达 MQ Server，经过固定时间后 MQ Server 将对该消息发起消息回查； 发送方收到消息回查后，需要检查对应消息的本地事务执行的最终结果； 发送方根据检查得到的本地事务的最终状态再次提交二次确认，MQ Server 仍按照步骤4对半消息进行操作。 事务消息完成本地事务后，可在返回如下三种状态： TransactionStatus.CommitTransaction 提交事务，允许订阅方消费该消息； TransactionStatus.RollbackTransaction 回滚事务，消息将被丢弃不允许消费； TransactionStatus.Unknow 暂时无法判断状态，期待固定时间以后 MQ Server 向发送方进行消息回查。 集群消费和广播消费集群消费 消息只被消费者组中的一个实例消费； 这是我们最常见的模式，集群消费可以很方便的横向拓展，提升处理能力。 广播消费 消费者组中的每一个实例都可以消费到消息。 消息过滤Tag，即消息标签、消息类型，用来区分某个 MQ 的 Topic 下的消息分类。MQ 允许消费者按照 Tag 对消息进行过滤，确保消费者最终只消费到他关心的消息类型。 以下图电商交易场景为例，从客户下单到收到商品这一过程会生产一系列消息，比如订单创建消息（order）、支付消息（pay）、物流消息（logistics）。这些消息会发送到 Topic 为 Trade_Topic 的队列中，被各个不同的系统所接收，比如支付系统、物流系统、交易成功率分析系统、实时计算系统等。其中，物流系统只需接收物流类型的消息（logistics），而实时计算系统需要接收所有和交易相关（order、pay、logistics）的消息。 说明：针对消息归类，您可以选择创建多个 Topic， 或者在同一个 Topic 下创建多个 Tag。但通常情况下，不同的 Topic 之间的消息没有必然的联系，而 Tag 则用来区分同一个 Topic 下相互关联的消息，比如全集和子集的关系，流程先后的关系。 消息重试 当消息不能送达时，MQ 默认允许每条消息最多重试 16 次，每次重试的间隔越来越长，从10 秒、30秒、1分钟，直到2小时； 如果消息重试 16 次后仍然失败，消息将不再投递； 也就是说，某条消息在一直消费失败的前提下，将会在接下来的 4 小时 46 分钟之内进行 16 次重试，超过这个时间范围消息将不再重试投递。 消费幂等发送时消息重复（消息 Message ID 不同） MQ Producer 发送消息场景下，消息已成功发送到服务端并完成持久化，此时网络闪断或者客户端宕机导致服务端应答给客户端失败。如果此时 MQ Producer 意识到消息发送失败并尝试再次发送消息，MQ 消费者后续会收到两条内容相同但是 Message ID 不同的消息。 投递时消息重复（消息 Message ID 相同） MQ Consumer 消费消息场景下，消息已投递到消费者并完成业务处理，当客户端给服务端反馈应答的时候网络闪断。为了保证消息至少被消费一次，MQ 服务端将在网络恢复后再次尝试投递之前已被处理过的消息，MQ 消费者后续会收到两条内容相同并且 Message ID 也相同的消息。 真正安全的幂等处理，不建议以 Message ID 作为处理依据。最好的方式是以业务唯一标识作为幂等处理的关键依据，而业务的唯一标识可以通过消息 Key 进行设置。 消息发送方式 可靠同步发送，同步发送是指消息发送方发出数据后，会在收到接收方发回响应之后才发下一个数据包的通讯方式； 可靠异步发送，异步发送是指发送方发出数据后，不等接收方发回响应，接着发送下个数据包的通讯方式。MQ 的异步发送，需要用户实现异步发送回调接口（SendCallback），在执行消息的异步发送时，应用不需要等待服务器响应即可直接返回，通过回调接口接收服务器响应，并对服务器的响应结果进行处理； 单向（Oneway）发送，单向（Oneway）发送特点为只负责发送消息，不等待服务器回应且没有回调函数触发，即只发送请求不等待应答。此方式发送消息的过程耗时非常短，一般在微秒级别。]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>mq</tag>
        <tag>rocketmq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Hexo搭建自己的博客]]></title>
    <url>%2F2018%2F04%2F21%2Fhexo-intro%2F</url>
    <content type="text"><![CDATA[概述搭建个性化的博客网站，我们需要用到hexo和github。其中Hexo是一个快速、简洁且高效的博客框架，使用hexo我们可以快速编写、生成、预览和部署博客文章，最终我们的博客文章发布到github上。Github为个人博客提供了免费的发布平台，通过域名yourname.github.io可以访问到同名的github项目。 准备工作安装Git可以去这里下载Git的windows版本，正确安装后可以在Shell中查看到git版本 $ git --versiongit version 2.7.2.windows.1 安装Node.js去nodejs官网下载最新版本(node-v8.11.1-x64.msi)并安装，正确安装后可以查看到版本 $ node -vv8.11.1 安装Hexonode.js中带了包管理工具npm，后面的模块都可以通过npm来安装，-g表示全局安装 官网上的文档中只安装了hexo-cli，试了一下有问题，这里还是安装hexo(里面包含hexo-cli) $ npm install -g hexo$ hexo versionhexo: 3.7.1hexo-cli: 1.1.0 创建Github项目 注册github账户，并做好配置 创建以用户开头，以github.io结尾的项目，例如：我的用户名是waterlu，那么创建的项目名称为 waterlu.github.io 项目创建成功后访问 https://waterlu.github.io/ ，后面就是部署页面的操作了。 Hexo基本操作Hexo是静态化的博客框架，使用markdown格式编写文章，然后通过hexo generate指令生成静态的HTML页面，最后通过hexo depoly指令将HTML页面上传到GitHub上。 所有hexo操作都需要在hexo init的目录执行，也就是含有_config.yml和source的目录，在其他目录执行hexo generate等操作是无效的。 初始化 hexo init 指令创建新的博客 $ cd /c/lu/blog$ hexo init$ ls -l-rw-r--r-- 1 _config.ymldrwxr-xr-x 1 node_modules/-rw-r--r-- 1 package.jsondrwxr-xr-x 1 scaffolds/drwxr-xr-x 1 source/drwxr-xr-x 1 themes/ 配置_config.yml，配置个性化信息和部署地址 title: Waterlu&apos;s Blogdescription: 个人技术博客author: Water Ludeploy: type: git repo: git@github.com:waterlu/waterlu.github.io.git branch: master 生成网站$ hexo generate 本地预览 启动web服务 访问http://localhost:4000 $ hexo server 部署到Github 第一次部署前安装hexo-deployer-git 以后通过deploy部署（事先需要在_config.yml中配置github相关信息） $ npm install hexo-deployer-git --save$ hexo deploy 个性化定制主题我使用的主题是Maupassant，感觉比较简洁。 注意：npm install的两个模块不是全局安装的，每次hexo init创建新项目后都得执行(npm install -g才是全局安装)。 $ git clone https://github.com/tufu9441/maupassant-hexo.git themes/maupassant$ npm install hexo-renderer-pug --save$ npm install hexo-renderer-sass --save 修改根目录下的_config.yml，设置theme为maupassant theme: maupassant 创建about页面 $ hexo new page about 修改themes/maupassant目录下的_config.yml，去掉RSS页面 menu: - page: home directory: . icon: fa-home - page: archive directory: archives/ icon: fa-archive - page: about directory: about/ icon: fa-user # - page: rss # directory: atom.xml # icon: fa-rss 评论功能 TODO 站内搜索 安装hexo-generator-search $ npm install hexo-generator-search --save$ npm install hexo-generator-searchdb --save 修改根目录下的_config.yml，增加如下配置 search: path: search.xml field: post format: html limit: 10000 修改themes\maupassant下的_config.yml，打开self_search google_search: false ## Use Google search, true/false.baidu_search: false ## Use Baidu search, true/false.swiftype: ## Your swiftype_key, e.g. m7b11ZrsT8Me7gzApciTtinysou: ## Your tinysou_key, e.g. 4ac092ad8d749fdc6293self_search: true ## Use a jQuery-based local search engine, true/false. 访问统计 修改themes\maupassant下的_config.yml，打开不蒜子busuanzi: true ## If you want to use Busuanzi page views please set the value to true. 流程图和序列图Hexo默认不支持markdown的flow图和sequence图，需要安装插件 进入项目根目录安装插件 $ npm install --save hexo-filter-flowchart$ npm install --save hexo-filter-sequence 修改项目的_config.yml，增加配置 flowchart: # raphael: # optional, the source url of raphael.js # flowchart: # optional, the source url of flowchart.js options: # options used for `drawSVG`sequence: # webfont: # optional, the source url of webfontloader.js # snap: # optional, the source url of snap.svg.js # underscore: # optional, the source url of underscore.js # sequence: # optional, the source url of sequence-diagram.js # css: # optional, the url for css, such as hand drawn theme options: theme: css_class: Hexo日常操作写文章 [layout]默认为post，指的是文章的布局类型，在_config.yml中可以配置 如果[layout]=post，那么新文章将生成到source/_posts目录下 $ hexo new [layout] &lt;title&gt; 文章开头”—“之间的部分称为Front-matter，主要包括以下信息 参数 描述 layout 文章布局 title 文章标题 date 文章发布时间 updated 文章更新时间 tags 标签 categories 分类 发表文章$ hexo new post [title]$ hexo clean$ hexo generate$ hexo server$ hexo deploy 常见问题解析错误 当title.md文章中出现无法解析的markdown语法时，报错Template render error 因为需要把markdown转成html，所以必须解析正确 $ hexo gINFO Start processingFATAL Something's wrong. Maybe you can find the solution here: http://hexo.io/docs/troubleshooting.htmlTemplate render error: expected variable end]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>github</tag>
      </tags>
  </entry>
</search>
